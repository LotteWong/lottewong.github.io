{"pages":[{"title":"About Me","text":"程序员小黄，会吃福建人的广东人，面临90后中年危机，爱的人都叫夏洛特。 TODODevOps 《鸟哥的linux私房菜-基础学习篇》 《鸟哥的linux私房菜-服务器架设篇》 Golang #Golang# Golang与反射机制(1) reflect使用【什么是反射/Golang反射和Java反射/反射三定律】 #Golang# Golang与反射机制(2) reflect原理【interface底层/reflect底层】 #Golang# Golang与延迟函数(1) defer使用 #Golang# Golang与延迟函数(2) defer底层 《Go语言高并发与微服务实战》 Arch 适用于业务的轻量级权限控制框架设计与实现 适用于业务的轻量级单点登录框架设计与实现 Cloud Computing CTOSD Microservice &amp; Containerization Vue+Go 开发企业级微服务网关项目 Go容器化微服务系统实战 Distributed System MIT 6.824 Data Structure to be continued… Algorithm Problem to be continued… GaTech OMSCS CS 6515 Introduction to Graduate Algorithms CS 6035 Introduction to Information Security CS 6210 Advanced Operating Systems CS 6250 Computer Networks CS 6400 Database Systems Concepts and Design CS 6300 Software Development Process CS 6310 Software Architecture and Design","link":"/about/index.html"}],"posts":[{"title":"#Mock# Challenge to Mock - Arch Designs","text":"God is a mock. – Just Kidding 目录 Table of Contents 背景 最近接到了新任务——希望 mock 掉项目依赖的底座，主要基于两点考量： 内部联调时可以屏蔽掉底座的影响，不至于阻塞当前开发模块的流程； 之后可集成自动化测试，降低测试成本。 我的第一感觉是这个东西不好搞。一是上下游的依赖关系比较复杂，这意味着：首先让 mock 做到可以替换原来的底座以满足基本功能就需要一些努力，其次项目“看起来”运行正常并不能保证上游亦是如此；二是替换底座包含了 mock 掉数据返回和状态管理两个概念，那么就不得不在简洁和可用之间做取舍了。 本文接下来要讨论的内容，暂不考虑上游影响，并坚持这样的原则：整个模块应当是轻量的，仅对高优先级且不满足的业务场景做出适配。 业务分析 project service api：同步的项目入口，直接发请求或开异步任务来调用底座 job：异步的后台任务，监控底座资源状态 db：存储项目所需的数据 infrastructure base 提供核心功能的底座 external services 出于其它业务需求，会存储底座的某些数据 根据上图的分析，需考虑以下几点： mock 可以代替 infrastructure base 正常响应； project service / infrastructure bases / external services 三者之间的数据应当保持一致性； 异步的后台任务需要监控状态变化，保存状态是必需的。 架构演化固定数据 问题描述：mock 从无到有 解决方法：选用预研的框架，可以方便地管理路由转发规则和模拟返回数据 mock api proxy：设置路由转发规则。应该采用正则匹配，保证增删查改的通用性，预研框架支持： 请求路径正则匹配 请求参数正则匹配 请求主体正则匹配 hardcoded response：提供对应路由的返回数据。应该返回全量的响应字段，其中一些字段可以灵活处理： UUID：创建资源时返回随机 UUID；查询/修改/删除单个资源时从路径读 UUID；查询资源列表时返回固定条目和 UUID 其它字段：必传字段从请求中接收；选传字段硬编码其内容；如果出现不同响应格式，路由转发规则要做区分 引入存根 问题描述：需要对返回字段做逻辑处理，固定数据模式无法直接满足 解决方法：预研框架支持存根注入，保留了扩展业务逻辑的能力 easy stub：支持简易逻辑扩展，主要可以用于： 提供配置 提取、组合和处理请求的数据 返回随机数据或当前时间等 注：在预研框架中，存根的入口是唯一的，因此如果希望复用多个存根，方式不太优雅。 存储数据 问题描述：目前的架构中没有办法保存数据，无法实现保持数据的一致性和监控状态变化 解决办法：引入 MVC 设计和轻量级的数据库 SQLite service stub：MVC 中的 Controller dao：MVC 中的 Model sqlite：轻量级关系型数据库，支持单文件和内存两种存储模式 参数匹配 问题描述：预研框架对通过请求参数匹配的支持较弱，infrastructure base A 没有相关需求，infrastructure base B 需解决该问题 解决办法：只能引入轻量的 Web 框架来补充 query matcher：强化请求参数匹配规则的核心中间件/装饰器 12345678910111213141516171819202122232425262728293031class MatchingMode(object): Has = \"has\" # 模糊匹配 Is = \"is\" # 精确匹配class QueryMatcher(object): def __init__(self, matching_rules, query_arguments, matching_mode): self.matching_rules = matching_rules self.query_arguments = query_arguments self.matching_mode = matching_mode def match(self): # 检查请求参数的数量 if self.matching_mode == MatchingMode.Is: if len(self.matching_rules) != len(self.query_arguments): logger.debug(\"match failed: length of query arguments is not equal to length of the matching rule\") return False # 检查请求参数的规则 for key in self.matching_rules: if key in self.query_arguments: rule = self.matching_rules[key] val = str(self.query_arguments[key][0]) if not re.match(rule, val): logger.debug(\"match failed: query argument not match matching rule. rule: %s, val: %s\" % (rule, val)) return False else: logger.debug(\"match failed: query argument not in matching rules\") return False # 均通过则返回真 return True 统一配置 问题描述：由于同时存在两套框架及一些业务数据，配置比较分散 解决办法：将这些配置统一到一个文件，并在文档上说明约束是有必要的 config：统一的配置文件 123456789101112131415{ \"host\": \"127.0.0.1\", \"mock_port\": 1024, \"web_port\": 2333, \"db_name\": \"test.db\", \"mock_config_path\": \"etc/mock_config.yml\", // 其中还可以配置日志的路径 \"web_config_path\": \"etc/web_config.json\", // 其中还可以配置日志的路径 \"business_field_1\": \"\", \"business_field_2\": \"\", \"business_field_3\": \"\", ...} 日志记录 问题描述：预研框架自带日志记录，但是新引入的 Web 框架没有 解决办法：需要自行补充日志模块 log：补充的日志模块 12345...[formatter_web]format=%(asctime)s|%(name)s|%(levelname)s|%(filename)s|%(funcName)s|%(message)sdatefmt=... 健康检查 问题描述：部署 mock 后不好快速简单地验证是否可用 解决办法：额外增加两个专门用于健康检查的接口 h-c：健康检查接口（Health-Check API），可参考的设计： 123curl --location --request GET 'http://${ip}:{port}/mock/ping' # Expected response body: {\"msg\": \"pong\"}curl --location --request GET 'http://${ip}:{port}/web/ping' # Expected response body: {\"msg\": \"pong\"} 预告 下期将继续讨论以下这些内容： 技术选型 接口文档 / 接口测试 进程部署 / 容器部署 代办事项","link":"/2020/12/16/Challenge to Mock - Arch Designs/"},{"title":"#Mock# Challenge to Mock - Tech Details","text":"God is a mock. – Just Kidding 目录 Table of Contents 背景 最近接到了新任务——希望 mock 掉项目依赖的底座，主要基于两点考量： 内部联调时可以屏蔽掉底座的影响，不至于阻塞当前开发模块的流程； 之后可集成自动化测试，降低测试成本。 我的第一感觉是这个东西不好搞。一是上下游的依赖关系比较复杂，这意味着：首先让 mock 做到可以替换原来的底座以满足基本功能就需要一些努力，其次项目“看起来”运行正常并不能保证上游亦是如此；二是替换底座包含了 mock 掉数据返回和状态管理两个概念，那么就不得不在简洁和可用之间做取舍了。 前文已经展开讨论了业务分析和架构演化这两方面的内容，本文将整理一些技术细节。 技术选型Postman 优点： 界面化操作，比较直观 可以集成 Postman 各种功能，如接口文档、接口测试等 缺点： 设置匹配规则不够灵活 返回数据自定义不方便 所有用例都在一个文件，不好进行版本管理 web framework 优点： 由于是自己来实现功能，非常灵活 缺点： 重新造很多轮子，工作量大 json-server + Mock.js 优点： 框架轻量且容易上手 json-server用于设置转发规则，mock.js用于模拟返回数据，分工明确 缺点： 二次开发有语言壁垒 内部框架 优点： 转发规则和返回数据在同一模板文件中约定 内置了常用的工具函数，并且支持存根注入来扩展功能 非单一的 mock 框架，支持契约测试 缺点： 存根入口单一，复用存根不太方便 请求参数匹配支持较弱 总结：选用内部框架更符合当前的场景。 接口文档 / 接口测试Postman + Newman 优点： 界面化操作，比较直观 独立于代码之外，无侵入 接口测试比较强大，支持设置顺序、次数、运行测试前执行脚本和运行测试后进行判断等功能 缺点： 生成的接口文档只能在线查看，无法本地保存 文档可定制化的部分较少，无法对输入输出字段做备注 Swagger 优点： 生成的文档信息齐全，包括路径、请求参数及描述、返回数据及描述以及示例等 直接在代码中标记，可以培养一边开发一边写文档的好习惯 配置后还可以直接发送请求测试接口 缺点： 接口测试功能比较单一，无法很方便地管理一个功能集合层面的测试用例 总结：如果看重文档输出，使用 Swagger；如果看重接口测试，使用 Postman + Newman。如果是在开发过程中，使用 Swagger，持续集成；如果是在开发过程后，使用 Postman + Newman，最少改动。其实最佳实践应该是两者结合起来使用，唯一的缺点就是工作量比较大。 进程部署 / 容器部署 分别提供两种模式的部署脚本，前置知识： #Linux&amp;Shell# 速查手册：常用 Linux&amp;Shell 命令 #Docker# 速查手册：常用 Docker 命令 #Kubernetes# 速查手册：常用 Kubernetes 命令 代办事项 完善单元测试 精简镜像大小 接入 CI / CD 流水线 附录 聊一聊契约测试","link":"/2020/12/17/Challenge to Mock - Tech Details/"},{"title":"#Api Docs# Api Docs Pre-study and Practice in Golang","text":"If you write code, write docs. – Make up by myself 目录 Table of Contents 背景 作为一个轻度强迫症候群者，单纯觉得人工写文档也太让人难受了（还有点累。其次是希望自己可以养成先出文档后写代码的好习惯，所以就迫切需要一个提高生产效率的文档生成工具了。 总的来说，我们希望解决以下问题： 写文档就像填表格，固定的输入规则对应固定的输出格式 整体应用文档应有这些内容： 接口目录 变更记录 其它备注 具体接口文档应有这些内容： 功能描述 请求方法 请求路径 请求参数（规格和示例） 响应状态 响应参数（规格和示例） 最好具备一定的接口测试功能 技术选型编码后写手写 markdown 文档：格式和内容容易出错，写完代码后再写文档积极性也不高，不推荐这样做。 测试时写postman + docgen：可以实现在线发布接口文档和离线导出接口文档。优点在于无侵入和允许可视化操作，缺点在于请求参数和响应参数无法增加规格描述。 编码前写swaggo + swagger-markdown：可以实现在线发布接口文档和离线导出接口文档。优点在于同时满足接口文档格式、内容和测试等方面的要求，缺点在于有侵入即需要改造原有项目。 安装工具安装及使用 swaggo 工具： 12345678910# 安装go get github.com/swaggo/swag/cmd/swaggo get -u github.com/swaggo/gin-swagger # 适用于 gin 的工程go get -u github.com/swaggo/gin-swagger/swaggerFiles # 适用于 gin 的工程# 使用swag init # 在工程根目录下执行# -g ${path} 解析文件路径# -d ${path} 解析目录路径（默认解析 main.go）# -o ${path} 输出文档路径 安装及使用 swagger-markdown 工具： 12345# 安装npm install -g swagger-markdown# 使用swagger-markdown -i ${input_yaml} -o ${outputMarkdown} 编写文档整体应用main.go12345678910111213141516171819package mainimport ( \"go-swagger-sample/router\" \"log\")// 注解对于导出 markdown 格式生效// @title Title For Go-Swagger-Sample Api Docs // 标题// @description `Markdown` Description For Go-Swagger-Sample Api Docs // 描述（支持 Markdown 格式）// @version 1.0.0 // 版本// @host 127.0.0.1:8080 // 测试接口的请求地址// @BasePath /api/v1 // 测试接口的请求前缀func main() { route := router.InitRouter() if err := route.Run(); err != nil { log.Fatalf(\"App crashed, err: %v\", err) }} router/router.go1234567891011121314151617181920212223242526package routerimport ( \"github.com/gin-gonic/gin\" swaggerFiles \"github.com/swaggo/files\" ginSwagger \"github.com/swaggo/gin-swagger\" \"go-swagger-sample/controller\" \"go-swagger-sample/docs\")func InitRouter() *gin.Engine { router := gin.Default() // 引用对于访问 html 网页生效 docs.SwaggerInfo.Schemes = []string{\"http\", \"https\"} // 测试接口的请求协议 router.GET(\"/swagger/*any\", ginSwagger.WrapHandler(swaggerFiles.Handler)) // 路由托管 swagger 静态资源 userGroup := router.Group(\"/api/v1/users\") { userGroup.GET(\"\", controller.ListUsers) userGroup.POST(\"\", controller.CreateUser) userGroup.GET(\"/:id\", controller.GetUser) } return router} 具体接口controller/controller.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package controllerimport ( \"github.com/gin-gonic/gin\" \"go-swagger-sample/models\" \"net/http\")// User godoc// @Summary 查询用户列表 // 标题// @Description 查询用户列表描述 // 描述（支持 Markdown 格式） // @Tags 用户接口 // 分类// @Id /users// @Accept json// @Produce json// @Param username query string false \"登录名称\" // 请求参数规格和示例（query）// @Success 200 {object} models.Users \"success\" // 响应参数规格和示例// @Router /users [get] // 测试接口的请求路径和请求方法func ListUsers(ctx *gin.Context) { user := &amp;models.User{} if err := ctx.ShouldBind(&amp;user); err != nil { ctx.JSON(http.StatusInternalServerError, err) } // TODO: list all users users := []models.User{*user} res := &amp;models.Users{ TotalCount: 1, Items: users, } ctx.JSON(http.StatusOK, res)}// User godoc// @Summary 创建用户 // 标题// @Description 创建用户描述 // 描述（支持 Markdown 格式） // @Tags 用户接口 // 分类// @Id /users// @Accept json// @Produce json// @Param createBody body models.User true \"创建用户请求主体\" // 请求参数规格和示例（body）// @Success 200 {object} models.User \"success\" // 响应参数规格和示例// @Router /users [post] // 测试接口的请求路径和请求方法func CreateUser(ctx *gin.Context) { user := &amp;models.User{} if err := ctx.ShouldBind(&amp;user); err != nil { ctx.JSON(http.StatusInternalServerError, err) } // TODO: create a user ctx.JSON(http.StatusOK, user)}// User godoc// @Summary 查询用户详情 // 标题// @Description 查询用户详情描述 // 描述（支持 Markdown 格式） // @Tags 用户接口 // 分类// @Id /users/:id// @Accept json// @Produce json// @Param id path string true \"用户标识\" // 请求参数规格和示例（path）// @Success 200 {object} models.User \"success\" // 响应参数规格和示例// @Router /users/{id} [get] // 测试接口的请求路径和请求方法func GetUser(ctx *gin.Context) { user := &amp;models.User{} if err := ctx.ShouldBindUri(&amp;user); err != nil { ctx.JSON(http.StatusInternalServerError, err) } // TODO: get a user ctx.JSON(http.StatusOK, user)} model/dto.go1234567891011121314package models// 请求参数或响应参数规格和示例type User struct { Id string `json:\"id\" form:\"id\" uri:\"id\" example:\"1\"` // 用户标识 Username string `json:\"username\" form:\"username\" example:\"admin\"` // 登录名称 Password string `json:\"password\" form:\"password\" example:\"123456\"` // 登录密码}// 请求参数或响应参数规格和示例type Users struct { TotalCount int `json:\"totalcount\" form:\"totalcount\" example:\"0\"` // 共计条数 Items []User `json:\"items\" form:\"items\" example:\"\"` // 用户列表} 接口测试query body path 在线查看访问 http://${ip}:${port}/swagger/index.html 可阅 离线导出导出 markdown 格式使用 swagger-markdown 工具将 swagger.yaml 转换为 docs.md 导出 PDF/Word/HTML 格式使用 Typora 工具将 docs.md 转换为 docs.pdf/docs.docx/docs.html 附录 swaggo/swag syroegkin/swagger-markdown","link":"/2020/11/19/Api Docs Pre-study and Practice in Golang/"},{"title":"#Others# GoLand + DevCloud 的远程开发与调试","text":"GoLand as IDE DevCloud as go run/go build/dlv debug environment 前言 缘起一个 EOF 错误，由于网络策略原因，本地开发机无法连接某个内网服务，遂转向在办公网内的远程服务器。本人作为 Linux 小菜，由此产生了一个新诉求：在 Windows 上远程开发和调试服务器的代码，充分地发挥 IDE 的强大作用。 环境准备本地环境 GoLand 2020.2.3 远程环境 Go 1.16.6 Delve 1.7.0 配置 GoLand 连接 DevCloud创建 Deployment 配置 Tools -&gt; Deployment -&gt; Configuration -&gt; + Connection - 网络连接 Type：选择 SFTP 协议 SSH configuration：填写 Host / Port / User name / Password 信息，通过 Test Connection 验证 Root path：点击 Autodetect 按钮 Web server URL：暂时不用考虑 Mappings - 存储映射 Local path：本地开发机项目目录 Deployment path：远程服务器项目目录 Web path：暂时不用考虑 创建 Run/Debug 配置 Run -&gt; Edit Configurations -&gt; + -&gt; Go Remote Host：远程服务器地址 Port：Delve Port 登录、查看和同步登录远程服务器 Tool -&gt; Start SSH Session 查看远程目录树 Tools -&gt; Deployment -&gt; Browse Remote Host 同步本地文件夹 手动：Tools -&gt; Deployment -&gt; Sync with Deployed to DevCloud 自动：Tools -&gt; Deployment -&gt; Automatic Upload (on explicit save) 部署与调试远程执行部署脚本编译调试一起1dlv debug cmd/server/main.go --headless --listen=:2345 --api-version=2 先编译再调试12go build -o cmd/server/demo.exe cmd/server/main.godlv --listen=:2345 --headless=true --api-version=2 exec cmd/server/demo.exe 进程后台操作12nohup dlv debug cmd/server/main.go --headless --listen=:2345 --api-version=2 &gt;&gt; ./demo.log 2&gt;&amp;1 &amp; # 后台启动pkill -9 dlv # 后台暂停 完整脚本文件 start.sh 1234567891011121314#!/bin/bash# set go envexport GO111MODULE=autoexport GOPROXY=https://goproxy.io,directgo mod tidygo mod vendor# kill processes already startedpkill -9 dlv# run demo backgroud servernohup dlv debug cmd/server/main.go --headless --listen=:2345 --api-version=2 &gt;&gt; ./demo.log 2&gt;&amp;1 &amp;echo 'nohup dlv debug cmd/server/main.go --headless --listen=:2345 --api-version=2 &gt;&gt; ./demo.log 2&gt;&amp;1 &amp;' stop.sh 1234#!/bin/bash# kill processes already startedpkill -9 dlv 本地打开调试模式 PS：这里需要注意，go run 的时候返回数据到 Postman，dlv debug 的时候返回数据到 GoLand 具体流程 配置好 Deployment 和 Run/Debug 修改本地代码文件，手动或自动同步内容到远程 登录远程服务器，一键执行部署脚本 本地打好断点，开启调试模式 附录GoLand Debug 开启调试模式：Shift + F9 打下断点：点击 Code 左侧 查看变量：查看 Debug 面板 Step Over：F8 Step Into：F7 Step Out：Shift + F8 下一个断点处：F9 Delve Debug 开启调试模式：dlv debug main.go 打下断点：break pkg.fn 或 break file:line 查看变量：print var 或 args 或 locals Step Over：next Step Into：step Step Out：stepout 下一个断点处：continue 参考文献 Go进阶36:Goland远程开发调试 解决在goland中通过dlv远程调试go程序后服务端无法退出","link":"/2021/08/12/GoLand + DevCloud 的远程开发与调试/"},{"title":"#Microservice# Golang Microservice 工程开发踩坑记录","text":"第一次独立开发 Golang 微服务工程的记录，方案设计、具体开发和细节对齐通通都被我踩了一遍坑（真有我的.jpg 目录 Table of Contents 方案阶段产物 目标功能：该微服务实现的功能简要说明 模块范围：该微服务涉及的上下游及自身模块的业务范围 逻辑架构：整体或内部的架构设计 调用时序：程序工作的调用时序 流程判断：复杂部分的流程判断 接口设计：先出文档然后开发 数据库模型设计：数据库表 注意事项：一些技术细节或潜在影响因素 接口设计遵循 RESTful 风格 主要涉及路径命名、参数位置和状态返回等约束 RESTful API 设计指南- 阮一峰的网络日志 RESTful API 最佳实践- 阮一峰的网络日志 充分考虑参数属性 文本长度： Path：过长的参数不宜放在 path Query：不同浏览器和服务器限制各异，默认为 2048 个字节 Header：若服务器不作限制，可认为无限制 Body：若服务器不作限制，可认为无限制 特殊字符：只有 Path 和 Query 需要进行编码和解码 上游：浏览器会自动 urlencode 编码，其它需要手工 urlencode 编码 下游：一般服务器的 Web 框架已经做了 urldecode 处理 经验参考： Token：Path 和 Query 对文本长度有一定限制，Body 不一定符合 RESTful 风格，放在 Header 是比较合适的；但页面跳转请求时，Header 无法生效，此时放在 Query 更加方便 数据库模型设计字段属性 主键： 字段应该唯一：存在重复不适合做主键 字段建立索引：内容太长不适合做主键 文本： 考虑长文本使用 varchar 和 text 的区别 更新方式 原地更新： 优点：节省空间 缺点：多入口的并发读写会互相影响 插入更新： 优点：多入口的并发读写会互相独立 缺点：浪费空间 索引建立 若出现长文本或数据少的情景： 长文本不建议建索引 数据少可以不建索引 开发加密方法 AES (CBC + PKCS7 + PBKDF2)：对称加密算法，内部服务之间使用该加密方法，速度较快 RSA (PKCS1v15 for pub_key + PKCS8 for pri_key)：非对称加密算法，外部服务交互使用该加密方法，保密较强 更新数据 增量更新：先查询出原记录的结构体，若请求字段不为空则更新结构体并更新数据库 全量更新：直接使用请求的结构体更新数据库 排查错误 查看应用运行日志和数据库操作日志 异常处理 Golang 使用 err 代替 expection，err 包含的错误更广泛，当希望对特定某类错误进行处理时，要注意做区分。如：使用 gorm.ErrRecordNotFound 或判断列表是否为空来区分找不到和其它异常。 空值处理 Gin 的模型绑定中，当传入字段为空时结构体会赋默认值，希望忽略为空字段应该使用指针（https://github.com/gin-gonic/gin/issues/659）。 Gorm 的操作中，若对空值有所限制，需要注意是否会产生副作用。 使用公共库 尽可能使用公共库，避免地重复造轮子 配置与常量 配置：根据环境修改变量（改变时无侵入） 常量：程序固有且基本不会改变（改变时须侵入） 中间件的使用认证1234567891011// 可以直接在路由组应用中间件secretGroup := router.Group(CONTEXT_PATH + \"/secrets\", gin.BasicAuth(gin.Accounts{ constants.BASIC_AUTH_USERNAME: constants.BASIC_AUTH_PASSWORD,})){ secretGroup.GET(\"\", controller.ListSecrets) secretGroup.POST(\"\", controller.CreateSecret) secretGroup.GET(\"/:secret_id\", controller.GetSecret) secretGroup.PUT(\"/:secret_id\", controller.UpdateSecret) secretGroup.DELETE(\"/:secret_id\", controller.DeleteSecret)} 跨域12345// 必须在路由注册前应用才会生效config := cors.DefaultConfig()config.AllowAllOrigins = true // 开放请求来源config.AddAllowHeaders(\"customized_header\") // 开放请求头部router.Use(cors.New(config)) 操作进行回滚数据库层面12345678// 进行事务回滚tx.Begin()...if success { tx.Commit()} else { tx.Rollback()} 外部调用层面1234567891011121314151617181920// 创建失败后，删除脏数据func Create(req *Request) error { resource := createResource(req) err := doSomethingElse() if err != nil { deleteResource(resource) }}// 删除失败后，创建旧数据func Delete(req *Request) error { resource := getResource(req) deleteResource(req) err := doSomethingElse() if err != nil { createResource(resource) }} 对齐接口出错的判定依据 根据状态码还是错误码 同名参数的真实含义 有些参数看似同名，实际上代表的意思在不同的微服务中是不一样的 附录 由前端登录验证，页面跳转，携带headers token引发的思考和尝试 服务端与客户端跳转的区别 cookie 你咋还没整明白？ 浏览器同源策略及Cookie的作用域 傻傻分不清之Cookie、Session、Token、JWT MySQL性能优化之char、varchar、text的区别 利用散列算法优化唯一索引性能（长文本字段的唯一索引优化）","link":"/2020/10/01/Golang Microservice 工程开发踩坑记录/"},{"title":"#Golang# Golang与并发编程(1) goroutine使用","text":"本文主要讨论 goroutine 使用的相关内容。 目录 Table of Contents 前情提要 Go 中的并发性是以 goroutine (独立活动)和 channel (用于通信)的形式实现的，这是因为 Go 所信奉的“不要通过共享内存来通信，而应该通过通信来共享内存”。当然，Go 也提供了对传统通信机制的支持，如 Mutex (互斥锁) 和 WaitGroup (信号量)。 本文将讨论 Go 并发编程中的基本单位 goroutine的使用，如有错漏，欢迎指出 ;P 概念辨析串行、并发与并行串行 CPU按顺序执行完一个线程后，才能开始另一个线程（显然不是同时执行）。 并发 CPU在各个任务间切换，同时刻一个CPU只能运行一个线程（看起来的同时执行）。 并行 同时刻多个任务在多个CPU上运行（事实上的同时执行）。 进程、线程与协程进程 进程是操作系统资源分配的最小单位。 进程具有独立的地址空间，通信需要通过IPC。 一个系统内的多个进程可以并发执行。 线程 线程是操作系统调度执行的最小单位。 线程共享进程的地址空间，通信直接共享内存。 一个进程内的多个线程可以并发执行。 协程 协程运行在用户态，而进程和线程都运行在内核态。 协程是函数间切换不是线程间切换，占用内存和切换开销更小。 一个线程内的多个协程只可串行执行。 PS：Linux虚拟地址空间布局 用户线程与内核线程 内核可见：用户线程对于内核来说是透明的，用户线程数量几乎不受限；内核线程对于内核来说是可见的，内核线程数量是有限制的。 调度实体：用户线程由应用程序或运行时调度器调度，用户线程切换只发生在用户态；内核线程由内核调度，内核线程切换需要陷入内核态。 资源竞争：用户线程在进程内竞争资源，用户线程阻塞那么对应进程阻塞，其它线程同时阻塞；内核线程在系统内竞争资源，内核线程阻塞只会阻塞该个线程，其它线程不被影响。 并行支持：使用用户线程，CPU 的执行单位为进程，要并行就要多进程；使用内核线程，CPU 的执行单位为线程，要并行只需多线程。 PS：线程实现模型 goroutine 与 coroutine goroutine 的运行机制属于抢占式任务处理，应用程序对CPU的控制由 Go Runtime Scheduler 管理；coroutine 的运行机制属于协作式任务处理，应用程序对CPU的控制由应用程序决定。 goroutine 可以并行执行，可能发生在多线程环境下；coroutine 始终顺序执行，总是发生在单线程环境下。 goroutine 使用 channel 通信；coroutine 使用 yield 和 resume 通信。 goroutine 使用main goroutine Golang 的入口函数 main() 本身就是个 goroutine： 123func main() { // ...} normal goroutine 创建一个普通的 goroutine，只需要在函数前加关键字 go： 12345678910111213func sample() { // ...}func main() { // 命名goroutine go sample() // 匿名goroutine go func() { // ... }} PS：除了 main 可以打断 goroutine 执行外，各 goroutine 间是独立的。由于 goroutine 执行顺序无法确定，代码的逻辑要独立于调用的顺序。 要点总结 goroutine 是在语言层面就提供的，只需要关键字 go，使用非常方便。 参考链接 并发简略-概述 并发简略-对比并发模型 Go语言圣经","link":"/2020/03/03/Golang与并发编程(1)/"},{"title":"#Golang# Golang与并发编程(2) goroutine调度","text":"本文主要讨论 goroutine 调度的相关内容。 目录 Table of Contents 前情提要 Go 中的并发性是以 goroutine (独立活动)和 channel (用于通信)的形式实现的，这是因为 Go 所信奉的“不要通过共享内存来通信，而应该通过通信来共享内存”。当然，Go 也提供了对传统通信机制的支持，如 Mutex (互斥锁) 和 WaitGroup (信号量)。 本文将讨论 Go 并发编程中的基本单位 goroutine的调度，如有错漏，欢迎指出 ;P goroutine 调度 goroutines 仅存在于 go runtime 中而不存在于 OS 中，因此需要 Go Runtime Scheduler 来管理它们的生命周期。 线程模型 M：machine，一个 M 代表一个用户线程 P：processor，一个 P 代表一个 Go 协程所需的上下文环境 G：goroutine，一个 G 代表一个 Go 协程 KSE：kernel schedule entity，一个 KSE 代表一个内核线程 + 共享任务队列（Global Queue） 流程： Step1. 先开一个线程池； Step2. 每个线程不断从 Global Queue 中取 G 执行，亦即一个线程非同时刻可以执行多个协程； Step3. 如果没有系统调用、I/O 中断或者 channel 阻塞，goroutine 对应的线程正常工作；如果有系统调用、I/O中断或者 channel 阻塞，goroutine 对应的线程将被阻塞。 问题： 线程每次取 G 时需要加锁，否则出现竞态危害； goroutine 本身可以被阻塞，goroutine 对应的线程不应该被阻塞。 解决： 引入独有任务队列，每个线程只读自己的任务队列，不存在资源竞争； 发生系统调用或I/O中断的 goroutine 对应的线程要记录 goroutine 的上下文； 发生系统调用或I/O中断的 goroutine 对应的线程可以换出该 goroutine，然后执行新 goroutine。 + 独有任务队列（Local Queue） 流程： Step2. 每个线程不断从 Local Queue 中取 G 执行，亦即一个线程非同时刻可以执行多个协程； 问题： 线程既要负责调度又要负责执行，性能下降。 解决： 引入一个负责线程调度的抽象层，也就是 M。 + 线程调度器（M） 流程： Step1. 线程池中每个线程对应一个 M，M 将根据调度算法选择合适的 G 交由内核线程执行。 问题： 到目前为止，goroutine 仍然是协作式的，这意味着一个 G 可以长时间占用 CPU，直到它完成任务或被阻塞。 解决： 引入一个负责资源分配的抽象层，也就是 P。 + 抢占式（P） 流程： Step3.当一个 G 占用一定的 CPU 时间，又没有被调度过，那么它将被 runtime 抢占。 问题： 保留了 Global Queue 承载 Local Queue 溢出的 G，此时如果多个 P 同时访问 Global Queue，还是要加全局锁。 解决： 引入全局调度器 Sched。 + 全局调度器（Sched） P 主要负责 Local Queue 的调度，Sched 主要负责 Global Queue 的调度。 + 非阻塞（netpoller） 阻塞的 IO 模型为：G1 被阻塞后，M1 也被阻塞，但是 M1 的其它 G# 可以转移到空闲或新起的 M# 中执行。 非阻塞的 IO 模型为：G1 被阻塞后，M1 不会阻塞，M1 的其它 G# 仍然可以执行。 此外，netpoller 还抽象了 epoll 的多路复用，netpoller 将对应的文件描述符注册到 epoll 实例中进行 epoll_wait，就绪的文件描述符回调通知给阻塞的 G，G 更新为就绪状态等待调度继续执行。 调度场景 调度的本质就是 P 将 G 合理地分配给某个 M 的过程，M 只有和 P 绑定才能运行 G。 负载均衡 从本地到全局：Local Queue 满了，会将前一半的 G 和新创建的 G 放到 Global Queue 并打乱顺序； 从全局到本地：Local Queue 空了，会从 Glocal Queue 随机选取 n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2)) 个 G； 为了调度公平：1/61 的几率在 Global Queue 中找 G，60/61 的几率在 Local Queue 找 G，否则 Global Queue 中的 G 有可能永远没办法被调度。 任务窃取 出现空闲的M，此时它绑定的 P 的 Local Queue 为空，并且 Global Queue 也为空，则从其它 P 中窃取后一半的 G，这就是 work-stealing 算法。 线程自旋 在创建 G 时，运行的 G 会尝试唤醒其他空闲的 M 执行，如果没有 G，M 将自旋而不阻塞，不停地找 G； 自旋的优点是降低了 M 切换上下文的成本，缺点是 CPU 空转浪费资源； 折中方案是：最多有 GOMAXPROCS 个自旋的线程，多余的线程将休眠。 请求抢占 满足以下两个条件，sysmon 将会发送抢占请求，但是能否抢占成功不被保障： G 进行系统调用超过 20 μs G 运行 (非循环)超过 10 ms network IO / channel 阻塞 当 network IO / channel 操作发生，被阻塞的 G 放入等待队列，M 选择其它的 G ； 如果有就绪的 G，M 正常执行；如果无就绪的 G，M 将解绑 P 并且休眠； 当 network IO / channel 操作完成，被阻塞的 G 从等待变成就绪，加入某个 P 中被新的 M 执行或加入到 Global Queue，休眠的 M 将等待新创建的 G 唤醒。 在这个过程中，调度实际上是非阻塞的——M 不会因为 G 阻塞而休眠。 system call 阻塞 当 system call 操作发生，G 会阻塞，M 会解绑 P 并且休眠； 如果有空闲的 M，该空闲的 M 将绑定 P ，如果无空闲的 M，将新建一个 M 来绑定 P； 当 system call 操作完成，被阻塞的 G 从阻塞变成就绪，加入某个 P 中被新的 M 执行或加入到 Global Queue，休眠的 M 将等待新创建的 G 唤醒。 在这个过程中，调度实际上是阻塞的——M 会因为 G 阻塞而休眠 参考链接 Go并发编程-Goroutine如何调度的? Go调度器系列（3）图解调度原理 一文摸清 Go 的并发调度模型 也谈goroutine调度器","link":"/2020/03/04/Golang与并发编程(2)/"},{"title":"#Golang# Golang与并发编程(5) channel底层","text":"本文主要讨论 channel 底层的相关内容。 目录 Table of Contents 前情提要 为了实现 goroutine 通信，有两种常见并发模型： 共享内存：使用共享内存方式，Go 中 sync 库包提供了多种同步的机制。 消息队列：使用类似管道和消息队列的方式，各个并发单元数据相互独立，通过消息进行数据交换，Go 中 channel 类型模拟了这种同步的模式。 让我们再一次来复读 Go 社区的并发口号——“不要通过共享内存来通信，而应该通过通信来共享内存”。 本文将讨论 Go 并发编程中的通信桥梁 channel的底层，如有错漏，欢迎指出 ;P 数据结构 123456789101112131415161718192021222324252627282930type hchan struct { buf unsafe.Pointer // 信道数据缓冲队列（循环链表） qcount uint // 信道数据元素个数 dataqsiz uint // 信道数据总计大小 elemsize uint16 // 信道数据元素大小 elemtype *_type // 信道数据元素类型 sendx uint // 信道数据待发送的索引，即循环链表的队头指针 front recvx uint // 信道数据待接收的索引，即循环队列的队尾指针 rear sendq waitq // 协程发送等待队列（双向链表） recvq waitq // 协程接收等待队列（双向链表） closed uint32 // 通道关闭标志 lock mutex // 互斥锁}type waitq struct { first *sudog // 指向协程等待队列的头部 last *sudog // 指向协程等待队列的尾部}type sudog struct { ... g *g // 阻塞协程的指针（包含状态） elem unsafe.Pointer // 阻塞协程的数据（包含数据） ... prev *sudog // 指向协程等待队列的前驱节点 next *sudog // 指向协程等待队列的后驱节点 ...} Why Lock is Mutex？ channel 的应用虽然体现了“通过通信来共享内存”的思想，但是 channel 的实现则遵循“通过锁作悲观并发控制”的做法。 由于 buf 和 waitq 均先进先出 (First In First Out)，当 goroutine 并发地读写 channel 时，需要保证并发安全，使用互斥锁是很好理解的。 Why buf is Circylar Linked List？ 任何节点可以作头节点开始遍历，只需要维护一个尾指针。 简化了 sendx 和 recvx 的变化。 使用 qcount 而非 空余单元 消除循环链表的二义性，减少额外数据结构开销，可以直接返回 buf 链表长度。 Why waitq is Double Linked List？ 既可以访问前驱节点，也可以访问后驱节点。 算法流程总览 “不要通过共享内存来通信”：不要把数据放在共享区，通过限制同一时间的来访者，达到数据通信和并发安全的目的。 “应该通过通信来共享内存”：应该用信道作为中间者，通过读写该并发安全的第三方数据结构，实现数据通信和并发安全。 发送 channel 未满 加锁 拷贝 goroutine 数据到 channel 中 解锁 channel 已满 goroutine 执行语句 ch &lt;- data，向 channel 的信道数据缓冲队列 buf 中写入拷贝数据（此时 buf 已满），触发 goroutine scheduler 执行操作 gopark G 让出所占用的 M，进入 waiting 状态，协程阻塞 已阻塞的 goroutine 被抽象为 sudog，入队 channel 的协程发送等待队列 sendq goroutine 执行语句 &lt;- ch，从 channel 的信道数据缓冲队列 buf 中读取拷贝数据（此时 buf 非满），触发 goroutine scheduler 执行操作 goready sudog 出队 channel 的协程发送等待队列 sendq，elem 进入 buf，g 更改 status G 放入 P 队列中，进入 ready 状态，协程可运行 接收 channel 未空 加锁 拷贝 channel 数据到 goroutine 中 解锁 channel 已空 goroutine 执行语句 &lt;- ch，向 channel 的信道数据缓冲队列 buf 中读取拷贝数据（此时 buf 已空），触发 goroutine scheduler 执行操作 gopark G 让出所占用的 M，进入 waiting 状态，协程阻塞 已阻塞的 goroutine 被抽象为 sudog，入队 channel 的协程发送等待队列 recvq goroutine 执行语句 ch &lt;- data，直接由 g1 拷贝数据到 g2（不经过 buf，不使用 lock），触发 goroutine scheduler 执行操作 goready sudog 出队 channel 的协程发送等待队列 recvq，elem 进入 g2，g1 更改 status G 放入 P 队列中，进入 ready 状态，协程可运行 关闭 排除 panic 情况，亦即关闭空的信道和重复关闭信道 遍历 sendq 和 recvq 并出队，sudog 中的 g 加入 gList 等待唤醒，sudog 中的 elem 置为 nil 将被清除 遍历 gList 并出栈，触发 goready 调度 参考链接 Golang源码分析系列之Channel底层实现 图解Golang的channel底层原理 Go channel 实现原理分析 Go 语言Channel 实现原理精要| Go 语言设计与实现","link":"/2020/03/07/Golang与并发编程(5)/"},{"title":"#Api Tests# Postman + Newman 最佳实践","text":"本篇博客将讨论 Postman + Newman 的最佳实践，从以下五个方面来展开： 初始化 测试单个接口 测试逻辑功能 接口文档 接口模拟 目录 Table of Contents 背景 程序写完之后，需要对单个接口和逻辑功能来进行测试，Postman (UI) 和 Newman (CLI) 是很易用且强大的工具。当然它们也拥有提供接口文档和进行接口模拟的功能，虽使用方便但略显粗糙。本博客将着重讨论测试部分，其它功能只做简单介绍，对于概念则不会过多地解释，主要讨论其功能与流程。 初始化Global Environment Dynamic 尽可能地抽取变量，既方便调试时修改数据，又方便自动测试的集成。 测试单个接口请求内容 Method：请求方法 Path：请求路径 Headers：请求头部 Params：请求参数 Body：请求主体 测试内容 Pre-request Script：测试前脚本 1234567891011121314151617181920212223242526/* 发起请求：用户登录 */var ip = pm.environment.get(\"ip\");var port = pm.environment.get(\"port\");var username = pm.environment.get(\"username\");var password = pm.environment.get(\"password\"); var body = { \"username\": username, \"password\": password};const postRequest = { url: \"http://\" + ip + \":\" + port + \"/login\", // 请求路径 method: 'POST', // 请求方法 header: ['Content-Type:application/json'], // 请求头部 body: { // 请求主体 mode: \"raw\", // 格式 raw: JSON.stringify(body) // 内容 }};pm.sendRequest(postRequest, (err, response) =&gt; { if (err) { console.log(err); } else { console.log(response.json()); }}); Tests：测试后断言 123456789101112131415161718192021222324/* 判断状态码正常：200 */pm.test(\"Status code is 200\", function () { pm.response.to.have.status(200);});/* 发起请求：用户登录 */var ip = pm.environment.get(\"ip\");var port = pm.environment.get(\"port\");const postRequest = { url: \"http://\" + ip + \":\" + port + \"/logout\", method: 'POST'};pm.sendRequest(postRequest, (err, response) =&gt; { if (err) { console.log(err); } else { console.log(response.json()); }});/* 设置相关的变量：更新密码 */var body = JSON.parse(pm.request.body.raw);pm.environment.set(\"password\", body[\"password\"]); 测试逻辑功能用例组织 流程跳转：优点是非常灵活，缺点是有点复杂 1postman.setNextRequest(\"接口名称\"); 目录集合：优点是比较直观，缺点是存在冗余 用例设计创建服务接口 Pre-request Script： 1234567891011// 生成随机的必填字段function rand (n, m) { var num = Math.floor(Math.random() * (m - n + 1) + n) return num}var tcp_port = rand(8001, 8999);pm.environment.set(\"tcp_port\", tcp_port);var tcp_service_name = \"test_tcp_service_\" + rand(1, 100).toString();pm.environment.set(\"tcp_service_name\", tcp_service_name); Tests： 12345678910111213// 状态判断pm.test(\"Status code is 200\", function () { pm.response.to.have.status(200);});// 错误判断pm.test(\"Body not matches string\", function () { pm.expect(pm.response.text()).not.to.include(\"user not login\");});// 回写标识var body = pm.response.json();pm.environment.set(\"service_id\", body[\"data\"][\"info\"][\"id\"]); 查询服务详情接口 对 Tests 进行状态判断和错误判断 修改服务接口 Body： 123456789101112131415{ \"black_list\": \"\", \"client_ip_flow_limit\": 0, \"forbid_list\": \"\", \"ip_list\": \"127.0.0.1:2333\", \"open_auth\": 0, \"port\": {{tcp_port}}, \"round_type\": 0, \"service_desc\": \"updated\", // 特殊字串 \"service_host_flow_limit\": 0, \"service_name\": \"{{tcp_service_name}}\", \"weight_list\": \"50\", \"white_host_name\": \"\", \"white_list\": \"\"} Tests： 1234567891011121314// 状态判断pm.test(\"Status code is 200\", function () { pm.response.to.have.status(200);});// 错误判断pm.test(\"Body not matches string\", function () { pm.expect(pm.response.text()).not.to.include(\"user not login\");});// 子串判断：特殊字串pm.test(\"Body matches string\", function () { pm.expect(pm.response.text()).to.include(\"updated\");}); 删除服务接口 对 Tests 进行状态判断和错误判断 查询服务列表接口 Params： 123keyword:{{service_name}} // 模糊搜索//page_index:2//page_size:2 Tests： 1234567891011121314// 状态判断pm.test(\"Status code is 200\", function () { pm.response.to.have.status(200);});// 错误判断pm.test(\"Body not matches string\", function () { pm.expect(pm.response.text()).not.to.include(\"user not login\");});// 数量判断：特殊数值pm.test(\"Service not found\", function () { pm.expect(pm.response.json().data.total).to.eql(0);}); 运行测试 Postman：界面化操作 Newman：命令行操作 12345678910111213141516171819# file path: test/postman/*.json# npm install -g newman# npm install -g newman-reporter-html or npm install -g newman-reporter-htmlextra# Initiate a Postman Collection run from a given URL or pathnewman run test/postman/giotto-gateway.postman_collection.json \\# Define the number of iterations to run-n 1 \\# Specify the extent of delay between requests (milliseconds) (default: 0)--delay-request 0 \\# Specify a URL or path to a Postman Environment-e test/postman/giotto-gateway_env_local.postman_environment.json \\# Specify a URL or path to a file containing Postman Globals-g test/postman/giotto-gateway.postman_globals.json \\# Specify the reporters to use for this run (default: [\"cli\"])-r htmlextra \\# Export test report as html (default: newman/*.html)--reporter-html-export giotto-gateway.newman_report.html 接口文档 已支持的功能 在线接口文档 目录和接口的描述 请求示例：根据环境进行填充 响应示例：Save response as example 生成多种语言的请求代码等 不支持的功能 离线接口文档 请求参数描述 响应参数描述 接口模拟修改响应示例路径 测试接口模拟效果 附录 Understanding example matching","link":"/2020/11/20/Postman + Newman 最佳实践/"},{"title":"#Kubernetes# QCloud上的Kubernetes初体验","text":"在QCloud上利用Kubernetes编排应用与服务，主要分为以下四个部分： 环境准备 Environment 疑难解决 FAQ 具体案例 Cases 参考文献 References 目录 Table of Contents 环境准备 Environment更新系统源和软件包12apt-get upgradeapt-get update 修改Docker配置12345678910# 编辑docker配置vim /etc/docker/daemon.json{ \"exe-opts\": [\"native.cgroupdriver=systemd\"], # 修改cgroup driver选项，使docker和k8s一致 \"registry-mirrors\": [\"https://registry.docker-cn.com\"] # 替换成国内镜像源}# 重启docker服务service docker restart 或 systemctl restart docker 安装Kubernetes工具123456789# 安装依赖工具apt-get install -y apt-transport-https# 获取阿里云镜像源密钥curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -echo \"deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\" &gt; /etc/apt/sources.list.d/kubernetes.list# 安装k8s工具apt-get install -y kubelet kubeadm kubectl 下载Kubernetes镜像1234567891011121314151617181920# 查看所需镜像列表kubeadm config images list# 编辑下载镜像文件vim pull_k8s_images.sh# 从国内镜像源中下载镜像并替换标签for i in `kubeadm config images list`; do imageName=${i#k8s.gcr.io/} if [ $imageName != \"coredns/coredns:v1.8.0\" ] then docker pull registry.aliyuncs.com/google_containers/$imageName docker tag registry.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.aliyuncs.com/google_containers/$imageName else docker pull coredns/coredns:1.8.0 docker tag coredns/coredns:1.8.0 k8s.gcr.io/$imageName docker rmi coredns/coredns:1.8.0 fidone; 初始化Kubernetes主节点123kubeadm init \\--service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 # 设置网络信息--ignore-preflight-errors=NumCPU # 允许单核运行 应用Kubernetes配置1234mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configexport KUBECONFIG=/etc/kubernetes/admin.conf 下载Kubernetes网络插件1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 允许主节点部署1kubectl taint nodes --all node-role.kubernetes.io/master- 允许命令行补全12apt install bash-completionecho \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc 查看是否部署成功12kubectl get nodeskubectl get pods -n kube-system 疑难解决 FAQDocker重启服务出现异常1234567891011# 查看日志定位原因service docker status 或 systemctl status docker# 是因为/var/run/docker.sock出错了level=fatal msg=\"can't create unix socket /var/run/docker.sock: is a directory\"# 删除/var/run/docker.sock文件rm -rf /var/run/docker.sock# 重启docker服务service docker restart 或 systemctl restart docker Kubernetes忘记加入集群命令12345# 提示的命令kubeadm join ${ip} --token ${token} --discovery-token-ca-cert-hash ${discovery-token-ca-cert-hash}# 找回的命令kubeadm token create --print-join-command x509: certificate signed by unknown authority12345# 重装后.kube/config变化了，重新应用配置mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configexport KUBECONFIG=/etc/kubernetes/admin.conf Docker容器连接本机MySQL/RedisBridge模式1234567# 查看docker容器网络模式docker inspect ${container_id} | grep -i \"network\"# 默认为bridge的模式\"NetworkMode\": \"bridge\"# 此时localhost仅仅指的是容器自身地址，应使用主机的内网地址 Host模式1234# 以host的模式启动docker容器docker run -d --network=host ${registry}:${tag}# 此时localhost同时代表了容器和主机的地址 Xshell外网远程访问MySQL/Redis修改 MySQL/Redis 配置12345678910111213141516171819202122232425# 编辑mysql配置vim /etc/mysql/my.cnf# 监听所有网段[mysqld]bind-address=0.0.0.0# 修改远程登录权限mysql -u root -pmysql&gt; use mysql;mysql&gt; update user set host='%' where user='root';# 重启mysql服务使其重新生效mysqld --defaults-file=/etc/mysql/my.cnfservice mysql restart 或 systemctl restart mysql# 编辑redis配置vim /etc/redis/redis.conf# 监听所有网段bind 0.0.0.0# 重启redis-server服务使其重新生效redis-server /etc/redis/redis.confservice redis-server restart 或 systemctl restart redis-server 修改腾讯云服务器安全组规则123# 允许所有网段访问3306和6379这两个端口0.0.0.0/0 TCP:3306,6379 Allow # ipv4放行::/0 TCP:3306,6379 Allow # ipv6放行 具体案例 Cases交叉编译与镜像构建123456789101112131415161718192021# set go envexport GO111MODULE=autoexport GOPROXY=https://goproxy.io,directgo mod tidy# build binary executablemkdir -p ./binGOOS=linux GOARCH=amd64 go build -o ./bin/giotto_gateway_core# DockerfileFROM golangMAINTAINER LotteWong &lt;lottewong21@gmail.com&gt;WORKDIR /go/src/appCOPY . .CMD ./bin/giotto_gateway_core -config ./configs/prod/# docker buildcommit=`git rev-parse --short HEAD`docker build -f ./ci/docker/Dockerfile -t giotto-gateway-core:$commit . 容器部署与容器编排12345678910111213141516171819202122232425262728293031323334353637383940414243444546# deploy configapiVersion: apps/v1kind: Deploymentmetadata: name: giotto-gateway-corespec: replicas: 3 selector: matchLabels: name: giotto-gateway-core template: metadata: labels: name: giotto-gateway-core spec: containers: - name: giotto-gateway-core image: giotto-gateway-core:d1785da imagePullPolicy: Never ports: - containerPort: 80 - containerPort: 443---# service configapiVersion: v1kind: Servicemetadata: name: giotto-gateway-corespec: ports: - port: 80 name: \"http-proxy\" targetPort: 80 protocol: TCP nodePort: 30080 - port: 443 name: \"https-proxy\" targetPort: 443 protocol: TCP nodePort: 30443 type: NodePort selector: name: giotto-gateway-core # kubectl createkubectl create -f ./ci/k8s/core.yaml 参考资料 References 在 Ubuntu 上安装 K8S 教程 ubuntu k8s 单节点快速安装 docker服务启动失败 K8S在kubeadm init以后查询kubeadm join x509 certificate signed by unknown authority- Kubernetes Docker的四种网络模式Bridge模式 mysql 远程连接数据库的二种方法 解决mysql不用密码也能登录","link":"/2021/06/20/QCloud上的Kubernetes实践/"},{"title":"#WSL# WSL从入门到...(1) WSL 1 vs WSL 2","text":"对比适用于 Linux 的 Windows 子系统（Windows Subsystem for Linux, WSL）的两个版本 - WSL 1 和 WSL 2 ，主要分为以下六个部分： 前情提要 相关简介 性能对比 架构对比 几点总结 参考链接 目录 Table of Contents 前情提要 前阵网上冲浪围观 M$ Build 2019 的 WSL Session ，感受了一波 Microsoft ❤ Open Source，遂决定根据讲座和文档内容当一次复读机讨论一下 WSL ( 啊我的塑料英语_(:з)∠)_。 相关简介 The Windows Subsystem for Linux lets developers run a GNU/Linux environment – including most command-line tools, utilities, and applications – directly on Windows, unmodified, without the overhead of a virtual machine. 适用于 Linux 的 Windows 子系统（Windows Subsystem for Linux, WSL）可以简单地理解为在 Windows 上提供了运行 Linux 的平台。由于是 Subsystem ，与裸机装 Linux Distribution 相比，存在功能限制和性能打折的情况。 You can: …… Invoke Windows applications using a Unix-like command-line shell. Invoke GNU/Linux applications on Windows. …… 对于懒得开虚拟机or装双系统 + ECS渣渣级配置 + 非尊贵苹果用户而言， WSL 还是很有吸引力的 (虽然也很多坑。除了对 Linux 本身有需求外，上面提到的 Windows 和 Linux 互相invoke 也很有意思， WSL 因此大大降低了原本配置两个文件系统的繁琐程度。 性能对比 WSL 2 相比 WSL 1，主要优化了访问文件系统的速度以及提供了更完整的系统调用接口。 File system performance Full system call compatibility 架构对比 WSL 1 WSL 1 的大体思路是，在一台 Windows 主机上安装 Linux 发行版本，依赖中间层的驱动器完成 Linux Namespace 和 Windows Kernel 之间的通信捕获和指令翻译（比如 path 和 flag ），作用范围包括但不局限于系统调用、文件系统、权限管理和网络配置等。 这样的设计存在一些缺陷： 某些翻译无可避免地需要付出时空代价，甚至由于两种内核的设计思想存在冲突而无法进行。 由于 Linux Kernel 更新得非常快，单靠 M$ Team 自己实现翻译，开发进度远远滞后于实际生产需求。 【更多详见 👉 WSL从入门到…(2) Dive into WSL 1】 WSL 2 WSL 2 的大体思路是，开启 Hyper-V 功能，Windows Hyper-V Container（包含Windows Kernel和Windows Usermode）持续运行，Linux Hyper-V Container（包含Linux Kernel和Linux Usermode）随用随开，两者通过 Socket 通信。 这样的设计存在一些缺陷： 需要处理器提供虚拟化选项，一些 arm64 架构的芯片不支持该功能。 Windows 开Hyper-V后将无法同时运行 VMware 和 Virtual Box 等工具，因为它们都要求独占 Hypervisor 才能够运行。 虚拟化伴随一系列一致性问题，比如权限管理和网络配置等等。 【更多详见 👉 WSL从入门到…(3) Dive into WSL 2】 Linux Kernel 用 Linux Kernel 是为了解决 WSL 1 的遗留问题（“Uses real Linux kernel for improved performance and perfect compatibility”），翻译不好搞就“拿来主义”。 M$ 甚至为 WSL 2 定制了 Linux Kernel (没想到吧.jpg Virtualization 要使两种内核能够共存最直接的思路就是使用虚拟化技术，而 WSL 2 采用了一种有别于传统虚拟机和新兴容器的新(?)方法 - Lightweight utility VM，其特点是集成度高（关联 Windows 服务）且只在运行时启动（否则被销毁回收）。 相比传统虚拟机，内存占用更小、启动速度更快以及可以同时运行更多实例。 相比新兴容器，基于 Hyper-V 面向 server 场景，本质还是 VM ，隔离得更彻底。 几点总结 根据PM的说法， WSL 1 和 WSL 2 会并行维护，既适用于桌面版也可以运行在服务器。下面简单回顾两者的区别： WSL 1 WSL 2 核心技术 Pico provider drivers Lightweight utility VM 同一实例（Container） ✓ ✗ 额外支持（虚拟化） ✗ ✓ 文件系统 访问慢 访问快 系统调用 缺少 完整 权限管理 相同 不同 网络配置 相同 不同 后续两节将分别再深入介绍 WSL 1 和 WSL 2 的实现细节。那么我先占坑逃了（（（ 参考链接 The new Windows subsystem for Linux architecture: a deep dive Windows Subsystem for Linux Documentation","link":"/2019/12/12/WSL从入门到...(1)/"},{"title":"#Microservice# 阅读《Management of API Gateway Based on Micro-service Architecture》笔记","text":"Zhao, J &amp; Jing, S &amp; Jiang, L. (2018). Management of API Gateway Based on Micro-service Architecture. Journal of Physics: Conference Series. 1087. 032032. 10.1088/1742-6596/1087/3/032032. 目录 Table of Contents 阅读本论文后，主要讨论以下四点： 应用架构图示及分析 身份认证令牌选择 信息加载的热更新解决方案 分布式的流量控制 应用架构 代理服务Nginx 接入层 代理流量的统一入口。 Lua 脚本集 支持扩展各项中间件功能，如：权限认证、负载均衡、流量控制、存储日志、请求重写和反向代理等。与“管理服务-业务逻辑层”的功能相对应。 管理服务API 接入层 管理接口的统一入口。 业务逻辑层 支持扩展各项业务层功能，如：接口配置信息、权限认证管理、流量控制管理、系统状态监控、系统数据统计和请求重写配置等。与“代理服务-Lua 脚本集”的功能相对应。 认证中心 用于提供 OAuth 2 + JWT 认证功能。 注册中心 用于提供服务发现与服务注册功能。 持久层Redis 集群 作分布式限流的计数器； 缓存响应请求结果。 MySQL 集群 主要用于存储流量控制信息。 注：作者没有进一步阐述为什么服务配置信息和流量控制信息要分开不同类型的数据库集群存储。 MongoDB 集群 主要用于存储服务配置信息。 身份认证本文将采用 OAuth 2 + JWT 组合。OAuth 2 引入了认证服务器和资源服务器的概念区分，OAuth 2 协议可以携带用户信息和权限信息的特征；JWT 是包含身份信息和过期时间的加密令牌，以减少数据库的访问。两者结合使用可以实现认证和鉴权。 毕设将采用 JWT 令牌，出于简化的目的去除了 OAuth，更接近原文中所提及的 AppKeys ，也可以基本满足当前的需求。AppKeys 身份认证模式更适合开放服务的场景，它不涉及用户信息和权限信息。 信息加载本文的处理方式是：先从 Nginx Cache 中读，再从 MongoDB 中读，否则判断为非法的请求。Nginx 是自定义网关技术的常见基石；MongoDB 作为文档型数据库在修改服务配置信息上十分方便。 毕设的处理方式是：先从 Redis 中读，再从 MySQL 中读，否则判断为非法的请求。Redis 是一个高性能的内存键值数据库，很适合用作为缓存；MySQL 作为关系型数据库，可以更好地抽象和管理服务信息、访问控制、负载均衡和租户信息等实体关系。 尽管如此，无论哪种方式都亟待去解决以下问题： MongoDB 更新之后如何刷新 Nginx Cache ？MySQL 更新之后如何刷新 Redis ？ 事实上，我们可以对这个问题进行抽象化： 已知：A 服务写多读少，流量小；B 服务只读不写，流量大；C 数据由 A 服务写入数据库，由 A 服务或 B 服务读出数据库。 问题：如何使 A 服务和 B 服务之间保证 C 数据同步且一致（请求不能直接打到底层的数据库）呢？ 进行头脑风暴之后，解决的思路有： 管理服务同步更新代理服务：代理服务提供配置下发接口，管理服务变更时调用该接口，代理服务在内存中重新同步管理服务配置数据。缺点：代理服务和管理服务强耦合；配置下发性能损耗。 管理服务异步更新代理服务：代理服务开启异步定时任务，管理服务直接变更，代理服务在内存中周期同步管理服务配置数据。缺点：数据一致性较差。 MySQL 主从复制实现读写分离：主库写从库读，主库写时要解锁，从库读时不加锁。缺点：请求直接会打到数据库，并发要求可能被满足，但比内存数据库的请求时间会长。 从 MySQL 同步数据至 Redis：增删改 MySQL 时，删除 Redis 对应的记录；查 Redis 时，如果命中立即返回，没有命中查 MySQL 并回写到 Redis。缺点：需要考虑缓存穿透、击穿和雪崩等问题。 引入 RabbitMQ 解耦：观察与订阅的模式，生产者的 MySQL 发生改动时通知消费者的 Redis 也发生改动。缺点：又引进新组件，运维成本进一步地增大。 使用 Consul 作为配置中心：Consul 既可以作为注册中心又可以作为配置中心，是分布式的键值型数据库。缺点：服务配置信息蕴含实体关系映射，不是配置中心的经典使用场景。 流量控制本文中使用 Redis 充当计数器来实现限流，适用于分布式的环境。 毕设中可以采用官方原生库 golang.org/x/time/rate 或滴滴开源库 github.com/didip/tollbooth，仅适用单机版的环境。 显然，考虑到可扩展性，网关会以集群的形式进行部署，分布式限流是更为合理的。 总结 本文提出了一种基于 Nginx + Lua 实现的微服务 API 网关的架构，在身份认证、信息加载和流量控制这三个方面为毕设工作提供了宝贵的参考。 致谢：@lyq大佬和@d师对本文亦有贡献 :D","link":"/2021/04/04/Management of API Gateway Based on Micro-service Architecture/"},{"title":"#Unit Test# Unit Test Pre-study and Practice in Golang","text":"If you write code, write tests. – The Way of Testivus 目录 Table of Contents 背景 单元测试的重要性无需多言，但是由于业务迭代得超快，就很难再分出时间和精力投入到质量保障中去。尽管如此，等待接口联调的过程中既漫长无比又压力山大（毕竟谁想被挂 Tapd Bug 单呢 _(:з」∠)_ 在之前的 Unit Test Pre-study and Practice in Python 文章中，已经简要地介绍了测试流程和测试用例的核心理念，本文将沿用这些方法论以及结合各位大神的博客和日常工作的体验，着重讨论以下内容： 技术选型：Golang 作为一门静态和强类型语言，相比于 Python 的动态和弱类型特性，带来了一些新的挑战。 工程实践：业务逻辑快速验证的最佳实践，暂时不涉及脚手架设计。 技术选型单测框架testing 官方原生库，无断言机制，编写较繁琐。 编写 12345678910111213141516func DoSomething() error { // ...}func TestDoSomething(t *testing.T) { // Arrange // ... // Act err := DoSomething() // Assert if err != nil { t.Errorf(err.Error()) }} 运行 1go test -v GoConvey 兼容官方原生库和模拟框架，有断言机制，编写较简洁。 编写 123456789101112131415161718func DoSomething() error { // ...}func TestDoSomething(t *testing.T) { Convey(\"TestDoSomething\", t, func() { Convey(\"Condition 1\", func() { // Arrange // ... // Act err := DoSomething() // Assert So(err, ShouldBeNil) }) })} 运行 1234# Cmdgo test -v# Web$GOPATH/bin/goconvey 模拟框架GoMonkey Mock 全局变量 &amp; 函数方法 全局变量 12345patches := ApplyFuncVar(&amp;funcVar, mockVar)defer patches.Reset()patches := ApplyGlobalVar(&amp;funcVar, mockVar)defer patches.Reset() 函数方法 123456patches := ApplyFunc(funcName, mockFunc)defer patches.Reset()var ptr *SomeClasspatches := ApplyMethod(reflect.TypeOf(ptr), \"methodName\", mockMethod)defer patches.Reset() GoMock Mock 接口 生成 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// repository.go// Repository is the interface to be mockedtype Repository interface { Create(val interface{}) error Get(key string) (interface{}, error) Update(key string, val interface{}) error Delete(key string) error}// mockgen -source=${file}// mockgen ${package} ${interface1}, ... , ${interfaceN}// mock_repository.go// MockRepository is a mock of Repository interfacetype MockRepository struct { ctrl *gomock.Controller recorder *MockRepositoryMockRecorder}// MockRepositoryMockRecorder is the mock recorder for MockRepositorytype MockRepositoryMockRecorder struct { mock *MockRepository}// NewMockRepository creates a new mock instancefunc NewMockRepository(ctrl *gomock.Controller) *MockRepository { mock := &amp;MockRepository{ctrl: ctrl} mock.recorder = &amp;MockRepositoryMockRecorder{mock} return mock}// EXPECT returns an object that allows the caller to indicate expected usefunc (_m *MockRepository) EXPECT() *MockRepositoryMockRecorder { return _m.recorder}// Create mocks base methodfunc (_m *MockRepository) Create(_param0 []byte) error { // ...}// Get mocks base methodfunc (_m *MockRepository) Get(_param0 string) (interface{}, error) { // ...}// Update mocks base methodfunc (_m *MockRepository) Update(_param0 string, _param1 interface{}) error { // ...}// Delete mocks base methodfunc (_m *MockRepository) Delete(_param0 string) error { // ...} 使用 12345678910ctrl := gomock.NewController(t)defer ctrl.Finish()mockRepo := mock_repo.NewMockRepository(ctrl)InOrder ( createCall := mockRepo.EXPECT().Create(mockVal).Return(mockErr) getCall := mockRepo.EXPECT().Get(mockKey).Return(mockVal, mockErr).Times(7) updateCall := mockRepo.EXPECT().Update(mockKey, mockVal).Return(mockErr) deleteCall := mockRepo.EXPECT().Create(mockKey).Return(mockErr)) sqlmock Mock 数据库 12345678910111213141516// Arrangedb, mock, err := sqlmock.New()defer db.Close()rows := sqlmock.NewRows(colKeys).AddRow(colVals)mock.ExpectQuery(sqlStatement).WillReturnRows(rows)// Actres, err := db.Query(sqlStatement)defer res.Close()// Assertfor res.Next() { res.Scan(&amp;fileds) // ...} httptest Mock 服务器 12345678910// Arranger := httptest.NewRequest(method, url, nil)w := httptest.NewRecorder()// Acthandler(w, r)// Assertres := w.Result()// ... 工程实践 to be continued… 总结 单测框架用于断言：使用 GoConvey 框架。 模拟框架用于替换：对于全局变量和函数方法使用 GoMonkey 框架，对于接口使用 GoMock 框架，对于数据库使用 sqlmock 框架，对于服务器使用 httptest 框架。 参考链接 以下文章对本文亦有贡献 :) 单元测试成神之路——Golang篇 Golang单元测试调研和实践 附录 使用文档和最佳实践 :) testing的更多用法 GoConvey的更多用法 GoMonkey的更多用法 GoMock的更多用法 sqlmock的更多用法 httptest的更多用法","link":"/2021/08/16/Unit Test Pre-study and Practice in Golang/"},{"title":"#WSL# WSL从入门到...(3) Dive into WSL 2","text":"对 WSL 2 的一些实现细节进行补充说明，主要分为以下五个部分： 前情提要 背景 架构与答疑 总结 参考链接 目录 Table of Contents 前情提要 前面已经简要介绍了 WSL 1 和 WSL 2 的区别，本节将聚焦于 WSL 2的实现细节。点开官方博客开始收获惊(da)喜(keng)，才疏学浅写错也不要打我 (预先感谢各位勘误 逃 【更多信息 👉 WSL从入门到…(1) WSL 1 vs WSL 2】 背景功能 …… still provides the same user experience as in WSL 1 (the current widely available version). 性能 Its primary goals are to increase file system performance, as well as adding full system call compatibility. 兼容 Individual Linux distros can be run either as a WSL 1 distro, or as a WSL 2 distro, can be upgraded or downgraded at any time, and you can run WSL 1 and WSL 2 distros side by side. 架构 工作流大概是： 启动 LXSS Manager Service 跟踪 Linux Distribution 的安装、运行和卸载。 启动 Host compute service 和 Host Network Service 创建和初始化 Lightweight utility VM 实例。 被封装好的（“shipping in box”）基于 Linux Kernel 的虚拟机运行。 LXSS Manager Service 映射、加载和管理 Linux Distribution 的文件系统。 以上准备工作完成后，wsl.exe 和 bash 之间将通过 socket 传递指令来完成作业。 PS: Lightweight utility VM 只会在需要时创建运行，如果 bash 或 wsl.exe 退出，一段时间后将会被回收。 访问 Windows 文件 Windows 主机启动一个文件服务器，此时 Linux 作为客户端发送请求，两者使用 9P 协议进行通信。 效果看起来像把 Windows 的 C 盘挂载到了 Linux 的 /mnt 目录下。访问 Linux 的 /mnt/c 就是在 访问 Window 的 C:\\ 。 PS: 特别地，如果在 bash 内启动 cmd.exe ，由于 Windows 和 Linux 的可执行文件格式不同（前者是 PE 或 PE32+ ，后者是 ELF32 或 ELF64），.exe 文件无法直接运行。WSL 2 的处理方法实际上是：Linux 下的 bash 向 wsl.exe 发送 Interop command，Windows 下的 wsl.exe 解析后启动 .exe 文件。 访问 Linux 文件 Linux 虚拟机启动一个文件服务器，此时 Windows 作为客户端发送请求，两者使用 9P 协议进行通信。 效果看起来像在 Windows 上开一般的虚拟机，对应的目录（在 Network 内）可以被文件资源管理器轻松地访问。 PS: 从上述中可见，WSL 2 访问文件的中心观点 —— “两个系统都做各自可以做 / 擅长做的事情，遇事不决就通过socket发指令吱一声，而不会选择简单粗暴地翻译。” 答疑 Q1: Microsoft 的 Linux Team 根据 WSL 2 针对 Linux Kernel 做了哪些调整？ A1: 首先，和 WSL 1 一样，WSL 2 本身并不提供 Linux 发行版本，用户需自行前往 Windows Store 下载或脚本安装自定义的发行版本；其次，WSL 2 的 Linux Kernel 基于稳定的 version 4.19，并在启动时间、内存占用和需支持设备数等方面都进行了相应的优化；最后， WSL 2 将通过 Windows 更新来推送新服务，并由 Microsoft 及其它专业的商业伙伴提供安全监控和保障。 Q2: 可以在虚拟机中使用 WSL 2 吗？ A2: 可以，但要确保开启 nested virtualization 选项（在 Windows PowerShell （以管理员身份运行）中输入 Set-VMProcessor -VMName &lt;VMName&gt; -ExposeVirtualizationExtensions $true 命令）。 Q3: WSL 1 中的配置文件 wsl.conf 在 WSL 2 中仍可以使用吗？ A3: 可以，比如自动挂载磁盘、开启或关闭 interop command和更改挂载目录等操作都将继续支持，更多 WSL 配置项可见 Distro Management 。 Q4: WSL 2 将支持 Docker 技术，WSL 2 的 Docker 会有什么特别的限制吗？ A4: 如果启动的是 Windows 的 Docker ，将按照 Window 的 Docker 工作；如果启动的是 Linux 的 Docker ，将按照 Linux 的 Docker 工作。尽管 Windows 的 Docker 和 Linux 的 Docker 实现方式有所出入（由于篇幅有限，将不展开说明），但原则上 WSL 2 不存在对 Docker 的特别限制。 Q5: 有没有针对 WSL 2 的硬件支持，比如访问并加速GPU并之类？ A5: 暂未完善，但持续开发中（但 WSL 1 支持串行端口和USB设备的访问，有需要可以先凑合用）。 Q6: 有没有统一 Windows 文件和 Linux 文件权限管理的解决方案？ A6: 在 WSL 1 中，因为是同一主机不存在系统边界（映射相对容易），权限管理是通过中间层的驱动器提供额外服务实现的；在 WSL 2 中，因为是不同主机而存在系统边界（映射相对困难），WSL 2 采取的策略是保持各自系统原有的访问权限，通过补充一些上层协议（比如 SSH）进行辅助管理，新的 Release 版本已经支持 “Sharing SSH keys between Windows and WSL 2“。 Q7: 有没有 WSL 2 对网络配置的支持？ A7: 在 WSL 1 中，因为是同一主机，网络出口的 IP 地址是相同的，相关操作也接近原生 ；在 WSL 2 中，因为是不同主机，网络出口的 IP 地址是不同的，WSL 2 计划实现的 Feature 包括：① 在提供不同的IP 地址情景下，加速网络访问；② 将客机映射到主机，共享同一 IP 地址；③ 尽快支持全部 Linux 下的网络应用。 总结 简单的理解：通过使用虚拟化技术，使得 Hypervisor 上同时运行 Windows 实例和 Linux 实例，Windows 实例占主导地位并且持续地运行，Linux 实例非常轻量级并且只有在用到时才会启动。采用原生的 Linux Kernel 保证了系统调用的完整性，9P 协议的注入又很好地解决了两个不同文件系统之间的交互问题。 参考链接 The new Windows subsystem for Linux architecture: a deep dive About WSL 2 Shipping a Linux Kernel with Windows WSL 2 Frequently Asked Questions","link":"/2019/12/14/WSL从入门到...(3)/"},{"title":"#Sucks# 写在二零二壹","text":"（（（假装有简介.jpg 过去的一年其实还蛮糟糕的（或者说下半年，但是也发生了很多美好的事情。因为很长一段时间都不写作了，感觉到既遗憾又气愤，所以这不会是一篇好随感，索性就像每日面对的客体一样，整齐划一地理清我的思绪。 2020 糟糕的事情： 做了一些无用功，并且最后也处理得不好 工作的时候学习变得零碎，休息的时候缺乏学习热情 身体感觉不好，作息不够规律，职业病少运动，摄入过多酒精 对事物开始冷感，不阅读不写作 工作的时候很自闭，休息的时候很肥宅 最近有点本末倒置，害怕看到了尽头 感觉自己有点病了，失去了生命力 2020 美好的事情： 王小葵和王银河 春招的 offer 收割机（bushi，对自己的一点点的肯定 拿到了满意的 offer，妈宝的胜利（逃 开始学习理财知识，一场有趣的游戏 总的来说，我讨厌 2020 原地踏步甚至拼命倒退的自己，并且这种想法还会越来越少，自己也不愿意走出舒适圈。与此同时，我感到灵魂中，已经少了许多纯粹，反而添了许多欲望。2021 希望自己健健康康、开开心心。 2021 Todo List： 重视身体情况，早睡早起，晚上回来可以做做运动，养生 午休前和睡觉前都可以读读书，多看电影多听新歌，坚持写日记 养成每天开始工作前关注新技术，结束工作后总结这一天的好习惯 周末要出去走走，要学习知识 工作时间不要分心其它事情，做好时间管理 和别人交往善良和热情，如果需要练习那么就去练习，但也要有自己的原则 不要拖延，想就去做，每天记录自己好的变化 希望新的一年除了工作以外，有一些新的关注点 Hope is a dangerous thing for a woman like me to have. Fake it till you make it.","link":"/2021/01/01/写在二零二壹/"},{"title":"#Arch# 企微客服号后台开发小结","text":"本文将介绍一种通用的企微客服号后台设计与实现的方案（仍在改进ing… 前言 企业微信开放了机器人和客服号两种方式对会话进行自定义的功能扩展，本文将介绍一种通用的企微客服号后台设计与实现的方案（仍在改进ing… 需要注意的是如何注册申请以及相关接口规范不在本次的讨论范围中。最终 wework-service 应该具备两种通用能力： 对于企微用户而言：响应多种模式指令，执行指定业务逻辑。 对于其它服务而言：提供原生or聚合的调用企微接口操作。 整体设计逻辑架构 wework-service 内部实现采用的是洋葱模型，通过 gin 框架的中间件灵活集成各类插件，包括：消息解析中间件（decrypt XML）、崩溃恢复中间件（panic recover）、日志记录中间件（log request）、流量控制中间件（rate limit）、权限认证中间件（rbac auth）和消息处理控制器（handle controller）。 wework-service 外部依赖主要有微服务和数据库。其它微服务绑定响应的逻辑，数据库主要用于存储流量控制和权限认证的相关配置，缓存主要避免企微对令牌的获取限流。 调用关系用户交互 Step 1：企微用户与客服号进行单聊or群聊会话，发送文本or混编消息，包含了指令本身和业务数据。 Step 2-3：加密消息从客服号回调到 wework-service，此时为了避免重试应该及时返回空包。 Step 4-6：进行消息解析、流量控制、权限认证和消息处理。 Step 7-9：消息流转到具体的处理策略当中，通过驱动与 other-service 和企微后台进行交互。 Step 10-11：企微后台直接通过客服号将结果发送给企微用户。 服务交互 Step 1：other-serivce 先自行进行业务的处理 Step 2-3：other-serivce 请求 wework-serivce 操作企微后台 Step 4-5：企微后台直接通过客服号将结果发送给企微用户。 组件设计消息解析中间件 加解密工具库：https://github.com/sbzhu/weworkapi_golang 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// ParseCallbackMessage verify, decrypt and unmarshal wework callback requestfunc ParseCallbackMessage(query *model.WeworkCallbackQueryModel, body []byte) (*model.WeworkXMLRecvMsg, error) { var err error // verify and decrypt weworkSvcToken := app.GetConfig().WeworkSvcToken weworkSvcEncodingAESKey := app.GetConfig().WeworkSvcEncodingAESKey crypt := wxbizmsgcrypt.NewWXBizMsgCrypt(weworkSvcToken, weworkSvcEncodingAESKey, \"\", wxbizmsgcrypt.XmlType) bts, cryptErr := crypt.DecryptMsg(query.MsgSignature, query.Timestamp, query.Nonce, body) if cryptErr != nil { err = fmt.Errorf(\"verify and decrypt wework callback request failed: %s\", cryptErr.ErrMsg) return nil, err } // unmarshal xml data recv := &amp;model.WeworkXMLRecv{} unmarshalErr := xml.Unmarshal(bts, recv) if unmarshalErr != nil { err = fmt.Errorf(\"unmarshal xml data of wework callback request failed: %s\", unmarshalErr.Error()) return nil, err } logrus.Debugf(\"WeworkXMLRecvMsg: %+v\", recv.Msg) // better log in middleware return &amp;recv.Msg, nil}// MessageParserMiddleware middleware to parse callback messagefunc MessageParserMiddleware() gin.HandlerFunc { return func(ctx *gin.Context) { var query model.WeworkCallbackQueryModel if err := ctx.ShouldBindQuery(&amp;query); err != nil { logrus.Errorf(err.Error()) ctx.JSON(http.StatusOK, nil) ctx.Abort() return } body, err := ioutil.ReadAll(ctx.Request.Body) if err != nil { logrus.Errorf(err.Error()) ctx.JSON(http.StatusOK, nil) ctx.Abort() return } msg, err := ParseCallbackMessage(&amp;query, body) if err != nil { logrus.Errorf(err.Error()) ctx.JSON(http.StatusOK, nil) ctx.Abort() return } ctx.Set(\"msg\", msg) ctx.Next() }} 权限认证中间件 to be continue… 流量控制中间件 to be continue… 消息回调控制器 工厂模式 CallStrategyFactory 主要解决多种匹配模式和消息格式问题，以支持通过单聊or群聊和文本or混编的方式响应。getTriggerAndDataFromText 和 getTriggerFromMixedMessage/getMediaIdAndPicUrlFromMixedMessage 解决匹配模式问题，TextStrategyFactory 和 MixedMessageFactory 类解决消息格式问题。 1234// CallbackStrategyFactorytype CallbackStrategyFactory interface { ProduceStrategy(*trigger.Config, *model.WeworkXMLRecvMsg) strategy.CallbackStrategy} 策略模式 所有策略必须实现 CallbackStrategy.Handle(CallbackContext)，换言之定义策略实现了这个接口就可在工厂中注册，投入实际使用，这样非常灵活。这里辨析一点：Handle 传入参数 ctx 指的是完整的消息（包含发送主体和内容），而 Strategy 固有数据成员则往往仅代表业务数据（可以是紧跟在指令后的文本或图片）。 1234// CallbackStrategytype CallbackStrategy interface { Handle(ctx *context.CallbackContext)} 注意缓存令牌 由于企微后台对获取令牌的接口做了限流保护，如果每次经 wework-service 的流量都要调用一次接口获取令牌，当流量过大时会影响到 wework-service 的正常工作，考虑到令牌有过期时间，实际上也没必要每次都直接请求。我们可以多加一层缓存，避免被限流了同时提高响应速度。 避免重试 由于企微的客服号在回调后若未及时收到空包，将会在短时间内做持续重试。这种情况必须考虑，否则消息将会重复消费以及增加后台处理负荷。 方法一：接收和处理的逻辑分离，亦即同步接收异步处理。这里需要注意的点：错误处理不能再以直接返回的方式做，需要写进日志，必要时还可以消息通知用户。这是一种积极避免重试的手段（防患于未然）。 方法二：消息 id 去重，使用缓存记录一定周期内的所有消息编号，并且设置过期时间，对重复的消息直接忽略不做处理。这是一种悲观避免重试的手段（来之则安之）。 参考文献 企业微信内部服务号CI助手开发总结 企业微信客服服务号开发小记 企业微信内部客服号开发小结 从零开始搭建你的企业微信客服服务号","link":"/2021/08/28/企微客服号后台开发小结/"},{"title":"#Sucks# 写在二零二零","text":"（（（无聊的吐槽与没多少意思的复读 生活大概就是，起落落落。 说来写前端也快一个月，虽然以后大概率也不会再专门帮别人写了，但是这个过程还是有不少心得体会，比如理解需求、读懂架构、实现逻辑、保证质量和通过测试之类的。因为开发得比较随心所欲，换句话说，就是还有很多成长的空间，非常感谢实验室的师兄师姐没有嫌弃我这个小菜🐓，黄老师还即将迎来人生第一桶金 (?) 要说后悔到印象深刻的事情，除了在GY咕咕掉了信息竞赛，选大数据可能也是之一。无非就是不会也不那么感兴趣，每次先被数据处理套路一阵，然后对着数学公式和神经网络敲敲敲，Debug没有机器也要来个地久天长，还要盯着AB榜患得患失，实在是搞不来啦。虽然但是，学算法这半年来最大的收获就是学会如何心平气和地把一件事情真正做得又快又好（我却还没有 过去一年搞了不少副业，真正有营养的却不多，从C++写到Dart，从全栈写到云计算…明白一个人的精力其实很有限，什么都干 ≈ 什么都没干。就算开了n个repo，混了n个project，挂了n个title，只要面对 Talk is cheap, show me the code 也会沉默。当然广度优先学习也没什么不好，只不过是我算力太弱了罢。到了三年级就不可避免地想东想西，不能再像从前一样说干就干，要考虑沉没成本，要面对同伴焦虑，决定去哪搬砖也要小心翼翼，还随时在敏捷和投机的边缘试探。最后说服了自己还是保持刮刮乐的心态…（刮到了云计算还挺幸运的 误 虽然以上都是些无关痛痒的吐槽，生活也还有它的复杂和美好，诸如和很长一段时间被gaslight的自己和解啦、第一次当PM啦、去M$RA蹭吃蹭喝啦、再见好X友发展革命情谊啦、无疾而终地暗恋过啦云云，这种时候还是要感慨年轻真好滴嘻嘻 :P 以前觉得生活本质就是和西西弗斯神话一样的，相当虚无。现在也还是这么觉得，不过直觉上有趣的事情那么多，每天一点点也足够快乐。一般来说，新年之交讲的东西都不能信，就不继续一本正经胡说八道了，最后以小波作结吧： “那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想再一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。”","link":"/2020/01/01/写在二零二零/"},{"title":"#Others# 和新项目相爱相杀","text":"夸张的修辞手法.jpg（（（ Happy 7*24 Day 🤟 前言 来你🐧正式打工不知不觉已经十天了，比起实习的时候工作内容已经大有不同，再见已是工具人小黄bot（此工具人非彼工具人thx。 今天主要记录一下理解和熟悉新项目的过程，希望在未来接触新业务也会有所帮助。 前置条件 本人司职 Golang 后台开发，下面内容仅供参考。 编程语言 Golang：业务开发的主要语言 Shell：工具运维的主要语言 基础知识 Git、Linux 云原生、高并发、分布式、微服务 算法分析、数据结构 计算机网络、操作系统、数据库概论 设计模式、软件架构 敏捷开发、项目管理 开发框架 gin：基于 API go-micro：基于微服务 数据库操作及驱动 MySQL：关系型数据库 MongoDB：文档型数据库 Redis：键值型数据库 其它的中间件 消息队列 注册中心 相关系统 upstream：对接内部产品 downstream：前端项目 迭代流程 Unit Test、Mock Test Coding Standard CI / CD 需求分析 需求分析阶段主要是从需求层面来了解项目，知道项目在做什么。 可用资产 产品手册 产品原型 需求文档 阶段目标 理解和区分关键的领域概念 明确产品的主要功能和主要流程 方案设计 方案设计阶段主要是从方案层面来解构项目，思考项目该怎么做。 可用资产 技术文档 接口文档 数据库表 阶段目标 整理项目的整体设计（项目本身），包括功能、架构和流程 整理项目的局部设计（对应特定场景的具体解决方案），包括功能、架构和流程 了解接口文档（dto）如何与业务相结合起来 了解数据库表（po）如何与业务相结合起来 代码实现 代码实现阶段主要是从代码层面来落实项目，有依据地搞好细节。 可用资产 项目代码 阶段目标 梳理项目代码层次，比如 router、api controller/cron job/message queue、service、dao/driver 等等 对应需求和方案，从 api controller/cron job/message queue 来入手，巩固理解业务，了解实现细节 遇到复杂且核心的代码，可画流程图等专门记录和分析 模拟开发 模拟开发阶段主要是从实践层面来运行项目，过一遍工作的流程。 可用资产 项目代码 环境信息 阶段目标 本地和远程可以跑通项目代码 熟悉完整的开发流程：编写文档 → 生成代码 → 业务开发 → 单元测试 → 代码规范 → 提交代码 → 代码评审 → 合入代码 → 代码打包 → 部署 → 测试 代码重构 代码重构阶段主要是从理想层面来优化项目，提升自己和新项目。 可用资产 项目代码 阶段目标 学习或改进项目代码，大到架构模式，小到算法结构，同时也要关注代码规范 致谢 感谢晓清哥成为我的伯乐，让我有机会在喜欢的地方做喜欢的事情，在工作中和生活上也给了我很多鼓励；感谢风哥在我回来之后依然让我觉得对这里很有归属感，风哥也会一直是我的榜样（in every aspect；感谢远哥，亦师亦友，为全世界坠好的 mentor 打 call；感谢各位不嫌弃我菜的同事，有你们在，有风哥选的 Macbook Pro，有智神送的 Windows，每天到了工位都觉得这一刻一定要为 HK0700 卖命（bushi。 上一次分别时，其实自己感到蛮有压力，一方面担心要被炒鱿鱼了（现在也，另一方面是因为有偶像包袱（xs开始给自己加戏。但是无论如何地说，我最应该做的就是——好好工作。在热爱的事业里实现价值（我最好是，同时也希望大家因为我的存在而感到开心（一丢丢也行，btw愿下一次没有分别 :)","link":"/2021/07/24/和新项目相爱相杀/"},{"title":"#Microservice# 阅读《基于 OpenResty 平台的 API 网关系统的设计与实现》笔记","text":"温馨,樊婧雯,王富强.基于OpenResty平台的API网关系统的设计与实现[J].信息化研究,2020,46(03):62-68. 目录 Table of Contents 阅读本论文后，主要讨论以下两点： API 网关设计 API 网关实现 API 网关设计 API网关软件 读多，实现安全认证、流量控制、请求重写、反向代理、负载均衡和结果缓存等功能。 API网关监控管理中心 写多，实现服务配置、日志管理、系统监控、API管理等功能。 注：为实现数据的读写分离，提高网关的性能，网关不进行数据处理操作，数据处理由监控管理中心负责。 持久层 Redis：缓存配置和结果、分布式限流等 MongoDB：存储核心层的数据 MySQL：存储管理层和监控层的数据 Zookeeper：服务发现与服务注册 注：由于作者对数据同步和消息订阅没有详细展开讨论，个人直观感觉设计得有点过复杂了。 本文的架构设计会涉及三次数据同步和消息订阅，一是 Zookeeper 和 MySQL 之间，二是 MySQL 和 MongoDB 之间，三是 MongoDB 和 Redis 之间。毕设的架构设计只涉及一次数据同步和消息订阅，即为 MySQL 和 Redis 之间。 引入 Zookeeper 实现服务注册与服务发现，不可简化；MySQL 和 MongoDB 之间可以二者选一，MySQL 提供很好的事务性支持，MongoDB 更快速和易用，两者备份都有较成熟的方案；Redis 需要用作缓存与限流，不可简化。 Zookeeper 和 MySQL 之间可不同步，因为配置间有实体映射关系；MySQL 和 Redis 之间必须同步，以提高网关访问性能和实现配置热更新。 API 网关实现 流量控制 使用 Redis 作为全局的分布式计数器。 业务层面，设周期为 t 和 阈值为 d，则 TPS 为 d/t；技术层面，Redis 创建一个存储访问的键，设置过期时间为 t，当值达到 d 则触发自动告警或熔断降级。 服务兜底 与流量控制相结合，保证上游的数据服务永不消失。 两种实现方式：一是触发限流后请求重定向到 fallback 过程中处理，可以主动发起二次请求获取兜底数据，这种做法需引入额外的回调逻辑，但数据和后端服务是保持一致的；二是从缓存中读取响应数据，这种做法不能保证数据一致，但是速度快且改动小。 总结 本文提出了一种基于 OpenResty 实现的微服务 API 网关的架构，在拆分服务、数据库的选型、数据同步和消息订阅这三个方面为毕设工作提供了宝贵的参考。","link":"/2021/04/05/基于 OpenResty 平台的 API 网关系统的设计与实现/"},{"title":"#Microservice# 微服务API网关的设计与实现(1) 需求分析","text":"本文主要介绍微服务API网关的需求分析，分为两个方面： 功能性需求分析 - 用例图和用例表 非功能性需求分析 目录 Table of Contents UML用例图 用例图一般由参与者、用例、系统边界和关系构成。 关系类型 元素 说明 条件性 直接性 箭头指向 关联 参与者与用例之间的关系 参与者和用例通信 - - 发送方指向接受方 泛化 参与者之间或用例之间的关系 子元素继承父元素 无 直接 子元素指向父元素 包含 用例之间的关系 复杂用例拆成简单用例 无 间接 复杂用例指向简单用例 扩展 用例之间的关系 基础用例增加附加用例 有 直接 基础用例指向附加用例 用例表 用例表一般由用例编号、用例名称、参与者、用例描述、前置条件、后置条件、正常流程和异常流程构成。 条目 内容 用例编号 [数字] 用例名称 [动宾结构] 参与者 [主语] 用例描述 [相互独立；可以观测] 前置条件 [分点说明] 后置条件 [分点说明] 正常流程 [正常操作→正常结果] 异常流程 [异常操作→异常结果] 功能性需求分析微服务API网关管理模块用例 下图为微服务API网关管理模块的用例图，其展示了在管理模块中，管理员用户作为参与者与用例之间的关系以及主用例和子用例之间的关系。根据分析，管理模块共有6个主要的用例，分别为用户登录、用户登出、管理用户、管理服务、管理应用和数据统计。 微服务API网关核心模块用例 下图为微服务API网关核心模块的用例图，其展示了在核心模块中，普通用户作为参与者与用例之间的关系以及主用例和子用例之间的关系。根据分析，核心模块共有7个主要的用例，分别为协议接入、权限认证、流量统计、流量控制、请求重写、负载均衡和反向代理。 非功能性需求分析 安全性 对于用户操作而言：应用口令安全要求和会话超时机制 对于请求访问而言：设置 JWT 校验和 IP 校验 对于数据传输而言：启动 HTTPS 监听 对于数据保存而言：敏感信息使用盐值加密并以密文方式入库 高性能 选用性能表现优秀、功能支持齐全的框架 Gin 先访问缓存 Redis 代替直接访问数据库 MySQL 高可用 故障时仍稳定服务：进行多实例部署，周期探活并故障重启 容易横向扩展实例：弹性伸缩&amp;&amp;负载均衡 易用性 统一的 RESTful API 接口 直观的 Vue-Element-Admin 界面 FAQs Q：如何控制用例的粒度呢？ A：参考用例的类型与粒度 Refs UML系列-用例图 谈谈需求的描述-用例","link":"/2021/06/01/微服务API网关的设计与实现(1)/"},{"title":"#Microservice# 微服务API网关的设计与实现(2) 整体设计","text":"本文主要介绍微服务API网关的整体设计，分为两个方面： 逻辑架构 调用关系 目录 Table of Contents 逻辑架构 下图是微服务API网关的整体逻辑架构图，展示了微服务API网关的组成部分和逻辑功能。微服务API网关由管理模块和核心模块两个微服务提供主要功能，同时还依赖服务注册与服务发现中心提供服务的注册和发现，以及数据库层提供数据的缓存和持久化。 微服务API网关管理模块，内置了UI界面层提供可视化的管理平台，请求经由API接口层可以访问用户登录、用户登出、管理服务、管理应用、管理用户和数据统计等功能，实现一站式的网关配置管理。 微服务API网关核心模块，由协议接入中间件识别请求和匹配配置，权限认证、请求重写、流量统计和流量控制中间件进行公共业务逻辑处理，负载均衡中间件从服务注册与服务发现中心发现可用服务列表并应用负载均衡算法找出合适的响应实例，反向代理根据负载均衡地址将请求转发至服务端服务并返回响应给客户端应用。 服务注册与服务发现中心，技术选型为开箱即用的 Consul，主要提供服务注册和服务发现的功能。对服务端服务而言，提供服务注册的统一存储位置，保存服务的名称、地址、端口和标签等元数据信息，还可以对已注册的服务进行自定义的周期性健康检查。对于微服务API网关而言，负载均衡中间件可以根据服务名发现可用的服务实例地址，并动态监听这些地址的可用情况和状态变化，及时更新负载均衡的地址列表。 数据库层，包括 MySQL 关系型数据库和 Redis 非关系型数据库。MySQL 用于持久化用户、服务和应用的信息，是业务数据存放的位置和缓存数据同步的来源。Redis 用作缓存和计数器，加快微服务API网关处理客户端应用请求的速度，实现系统流量的统计和监控，并根据策略控制流量的进出。 调用关系 下图是微服务API网关的整体调用关系图，展示了微服务API网关各模块及其依赖作为一个整体如何与客户端和服务端进行交互的过程。其中客户端由管理员用户、Web/App 应用组成，微服务API网关由管理模块、核心模块、MySQL、Redis 和 Consul 组成，服务端由微服务组成。 第1步，服务端的微服务先在服务注册与服务发现中心 Consul 中注册该微服务的名称和地址。 第2步，客户端的管理员用户在管理模块中配置服务和应用。 第3步，配置成功写入 MySQL 关系型数据库和 Redis 非关系型数据库中。 第4步，客户端的 Web 应用或 App 应用即可通过核心模块请求服务端的微服务。 第5步，核心模块在 Redis 缓存中读取服务和应用的配置。 第6步，核心模块在服务注册与服务发现中心 Consul 中获取可用的地址列表。 第7步，经过核心模块的一系列公共业务逻辑中间件处理后，请求被反向代理到已注册的微服务，服务端的微服务接收到请求并处理后返回响应给核心模块，核心模块再返回响应给客户端的应用。","link":"/2021/06/02/微服务API网关的设计与实现(2)/"},{"title":"#Microservice# 微服务API网关的设计与实现(3) 微服务设计","text":"本文主要介绍微服务API网关的微服务设计，分为两个方面： 微服务API网关管理模块设计 - 时序图 微服务API网关核心模块设计 - 时序图 目录 Table of Contents UML 时序图一般由角色、对象、生命线、控制焦点、消息和组合片段构成。 控制焦点 控制焦点是时序图中表示时间段的符号，在此时间段内对象将执行相应的操作。 消息 消息类型 说明 同步消息 发送者同步调用接收者，两者顺序工作 异步消息 发送者异步调用接收者，两者并发工作 返回消息 从调用中返回结果 自联消息 调用对象自身方法 组合片段 组合类型 说明 Alternative Fragment (alt) 相当于 if-else Option Fragment (opt) 相当于 switch-case Parallel Fragment (par) 相当于 go Loop Fragment (loop) 相当于 for 微服务API网关管理模块设计架构图 下图是微服务API网关管理模块的架构图，微服务API网关管理模块的内部逻辑是典型的MVC模式，由 UI 层、Router 层、Controller 层和 Dao 层组成。 UI 层即前端可视化的管理平台界面，前端代码被编译打包后，将静态托管于管理模块中。 Router 层对外暴露API接口，定义了API的请求方法和访问路径，编排了所应用的中间件的类型和顺序。 Controller 层是具体实现业务逻辑的层次，在该层次进行用户登录、用户登出、管理用户、管理服务、管理应用和数据统计功能的编写。 Dao 层作为数据库驱动层直接对接不同类型的数据库，管理模块支持对 MySQL 和 Redis 进行操作。 UI 层和 Router 层之间主要传输 json 数据，统一了前后端的数据传输格式；Router 层和 Controller 层之间主要传输程序定义的 dto (数据传输对象) 结构体；Controller 层和 Dao 层之间主要传输程序定义的 po (持久化对象) 结构体。 时序图 下图是微服务API网关管理模块的时序图，来描述管理员用户如何通过管理模块进行登录登出和各项配置管理。 第1步到第2步，管理员用户需要输入用户名称和用户密码登录，此时登录生成的会话信息将保存到 Redis ，以便保持一定时间内的登录状态。 第3步到第5步，管理员用户添加、修改或删除配置，配置的变更将会分别存入到 MySQL 和 Redis 中。 第6步到第12步，管理员用户查询配置，若缓存命中则直接从 Redis 中读取配置的缓存数据，若缓存未命中则会从 MySQL 中读取配置的数据库数据，并将配置回写到 Redis 缓存中，然后返回配置给管理员用户。 第13步到第14步，当管理员用户登出时，管理模块将删除 Redis 中对应的会话信息，此后该管理员用户的登录状态不再保持，可以选择重新登录或者切换账户登录。 微服务API网关核心模块设计架构图 下图是微服务API网关核心模块的架构图，微服务API网关核心模块由多个中间件以洋葱模型的形式组织起来，并与 Redis 和 Consul 结合使用，为不同形态的客户端提供多协议的后台服务统一入口。 App 应用或 Web 应用发起请求，在核心模块中经过协议接入、权限认证、流量统计、流量控制、请求重写、负载均衡和反向代理中间件的处理，最终到达后台的 HTTP 服务、HTTPS 服务或 WebSocket 服务。 其中，后台的服务应预先配置好服务和应用的配置，方便核心模块的协议接入中间件和权限认证中间件读取服务和应用的配置进而处理后续的业务逻辑。同时，后台的服务也应先在 Consul 中注册服务名称和地址，方便核心模块的负载均衡中间件发现服务地址，根据权重列表设置和负载均衡算法合理分发流量，最后交由反向代理中间件去访问实际的后台服务。 特别地，在核心模块中应该保持对服务地址变化的监听，Consul 也有必要周期性对后台服务进行健康检查，保证服务的可用性。 时序图 下图是微服务API网关核心模块的时序图，来说明应用如何通过核心模块进行公共逻辑处理和请求代理转发。 第1步，应用发起请求。 第2步到第7步，核心模块先向 Redis 缓存查询服务配置进行协议接入，然后查询应用配置进行权限认证。 第8步到第11步，进行流量统计和流量控制，并回写入 Redis。 第12步，根据规则进行请求重写。 第13步到第15步，根据服务发现获取的地址列表以及预先配置的权重列表应用指定的负载均衡算法选出访问地址。 第16步到第18步，核心模块使用负载均衡地址反向代理访问后台服务，并将响应返回给应用。 FAQs Q：并行和异步如何用时序图来表示？ A：首先确定触发的时间点，接着判断是否并行，最后判断是否异步 Refs UML建模之时序图（Sequence Diagram） 序列图(Sequence Diagram)::并行区/临界区 序列图(Sequence Diagram)::同步/异步","link":"/2021/06/03/微服务API网关的设计与实现(3)/"},{"title":"#Microservice# 阅读《微服务API网关的设计及应用》笔记","text":"廖俊杰,陶智勇.微服务API网关的设计及应用[J].自动化技术与应用,2019,38(08):85-88. 目录 Table of Contents 总结 本文提出了一种基于 Spring Cloud Zuul 实现的微服务 API 网关的应用，侧重关注基于 Zuul 的实践使用而不是基于 Zuul 的二次设计，在技术栈的使用上也存在不同，故对毕设工作的帮助较少。","link":"/2021/04/06/微服务API网关的设计及应用/"},{"title":"#Microservice# 微服务API网关的设计与实现(5) 容器部署","text":"本文主要介绍微服务API网关的容器部署，分为三个方面： Golang 交叉编译 Docker 镜像构建 Kubernetes 容器编排 目录 Table of Contents Golang交叉编译 Golang 支持交叉编译，即在当前的操作系统和体系架构上生成指定的操作系统和体系架构的可执行程序。微服务API网关预先采取 Golang 交叉编译出于两点考虑：一是提前在开发环境中编译程序比之后在镜像构建中编译程序的速度要更加快；二是开发环境和部署环境的操作系统不同，可执行的二进制文件必须经过交叉编译才能正常运行。 1234567891011# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/docker/cross_compile.sh# set go envexport GO111MODULE=autoexport GOPROXY=https://goproxy.io,directgo mod tidy# build binary executablemkdir -p ./binGOOS=linux GOARCH=amd64 go build -o ./bin/giotto_gateway_core 先设置 Golang 打开 Go Module 模式并下载程序的模块依赖，再定义目标的操作系统和体系架构开始交叉编译。 Docker镜像构建 Docker 是一个通过管理 Linux 容器来实现应用环境隔离的开源容器引擎，它提供了一整套完备且易用的容器管理接口。微服务API网关的管理模块和核心模块两个微服务将使用 Docker 构建镜像，实现更快的程序部署和更低的计算开销。 12345678910# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/docker/DockerfileFROM golangMAINTAINER LotteWong &lt;lottewong21@gmail.com&gt;WORKDIR /go/src/appCOPY . .CMD ./bin/giotto_gateway_core -config ./configs/prod/ 先拉取基础镜像 golang，再定义容器内的工作目录为 /go/src/app，接着将主机的源文件拷贝进容器中，最后命令行启动微服务。 123456# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/docker/cross_compile.sh# build docker imagescommit=`git rev-parse --short HEAD`docker build -f ./ci/docker/Dockerfile -t giotto-gateway-core:$commit . 先读取 Git 版本管理库中最新的 commit id 作为镜像的 tag，以便更好地标识和管理镜像，再使用 docker build 命令，传入参数构建镜像。 Kubernetes容器编排 Kubernetes 是具备良好的自动化部署、扩展、调度和编排能力的开源容器管理平台，能够帮助有效地降低容器运维成本，提高服务集群管理效率。微服务API网关的管理模块和核心模块两个微服务将使用 Kubernetes 部署和编排容器，以提高系统的扩展性和可靠性。 对于核心模块而言，1个核心模块 Pod 管理1个核心模块 Container 的生命周期，总共部署3个 Pod 实现核心模块功能的高可用；对于管理模块而言，1个管理模块 Pod 管理1个管理模块 Container 的生命周期，由于到达管理模块的流量相对较小，总共部署1个 Pod 提供服务。创建 Deployment 用于对 Pod 进行弹性伸缩和负载均衡，创建 Service 用于对 Pod 进行端口映射以实现外部网络的访问。 12345678910111213141516171819202122232425# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/k8s/core.yaml# deploy configapiVersion: apps/v1kind: Deploymentmetadata: name: giotto-gateway-corespec: replicas: 3 selector: matchLabels: name: giotto-gateway-core template: metadata: labels: name: giotto-gateway-core spec: containers: - name: giotto-gateway-core image: giotto-gateway-core:d1785da imagePullPolicy: Never ports: - containerPort: 80 - containerPort: 443 Kubernetes Deployment 配置定义了 Pod 的副本数量、元数据、容器镜像和容器端口映射关系等，用于对微服务容器进行部署运行、弹性伸缩和负载均衡。 1234567891011121314151617181920212223# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/k8s/core.yaml# service configapiVersion: v1kind: Servicemetadata: name: giotto-gateway-corespec: ports: - port: 80 name: \"http-proxy\" targetPort: 80 protocol: TCP nodePort: 30080 - port: 443 name: \"https-proxy\" targetPort: 443 protocol: TCP nodePort: 30443 type: NodePort selector: name: giotto-gateway-core Kubernetes Service 配置定义了元数据和对外端口映射关系等，用于建立外部网络访问 Kubernetes 节点内容器的通信桥梁。 12345# take giotto-gateway-core as an example# https://github.com/LotteWong/giotto-gateway-core/blob/main/ci/k8s/apply_yaml.sh# k8s apply yaml to create deploy and servicekubectl create -f ./ci/k8s/core.yaml 使用 kubectl create 命令，传入配置文件路径创建 Deployment 和 Service。","link":"/2021/06/04/微服务API网关的设计与实现(5)/"},{"title":"#Bash# 思维导图：Bash 命令行","text":"备份记录 Bash 的思维导图和相关文档。 思维导图 相关文档 认识与学习 BASH 正规表示法与文件格式化处理","link":"/2021/07/20/思维导图之Bash/"},{"title":"#Gin# 思维导图：Gin Web Framework","text":"备份记录 Gin 的思维导图和相关文档。 思维导图 相关文档 Gin 框架中文文档","link":"/2021/05/01/思维导图之Gin/"},{"title":"#Go-Micro# 思维导图：Go-Micro Microservice Framework","text":"备份记录 Go-Micro 的思维导图和相关文档。 思维导图 相关文档 Go Micro 中文文档","link":"/2021/05/03/思维导图之Go-Micro/"},{"title":"#Gorm# 思维导图：Gorm Object Relational Mapping Library","text":"备份记录 Gorm 的思维导图和相关文档。 思维导图 相关文档 Gorm 中文文档","link":"/2021/05/02/思维导图之Gorm/"},{"title":"#Grpc# 思维导图：Grpc Rpc Framework","text":"备份记录 Grpc 的思维导图和相关文档。 思维导图 相关文档 gRPC","link":"/2021/05/04/思维导图之Grpc/"},{"title":"#Microservice# 微服务API网关的设计与实现(6) 系统测试","text":"本文主要介绍微服务API网关的系统测试，分为两个方面： 功能测试 性能测试 目录 Table of Contents 功能测试用例设计 常见测试用例设计方法 用例记录 条目 内容 用例编号 [数学] 功能描述 [-] 前置条件 [-] 测试过程 [-] 预期结果 [-] 是否通过 [是否] 性能测试测试环境及工具 条目 内容 硬件机器配置 腾讯云服务器1C2G1M 测试网络环境 localhost 软件压测工具 wrk 测试过程及结果 压测对象 压测命令 每秒的请求量 微服务API网关核心模块 wrk -t30 -c600 -d30s -H&quot;Authorization:Bearer ${jwt}&quot; http://localhost:8080/wrk 5651.29 纯 Golang 服务器 wrk -t30 -c600 -d30s http://localhost:8081/wrk 25961.68 Nginx wrk -t30 -c600 -d30s http://localhost:8082/wrk 3561.78 开启30个线程，并发请求600次后台接口，持续30秒时间，采集并打印压测结果。 从每秒的请求量看，纯 Golang 服务器没有中间流程损耗和额外组件开销因而支撑的 QPS 大幅领先，微服务API网关核心模块能够超过未调优前的 Nginx 的性能表现。","link":"/2021/06/05/微服务API网关的设计与实现(6)/"},{"title":"#Vim# 思维导图：Vim 编辑器","text":"备份记录 Vim 的思维导图和相关文档。 思维导图 相关文档 vim程序编辑器","link":"/2021/07/19/思维导图之Vim/"},{"title":"#Shell Script# 思维导图：Shell Script","text":"备份记录 Shell Script 的思维导图和相关文档。 思维导图 相关文档 学习 shell scripts","link":"/2021/07/21/思维导图之Shell Script/"},{"title":"#Others# 新移动设备的必要软件清单","text":"备份记录新移动设备的必要软件清单：To C / To B 目录 Table of Contents To C社交 微信：手机/平板 TIM：手机/平板 娱乐 QQ音乐：手机/平板 微信读书：手机/平板 豆瓣：手机 懂球帝：手机 微博：手机 哔哩哔哩：平板 生活 美团：手机 高德地图：手机 携程：手机 Keep：平板 购物 京东：手机 淘宝：平板 学习 牛客：平板 超级简历：平板 力扣：平板 V2EX：手机 知乎：手机 极客时间：平板 慕课网：平板 理财 招商银行：手机 招商证券：手机 支付宝：手机 理财通：手机 火币：手机 币安：手机 同花顺投资账本：平板 鲨鱼记账：平板 To B通信 企业微信：手机 腾讯会议：手机 存储 百度网盘：手机 OneDrive：平板 生产 腾讯文档：手机 Office 365：平板 Office Lens：平板 笔记 OneNote：平板 MarginNote：平板 公司 MOA：手机 RDM：手机 乐问：手机 脉脉：手机 工具 To Do：手机/平板 v2rayNG：手机 Forest：手机/平板","link":"/2021/03/15/新移动设备的必要软件清单/"},{"title":"#Microservice# 阅读《浅析微服务架构 API 网关的作用》笔记","text":"姚刚,吴海莉,王从镔.浅析微服务架构API网关的作用[J].信息系统工程,2020(12):16-18. 目录 Table of Contents 阅读本论文后，主要讨论以下两点： API 网关的架构 API 网关的选型 API 网关的架构 Core Core（核心网关）系统的功能主要是对客户请求的接收， 它将请求指向给上层的服务端，并且会把这些处理结果返回给客户端或下层服务端。 可以以集群的形式部署，需要额外的负载均衡器，反向代理连接业务集群。 可以实现核心的功能：认证鉴权、限流熔断、负载均衡、反向代理、服务编排、协议转换、日志记录、数据缓存、服务注册/发现和版本/灰度发布等。 Admin Admin（网关管理）系统负责配置系统的各种策略，如： 限流、缓存以及告警等基础信息。 可以以集群的形式部署，但是入口是统一的。 可以实现管理的功能：API 单个管理、API 分组管理、SDK/文档生成、访问配置、流控配置、协议转换配置、数据缓存配置和监控告警配置等。 Monitor Monitor（监控日志） 系统负责生成运维管理报表等。 可以以集群的形式部署，采集可以多个节点进行。 可以实现监控的功能：日志处理、生成报表和自动告警等。 持久层 管理库：记录管理信息 日志库：记录日志信息 Redis：缓存与限流 Zookeeper：服务注册与服务发现 OpenResty API Gateway 在 OpenResty API Gateway 中主要实现安全、限流、缓存、日志、监控和身份认证等功能，另外还可以实现制定服务的注册、路由重写和负载均衡等策略。 Aggr API Gateway 在 Aggr API Gateway 中可 以使用超时、缓存、熔断、重试、查询聚合等策略。 注：作者没有进一步阐述为什么需要分成两个网关，即 OpenResty API Gateway 和 Aggr API Gateway。 API 网关的选型安全性 用户密码使用加盐 sha256 加密 租户密钥使用 Md5 加密 高可用弹性伸缩 k8s 副本伸缩 热更新 MySQL 和 Redis 做数据同步 容灾备份 MySQL 主从备份 高性能高并发 gin 大流量 限流、熔断、降级 扩展性 中间件的洋葱结构 生命周期管理 可参考 Uber Edge Gateway 的设计 总结 本文提出了微服务 API 网关的通用设计架构，并指出在技术选型过程中需要考虑安全性、高可用、高性能、扩展性和生命周期管理等问题。","link":"/2021/04/03/浅析微服务架构 API 网关的作用/"},{"title":"#Microservice# 阅读《恒丰银行分布式核心系统 - API 网关 技术原型落地实践》笔记","text":"赵毅,张涛.恒丰银行分布式核心系统-API网关技术原型落地实践[J].中国金融电脑,2017(04):48-55. 目录 Table of Contents 阅读本论文后，主要讨论以下两点： 恒丰银行 API 网关技术架构 恒丰银行 API 网关设计亮点 技术架构 Java SPI：实际是“基于接口的编程＋策略模式＋配置文件”的动态加载机制。 Filter-PRPE：模型为 “PRE -&gt; ROUTING -&gt; POST -&gt; ERROR” 的责任链机制。 File System：提供了网关启动所需的环境配置信息，包括注册中心连接和参数配置、外部依赖连接和参数配置以及默认的基础规则配置。其中默认的基础规则配置可被动态地替换。 Zookeeper：在提供服务注册与服务发现的能力之余，对配置进行持久化和订阅通知。 注：Zookeeper 替代了传统的数据库直接存储配置（MySQL 和 MongoDB 不再是必需的），Zookeeper 自带的消息订阅功能也解决了热更新问题（Redis 和 RabbitMQ 不再是必需的），为了提高运行效率数据将缓存在内存，这些都是非常具有参考价值的做法。同时，本文也提出了动态覆盖本地设置的新思路。 设计亮点多维度动态路由机制 总结 本文提出了一种基于 Java SPI + Filter PRPE 实现的微服务 API 网关的架构，在服务/配置数据动态管理和多维度动态路由机制这两个方面为毕设工作提供了宝贵的参考。","link":"/2021/04/07/恒丰银行分布式核心系统 - API 网关技术原型落地实践/"},{"title":"#Docker# 速查手册：常用 Docker 命令","text":"覆盖在学习和工作中的常用 Docker 命令：Image / Container / Storage / Network 目录 Table of Contents Image查看12345678# 查看全部镜像详情docker imagesdocker images -a# 查看全部镜像标识docker images -aq# 查看指定镜像详情docker inspect ${registry}:${tag}docker inspect ${image_id} 制作1docker build --network ${network_mode} -f /path/to/dockerfile -t ${registry}:${tag} /path/to/data 保存123# 具备元数据等docker save -o ${output}.tar ${registry}:${tag}docker save -o ${output}.tar ${image_id} 加载12# 具备元数据等docker load -i ${input}.tar 修改1docker tag ${image_id} ${registry}:${tag} 删除12345# 删除全部镜像docker rmi -f $(docker images -aq)# 删除指定镜像docker rmi -f ${registry}:${tag}docker rmi -f ${image_id} Dockerfile1234567891011121314151617181920212223242526272829303132333435363738394041# Example: a sample python imageFROM ubuntu # basic imageMAINTAINER lottewong &lt;lottewong21@gmail.com&gt; # author info# install sqlite3, python3, pip3 and other toolsRUN apt-get update &amp;&amp; \\ apt-get install -y python3 \\ python3-dev \\ python3-pip \\ openssl \\ libssl-dev \\ libffi-dev \\ net-tools \\ sqlite3 &amp;&amp; \\ ln -s /usr/bin/python3 /usr/bin/python &amp;&amp; \\ ln -s /usr/bin/pip3 /usr/bin/pip &amp;&amp; \\ apt install -y vim lsof curl# make data and log directoriesRUN mkdir -p /data/test-proj/dependencies &amp;&amp; \\ mkdir -p /var/log/test-projWORKDIR /data/test-proj # fix work directory# install test-proj depending packagesCOPY dependencies dependencies # copy files from host to containerRUN cd dependencies &amp;&amp; \\ pip install -r requirements.txt &amp;&amp; \\ tar -zvxf some-package.tar.gz &amp;&amp; \\ rm -rf some-package.tar.gz &amp;&amp; \\ cd /data/test-proj/dependencies/some-package &amp;&amp; python setup.py install# start init script (mount file when running container)# CMD [\"sh\", \"start.sh\"]# ENTRYPOINT [\"sh\", \"start.sh\"]# RUN: 镜像层命令，应用于 docker build 时# CMD: 容器层命令，应用于 docker run 时（当指定命令时会被忽略）# ENTRYPOINT: 容器层命令，应用于 docker run 时（无论何种情况都被执行）# Shell形式执行命令: &lt;instruction&gt; &lt;command&gt;# Exec形式执行命令: &lt;instruction&gt; [\"executable\", \"param1\", \"param2\", \"param3\", ...] Container查看12345# 查看全部容器详情docker psdocker ps -a# 查看全部容器标识docker ps -aq 运行123456789# -p 可以映射多个端口# -v 可以挂载多个目录# -d 后台运行# -it 交互运行docker run --name=${container_name} -d -p ${host_port}:${ctnr_port} -v /path/to/host:/path/to/ctnr ${registry}:${tag} (${command})docker run --name=${container_name} -it -p ${host_port}:${ctnr_port} -v /path/to/host:/path/to/ctnr ${image_id} (${command})# --rm 运行后就删除# Example: docker run --rm busybox nslookup baidu.com 执行123# Example: docker exec -it test /bin/bashdocker exec -it ${container_name} ${command}docker exec -it ${container_id} ${command} 启动12docker start ${container_name}docker start ${container_id} 暂停12docker stop ${container_name}docker stop ${container_id} 重启12docker restart ${container_name}docker restart ${container_id} 删除12345# 删除全部容器docker rm -f $(docker ps -aq)# 删除指定容器docker rm -f ${container_name}docker rm -f ${container_id} 提交12docker commit -a \"${author}\" -m \"${message}\" ${container_name} ${registry}:${tag}docker commit -a \"${author}\" -m \"${message}\" ${container_id} ${registry}:${tag} 导出123# 没有元数据等docker export ${container_name} &gt; ${export}.tardocker export ${container_id} &gt; ${export}.tar 导入12# 没有元数据等cat ${import}.tar | docker import - ${registry}:${tag} 传输1234# 从容器到主机docker cp ${container}:/path/to/ctnr /path/to/host# 从主机到容器docker cp /path/to/host ${container}:/path/to/ctnr 日志12docker logs ${container_name}docker logs ${container_id} Storage To be continued… Network To be continued…","link":"/2020/05/15/速查手册之常用Docker命令/"},{"title":"#Git# 速查手册：常用 Git 命令","text":"覆盖在学习和工作中的常用 Git 命令：配置 / 仓库 / 查看 / 暂存 / 提交 / 回退 / 克隆 / 拉取 / 推送 / 合并 / 冲突 / 分支 / 标签 / 工具 目录 Table of Contents 配置账号123456789101112131415# 配置多个本地用户的账号# 全局级git config --global user.name \"${user_name}\"git config --global user.email \"${user_email}\"# 仓库级# git config --global --unset user.name \"${user_name}\"# git config --global --unset user.name \"${user_email}\"git config --local user.name \"${user_name}\"git config --local user.email \"${user_email}\"# 提交级git commit --amend --author=\"${user_name} &lt;${user_email}&gt;\"git commit --amend --reset-author 密钥1234567891011121314151617181920# 配置多个远程仓库的密钥# 生成密钥ssh-keygen -t rsa_githubssh-keygen -t rsa_gitlab# 配置密钥vim ~/.ssh/configHost github.comHostName github.comUser gitIdentityFile ~/.ssh/rsa_github Host gitlab.comHostName gitlab.comUser gitIdentityFile ~/.ssh/rsa_gitlab:wq 换行12345678# 提交时转换为LF，检出时转换为CRLFgit config --global core.autocrlf true# 提交时转换为LF，检出时不转换git config --global core.autocrlf input# 提交时不转换，检出时不转换git config --global core.autocrlf false 仓库查看1git remote -v 新建12# Example: git remote add origin git@github.com:LotteWong/lottewong.github.io.gitgit remote add ${origin_name} git@host:/path/to/registry.git 删除1git remote rm ${origin_name} 查询当前状态1git status 差异分析工作区 vs 暂存区1git diff (${branch_name}) (${file}) # 默认 branch = current; file 若不填作用于全部文件 暂存区 vs 版本库1git diff --cached (${commit_id}) (${file}) # 默认 commit = HEAD; file 若不填作用于全部文件 工作区 vs 版本库1git diff ${commit_id} (${file}) # file 若不填作用于全部文件 版本库 vs 版本库1git diff ${commit_id} ${commit_id} (${file}) # file 若不填作用于全部文件 提交记录123git log # 详细git log --oneline # 简略git log --graph # 图示 操作记录1git reflog 暂存查看1git stash list 保存1git stash 恢复12git stash pop # 默认还原栈顶数据git stash pop stash@{${id}} # 指定还原特定数据 删除12git stash clear # 删除全部暂存数据git stash drop stash@{${id}} # 删除指定暂存数据 提交暂存区123git add -A or git add --all # 提交整个仓库全部文件(New/Modified/Deleted)git add /path/to/file # 提交指定目录全部文件(New/Modified/Deleted)git add -u # 提交整个仓库已有文件(Modified/Deleted) 版本库123git commit -m \"${commit_message}\" # 指定提交信息标题git commit # 打开默认的编辑器git commit --amend # 追加提交 回退工作区12git reset --hard (${commit_id}) (${file}) # 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file} 暂存区12git reset (--mixed) (${commit_id}) (${file}) # 会清除暂存区; 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file} 版本库1234567# 向前移动指针git reset --soft (${commit_id}) (${file}) # 不清除暂存区; 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file}# 向后移动指针git revert (${commit_id}) # 默认 commit = HEAD; 撤销单次提交并生成单次提交git revert -n ${old_commit}^..${new_commit} # 撤销连续提交并生成单次提交 克隆12345# Example: git clone git@github.com:LotteWong/lottewong.github.io.gitgit clone git@host:/path/to/registry.git # 克隆默认分支# Example: git clone -b backup git@github.com:LotteWong/lottewong.github.io.gitgit clone -b ${branch_name} git@host:/path/to/registry.git # 克隆指定分支 拉取123456git pull origin ${remote_branch} # 拉取到已有本地分支git checkout -b ${local_branch} ${remote_branch} # 拉取并新建本地分支git fetch origin ${remote_branch}git pull origin ${remote_branch} # git fetch + git mergegit pull origin --rebase ${remote_branch} # git fetch + git rebase 推送12git push origin ${remote_branch} # 推送到已有远程分支git push origin ${local_branch}:${remote_branch} # 推送并新建远程分支 合并Merge1234git merge ${branch_name} # 带有单独合并提交信息git merge ${branch_name} --no-commit # 不带单独合并提交信息git merge --continue # 解决冲突后使用git merge --abort # 不打算解决冲突 Squash1234git merge --squash ${branch_name} # A1 → B1 → M3git rebase -i ${startpoint} (${endpoint}) # A1 → B1 → C2 → D2; 默认 endpoint = HEAD# pick(p)：保留本次提交# squash(s)：合并前后提交 Rebase123git rebase ${branch_name}git rebase --continue # 解决冲突后使用git rebase --abort # 不打算解决冲突 Cherry-Pick123git cherry-pick ${commit_id}git cherry-pick --continue # 解决冲突后使用git cherry-pick --abort # 不打算解决冲突 冲突1234git status # 查看冲突文件vim /path/to/file # 解决冲突之处git add /path/to/file # 将文件加入暂存区git commit -m \"${commit_message}\" # 将文件加入版本库 分支查看123git branch -a # 全部分支git branch -v # 本地分支git branch -r # 远程分支 更新1git remote update 新建12git checkout -b ${local_branch} ${remote_branch} # 创建本地分支：远程分支 → 本地分支git push origin ${local_branch}:${remote_branch} # 创建远程分支：本地分支 → 远程分支 改名123456# 本地重命名分支git branch -m ${old_branch} ${new_branch}# 远程重命名分支git push origin --delete ${old_remote_branch}git push origin ${new_local_branch}:${new_remote_branch} 切换1git checkout ${branch_name} 关联1git branch --set-upstream-to=${remote_branch} ${local_branch} 删除123git branch -d ${local_branch} # 非强制删除本地分支git branch -D ${local_branch} # 强制性删除本地分支git push origin --delete ${remote_branch} # 删除远程分支 标签查看12git tag # 全部标签git show ${tag_name} # 指定标签 新建123git tag ${tag_name} (${commit_id}) # 创建本地标签; 默认 commit = HEADgit push origin --tags # 创建全部远程标签git push origin ${tag_name} # 创建指定远程标签 删除12git tag -d ${tag_name} # 删除本地标签git push origin --delete ${tag_name} 工具提交规范12345# 安装npm install -g commitizen cz-conventional-changelog# 使用git cz 变更日志12345# 安装npm install -g conventional-changelog-cli# 使用conventional-changelog -p angular -i CHANGELOG.md -s -r 0 代码评审 To be continued… 子级模块 To be continued…","link":"/2020/05/08/速查手册之常用Git命令/"},{"title":"#Linux&Shell# 速查手册：常用 Linux&Shell 命令","text":"覆盖在学习和工作中的常用 Linux 命令：管理 / 连接 / 网络 / 进程 / 文件 / 文本 目录 Table of Contents 管理列举123456# Ubuntuapt list --installed# CentOSyum list installed# Alpineapk info 更新12345678# Ubuntuapt-get updateapt-get -y upgrade# CentOSyum update# Alpineapk updateapk upgrade 安装123456# Ubuntuapt-get install -y ${package}# CentOSyum install -y ${package}# Alpineapk add --upgrade ${package} 卸载123456# Ubuntuapt-get --purge remove ${package}# CentOSyum remove ${package}# Alpineapk del ${package} 连接ssh12ssh -p ${port} ${username}@${host}sshpass -p ${password} ssh -p ${port} ${username}@${host} telnet1telnet ${host} ${port} ping1ping ${host} nslookup1nslookup ${domain} curl12345curl \\-X ${method} \\-H \"${header_key}: ${\"header_val\"}\" \\-d \"${json_data}\" \\${api_url} \\ mysql1mysql -h ${host} -P ${port} -u ${username} -p 网络查看 ip1ip a |grep eth 查看 dns1cat /etc/resolv.conf |grep nameserver 进程查询 proc1ps -ef |grep ${proc_name} 查询 port1lsof -i:${port} 从 proc 查 port / 从 port 查 proc12netstat -tunlp |grep ${proc_name}netstat -tunlp |grep ${port} 杀死进程12345678ps -ef | grep ${including_keyword} | grep -v ${excluding_keyword}kill -s 9 ${pid}ps -ef | grep ${including_keyword} | grep -v ${excluding_keyword} | awk '{print $2}' | xargs kill -s 9kill -s 9 `pgrep ${keyword}`pkill -9 ${keyword} 后台任务123456789# 启动nohup ${command} &gt;&gt; ${log_file} 2&gt;&amp;1 &amp;# 查看jobs -llsof -i:${job_port}ps -ef |grep ${job_cmd}# 杀死kill -9 ${job_pid}kill -9 ${proc_pid} 文件从服务器下载到本机1234scp -r -P ${port} ${username}@${host}:/path/to/remote /path/to/local # 包括文件rsync -a -e ssh --exclude=\"${pattern}\" ${username}@${host}:/path/to/remote /path/to/local # 排除文件sz /path/to/server # 从server下载文件（可视化的） 从本机上传到服务器1234scp -r /path/to/local -P ${port} ${username}@${host}:/path/to/remote # 包括文件rsync -a -e ssh --exclude=\"${pattern}\" /path/to/local ${username}@${host}:/path/to/remote # 排除文件rz # 从local上传文件（可视化的） 解压zip 1unzip -d /path/to/unzip ${pkg_to_unzip} tar 123tar -xvf ${pkg_to_untar} # 解压 tar 包tar -zxvf ${pkg_to_untar} # 解压 tar.gz 包tar -jxvf ${pkg_to_untar} # 解压 tar.bz2 包 加压zip 123zip -r /path/to/unzip ${pkg_to_zip}zip -d /path/to/zip ${file_to_delete} # 从压缩包中删除文件zip -m /path/to/zip ${file_to_append} # 向压缩包中添加文件 tar 123tar -cvf ${pkg_to_tar} # 加压 tar 包tar -zcvf ${pkg_to_tar} # 加压 tar.gz 包tar -zjvf ${pkg_to_tar} # 加压 tar.bz2 包 文本查看json 1cat ${file} | python -m json.tool log 1234less ${log_file}vim ${log_file}tail -n ${number} ${log_file}tail -f ${log_file} 编辑复制 1ctrl + Insert 粘贴 1shift + Insert 移动 1234gg # 首行G # 末行shift + ^ # 行首shift + $ # 行末 搜索 1234/pattern # 向前搜索？pattern # 向后搜索n # 上一个N # 下一个 查看缩进和行尾 1: set list 处理分隔 1awk -F:\"${seperator}\" '/${pattern}/${command}' ${file} 替换 1sed \"s/${pattern}/${substr}/g\" 权限12chown -R ${user}:${group} ${file}chmod 777 ${file} 工具统计代码12sudo apt install -y cloccloc ${include_dir} --exclude-dir=${exclude_dir} 压力测试1wrk -t${threads} -c${connections} -d${duration} --latency ${url}","link":"/2020/05/08/速查手册之常用Linux&Shell命令/"},{"title":"#Kubernetes# 速查手册：常用 Kubernetes 命令","text":"覆盖在学习和工作中的常用 Kubernetes 命令：Node / Pod / Deployment / Service / Configmap / Storage / Network 目录 Table of Contents Node查看12kubectl get nodes | grep ${node_name}kubectl describe node ${node_name} Pod查看12kubectl get pods | grep ${pod_name}kubectl describe pod ${pod_name} 执行1kubectl exec -it ${pod_name} -c ${container_name} ${command} 删除12# 只删除 pod 不删除 deployment，相当于再重启kubectl delete pod ${pod_name} Deployment查看12kubectl get deployments | grep ${deployment_name}kubectl describe deployment ${deployment_name} 修改1234# 保存后会直接生效kubectl edit deployment ${deployment_name}kubectl set image deployment/${deployment_name} ${container_name}=${registry}:${tag} Service查看12kubectl get services | grep ${service_name}kubectl describe service ${service_name} Configmap查看12kubectl get configmaps | grep ${configmap_name}kubectl describe configmap ${configmap_name} 修改12# 需重启后才会生效kubectl edit configmap ${configmap_name} Storage To be continued… Network To be continued…","link":"/2020/05/15/速查手册之常用Kubernetes命令/"},{"title":"#MongoDB# 速查手册：常用 MongoDB 命令","text":"覆盖在学习和工作中的常用 MongoDB 命令：Database / Collection / Document / Index 目录 Table of Contents Database查询数据库1show dbs 切换/创建数据库1use &lt;db_name&gt; 删除数据库1db.dropDatabase() Collection查询集合1show collections 创建集合1db.createCollection(&lt;collection_name&gt;, &lt;options&gt;) 删除集合1db.&lt;collection_name&gt;.drop() Document条件查询12345678910111213db.&lt;collection_name&gt;.find(&lt;condition&gt;, &lt;projection&gt;).pretty()// 等于：{&lt;key&gt;: &lt;value&gt;}// 不等于：{&lt;key&gt;: {$ne: &lt;value&gt;}}// 小于：{&lt;key&gt;: {$lt: &lt;value&gt;}} // 小于或等于：{&lt;key&gt;: {$lte: &lt;value&gt;}}// 大于：{&lt;key&gt;: {$gt: &lt;value&gt;}}// 大于或等于：{&lt;key&gt;: {$gte: &lt;value&gt;}}// 与：{&lt;key1&gt;: &lt;value1&gt;, &lt;key2&gt;: &lt;value2&gt;}// 或：{$or: [{&lt;key1&gt;: &lt;value1&gt;}, {&lt;key2&gt;: &lt;value2&gt;}]}// 类型：{$type: &lt;type_id&gt;} 或 {$type: &lt;type_name&gt;} 分页查询1db.&lt;collection_name&gt;.find().limit(&lt;limit&gt;).skip(&lt;skip&gt;) 排序1234db.&lt;collection_name&gt;.find().sort({KEY:&lt;order&gt;}) // KEY: 1为升序排序// KEY: -1为降序排序 计数1db.&lt;collection_name&gt;.aggregate([{$group : {_id : \"$&lt;field&gt;\", num_tutorial : {$sum : 1}}}]) 插入记录12345678910111213141516db.&lt;collection_name&gt;.insert(&lt;document&gt;) // 不允许主键_id重复db.&lt;collection_name&gt;.save(&lt;document&gt;) // 可允许主键_id重复db.&lt;collection_name&gt;.insertOne( &lt;document&gt;, { writeConcern: &lt;document&gt; // 写入策略 })db.&lt;collection_name&gt;.insertMany( [&lt;document1&gt;, &lt;document2&gt;], { writeConcern: &lt;document&gt;, // 写入策略 ordered: &lt;boolean&gt; // 是否顺序写入文档 }) 更新记录123456789db.&lt;collection_name&gt;.update( &lt;condition&gt;, &lt;document&gt;, { writeConcern: &lt;document&gt;, // 写入策略 upsert: &lt;boolean&gt;, // 是否不存在就插入 multi: &lt;boolean&gt;, // 是否更新多条文档 }) 删除记录1234567db.&lt;collection_name&gt;.remove( &lt;condition&gt;, { writeConcern: &lt;document&gt;, // 写入策略 justOne: &lt;boolean&gt; // 是否删除多条文档 }) Index查询索引1db.&lt;collection_name&gt;.getIndexes() 创建索引1234db.&lt;collection_name&gt;.createIndex(&lt;keys&gt;, &lt;options&gt;)// key: 1为升序索引// key: -1为降序索引 删除索引12db.&lt;collection_name&gt;.dropIndexes()db.&lt;collection_name&gt;.dropIndex(&lt;key&gt;)","link":"/2020/05/01/速查手册之常用MongoDB命令/"},{"title":"#Redis# 速查手册：常用 Redis 命令","text":"覆盖在学习和工作中的常用 Redis 命令：Server / Client / Database / String / Hash / List / Set / Sorted Set 目录 Table of Contents Server12# 启动 redis 服务端redis-server redis.conf Client12# 访问 redis 客户端redis-cli -h ${host] -p ${post} -a ${password} Database12345# 清空当前数据库的数据flushdb# 清空全部数据库的数据flushall Key查询12345678# 检查是否存在EXISTS ${key}# 正则批量查询KEYS ${regexp}# 精确单个查询GET ${key} 超时1234567# 应用超时EXPIRE ${key} ${second}EXPIREAT ${key} ${timestamp}PEXPIRE ${key} ${millisecond}# 取消超时PERSIST ${key} String查询12345678# 检查是否存在EXISTS ${key}# 正则批量查询KEYS ${regexp}# 精确单个查询GET ${key} 设置1SET ${key} ${value} 删除1DEL ${key} Hash查询1234567891011# 检查是否存在HEXISTS ${key} ${h_key}# 查询单个键值HGET ${key} ${h_key}# 查询多个键值HMGET ${key} ${h_key}...# 查询所有键值HGETALL ${key} 设置12345# 设置单个键值HSET ${key} ${h_key} ${h_value}# 设置多个键值HMSET ${key} ${h_key} ${h_value} ... 删除12345# 删除单个键值DEL ${key} ${h_key}# 删除多个键值DEL ${key} ${h_key}... List1to be continued... Set1to be continued... Sorted Set1to be continued...","link":"/2020/05/22/速查手册之常用Redis命令/"},{"title":"#SQL# 速查手册：常用 SQL 命令","text":"覆盖在学习和工作中的常用 SQL 命令：Comment / Script / Database / Table / Column / Index 目录 Table of Contents Comment12345--单行注释/* 多行注释*/ Script12345--外部调用mysql -u ${username} -p ${password} -D ${database} &lt; ${file}--内部调用source ${file}\\. ${file} Database查询数据库1SHOW DATABASE; 创建数据库1CREATE DATABASE ${db_name}; 切换数据库1USE ${db_name}; 删除数据库1DROP DATABASE ${db_name}; Table查看表123456--查看所有表SHOW TABLES;--查看某个表DESC ${table_name};SHOW CREATE TABLE ${table_name}; 创建表1234CREATE TABLE `${table_name}` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY(`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 修改表123456--增加列ALTER TABLE ${table_name} ADD COLUMN id bigint(20) NOT NULL AUTO_INCREMENT;--修改列ALTER TABLE ${table_name} CHANGE COLUMN id ID bigint(20) NOT NULL AUTO_INCREMENT;--删除列ALTER TABLE ${table_name} DROP COLUMN id; 删除表1DROP TABLE ${table_name}; Column条件查询1SELECT name FROM ${table_name} WHERE id=1; 分页查询1234--计算公式--LIMIT：page_size--OFFSET：page_size * (page_index - 1)SELECT * FROM ${table_name} LIMIT 3 OFFSET 0 模糊查询123456--匹配模式--%：任意多个字符--_：任意单个字符--[]：要包含范围内的字符--[^]：不包含范围内的字符SELECT * FROM ${table_name} WHERE name Like ${cond}; 排序1SELECT * FROM ${table_name} ORDER BY id DESC; 计数1SELECT COUNT(*) FROM ${table_name}; 插入记录1INSERT INTO ${table_name} (id, name) VALUES (1, \"test\"); 更新记录1UPDATE ${table_name} SET id=1, name=\"test\"; 删除记录1DELETE FROM ${table_name} WHERE id=1 AND name=\"test\"; Index查询索引1SHOW INDEX FROM ${table_name} FROM ${db_name} 创建索引1CREATE [UNIQUE] INDEX ${index_name} ON ${table_name} (${column_name}) 删除索引1ALTER TABLE ${table_name} DROP INDEX ${index_name}","link":"/2020/05/01/速查手册之常用SQL命令/"},{"title":"#Others# 重装系统后的必要软件清单","text":"备份记录重装系统后的必要软件清单：开发 / 办公 / 实用 目录 Table of Contents 开发编辑器 Notepad++：查看文本文件 Typora：查看 Markdown 文件 VSCode：查看代码文件 开发语言 Golang Flutter Node.js Python 开发环境JetBrains JetBrains GoLand JetBrains PyCharm JetBrains 插件 Git Tool Box：查看Git提交的记录 PreCI：本地扫描腾讯代码规范 VSCode Flutter 支持和检查 Node.js 支持和检查 VSCode 插件 GitLens：查看Git提交的记录 PreCI：本地扫描腾讯代码规范 Chinese (Simplified) Language Pack for Visual Studio Code：中文显示 GBKtoUTF8：中文编码 Open In Browser：在浏览器打开 HTML 文件 Debugger for Chrome：在 Chrome 浏览器进行调试 Document This：支持快捷注释 Todo Tree：查看待办事项列表 Markdown All in One &amp; Markdown Lint &amp; Markdown Preview Github Styling &amp; Markdown TOC：Markdown支持&amp;检查&amp;渲染&amp;目录 PlantUML：绘制 UML 图表 Docker：管理 docker 镜像和容器等 Remote - WSL：远程连接 WSL 进行开发 数据库 MySQL Redis SQLite 远程连接 Windows Terminal：连接本地服务器 XShell：连接远程服务器 HeidiSQL：连接远程 MySQL 数据库 RDM：连接远程 Redis 数据库 虚拟系统 Ubuntu WSL Alpine WSL 其它工具 Git：版本控制 swaggo：接口文档 Postman &amp; Newman：接口测试 公司使用 iOA WeTERM iFit 腾讯电脑管家 办公通信 微信 企业微信 TIM Telegram 腾讯会议 存储 企业云盘 OneDrive 百度网盘 生产 Office 365 Office Lens Drawboard PDF 笔记 OneNote XMind 画图 StarUML MockPlus 实用功能 Bing壁纸：更换桌面和锁屏壁纸 Edge：微软浏览器 Chrome：谷歌浏览器 WinRar：解压/压缩工具，主要格式：.zip/.rar 7-Zip：解压/压缩工具，主要格式：.tar FormatFactory：转换各种格式 记录 To Do：待办事项 Sticks：桌面便签 便捷 Everything：搜索工具 TreeSize：查空间工具 Snipaste：截图工具 Ditto：剪切板工具","link":"/2021/03/15/重装系统后的必要软件清单/"},{"title":"#Golang# Golang与并发编程(3) goroutine泄漏","text":"介绍 goroutine 泄漏的相关内容，主要讨论以下三个部分： goroutine 泄漏判断 goroutine 泄漏分类 goroutine 泄漏预防 目录 Table of Contents 前情提要 goroutine 泄漏指的是因为编码中的陷阱使得 goroutine 无法正常释放而造成的内存泄漏，甚至导致内存溢出或最终程序崩溃。 本文将讨论 goroutine泄漏的判断、分类和预防，如有错漏，欢迎指出 ;P goroutine泄漏判断runtime.NumGoroutine runtime.NumGoroutine 可以返回正在运行中的 goroutine 数量（包括 main goroutine 和 normal goroutine）。 12345678910import( \"fmt\" \"runtime\")// ...fmt.Println(runtime.NumGoroutine())// ... runtime/pprof runtime/pprof 可以（以写入的形式）返回 goroutine 的运行数量和堆栈信息。 12345678910import ( \"os\" \"runtime/pprof\" )// ...pprof.Lookup(\"goroutine\").WriteTo(os.Stdout, 1)// ... http/net/pprof http/net/pprof 可以（以访问的形式）返回 goroutine 的运行数量、堆栈信息和其它资源信息。 123456789101112import ( \"net/http\" _ \"net/http/pprof\" )// ...http.ListenAndServe(\"localhost:6060\", nil)// ...// 进入 http://localhost:6060/debug/pprof/goroutine?debug=1 查看 gops gops 支持列出当前环境下的进程信息。 在 .go 中： 123456789101112import ( \"log\" \"github.com/google/gops/agent\")// ...if err := agent.Start(); err != nil { log.Fatalln(err)}// ... 在 terminal 中： 12345$ gops # 查看进程信息$ gops stats PID # 查看状态信息$ gops stack PID # 查看堆栈信息 leaktest leaktest 将泄漏检测过程加入到自动化测试中去。 1234567891011import ( \"github.com/fortytw2/leaktest\")// ...defer leaktest.Check(t)defer leaktest.CheckTimeout(t, time.Second)defer leaktest.CheckContext(ctx, t)// ... goroutine 泄漏分类无退出的计算循环 对于没有函数调用，纯循环计算的 G，runtime 无法实行抢占； 显然，如果没有退出机制且程序常驻的话，每次启动的 goroutine 都得不到释放，就会发生 goroutine 泄漏。 12345678910111213141516171819202122package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { for { fmt.Println(\"Testing...\") // 死循环无法抢占和回收 }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} 不结束的I/O请求 对于 I/O 请求，runtime 无法实行抢占； 如果 I/O 请求一直处于等待期间，该 goroutine 则无法释放，出现泄漏。 1234567891011121314151617181920212223242526package mainimport ( \"bufio\" \"fmt\" \"os\" \"runtime\" \"time\")func test() { input := bufio.NewScanner(os.Stdin) if input.Scan() { text := input.Text() // I/O请求无法抢占和回收 fmt.Println(text) }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} channel 引起的泄漏只发送不接收 上游生产速度远远大于下游消费速度，阻塞的 goroutine 会一直在 channel 的发送等待队列。 无缓冲 channel 没有接收就会阻塞，有缓冲 channel 缓冲满了就会阻塞。 123456789101112131415161718192021222324252627282930package mainimport ( \"fmt\" \"math/rand\" \"runtime\" \"time\")func query() int { n := rand.Intn(100) return n}func queryAll() int { ch := make(chan int) go func() { ch &lt;- query() }() go func() { ch &lt;- query() }() go func() { ch &lt;- query() }() return &lt;-ch}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 3 ，发生泄漏 }() queryAll()} 只接收不发送 下游消费速度远远大于上游生产速度，阻塞的 goroutine 会一直在 channel 的接收等待队列。 无缓冲 channel 仍然接收就会阻塞，有缓冲 channel 缓冲空了就会阻塞。 12345678910111213141516171819package mainimport ( \"fmt\" \"runtime\" \"time\")func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() ch := make(chan bool) go func() { ch &lt;- true }()} 空 channel 向 nil channel 发送和接收数据都会导致阻塞，只进行声明而不初始化 channel 容易出现该类泄漏。 12345678910111213141516171819202122package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { var ch chan bool &lt;-ch // ch &lt;- data}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} 空 select select{} 永远无法响应导致协程阻塞，一般不会出现这种情况。 1234567891011121314151617181920package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { select {}}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} sync 引起的泄漏Mutex 忘记解锁 有一个 goroutine 加锁忘了解锁，另一个 goroutine 竞争锁会失败，由此这个 goroutine 将一直地阻塞。 1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { var mutex sync.Mutex for i := 1; i &lt;= 2; i++ { go func() { mutex.Lock() fmt.Println(\"goroutine index:\", i) }() }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} WaitGroup 计数错误 WaiteGroup 的 Add 和 Done 数量不对应将引起 Wait 的等待退出条件永远无法满足，从而阻塞协程。 1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { var wg sync.WaitGroup wg.Add(2) go func() { wg.Done() }() wg.Wait()}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} Cond 没发信号 Wait 方法阻塞等待条件变量满足条件，如果没有 Signal 或者 Broadcast，Wait 将会一直不能唤醒。 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { cond := sync.NewCond(&amp;sync.Mutex{}) condition := false go func() { cond.L.Lock() condition = true cond.L.Unlock() }() cond.L.Lock() for !condition { cond.Wait() } cond.L.Unlock()}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} goroutine泄漏预防 对于计算循环和 I/O 请求：检查代码。 确保每个计算循环都会退出； 确保每个 I/O 请求都会关闭。 对于 channel 引起的泄漏：本质上是防止 channel 阻塞。 使用有缓冲的 channel ； 用 make 来声明并初始化 channel； 避免空的 select； 优雅地关闭 channel 等。 对于 sync 引起的泄漏：本质上是防止 sync 阻塞。 对于互斥锁，加锁解锁应该成对地出现，这时候可以利用 defer： 12345// ...mutex.Lock()// ...defer mutex.Unlock()// ... 对于信号量，Add(1) 和 Done() 搭配使用，而不是一开始就规定好任务计数： 123456// ...wg.Add(1)go func() { wg.Done() // ...}() 对于条件变量，条件改变后应发送信号，单播还是多播根据具体情况而定： 1234// ...condition = truecond.Signal() // or cond.Broadcast()// ... 参考链接 Go语言圣经 如何防止 goroutine 泄露（一） 如何防止 goroutine 泄露（二） Goroutine 泄露","link":"/2020/03/05/Golang与并发编程(3)/"},{"title":"#Golang# Golang与并发编程(4) channel使用","text":"本文主要讨论 channel 使用的相关内容。 目录 Table of Contents 前情提要 为了实现 goroutine 通信，有两种常见并发模型： 共享内存：使用共享内存方式，Go 中 sync 库包提供了多种同步的机制。 消息队列：使用类似管道和消息队列的方式，各个并发单元数据相互独立，通过消息进行数据交换，Go 中 channel 类型模拟了这种同步的模式。 让我们再一次来复读 Go 社区的并发口号——“不要通过共享内存来通信，而应该通过通信来共享内存”。 本文将讨论 Go 并发编程中的通信桥梁 channel的使用，如有错漏，欢迎指出 ;P 概念引申管道 Pipe 管道 (Pipe) 是操作系统中进程间通信的一种方式。管道的本质是一个存在于内存或文件系统的缓冲有限的特殊文件，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序地将数据写入缓冲区，另一端的进程则顺序地读出数据。 匿名管道没有名字，是半双工的；匿名管道对于管道两端的进程而言是一个存在于内存的特殊文件；匿名管道只能用于父子进程或兄弟进程之间通信。 有名管道拥有名字，是全双工的；有名管道对于管道两端的进程而言是一个存在于文件系统的特殊文件；有名管道可以用于本机任意两个进程之间通信。 管道传送无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式。 消息队列 Message 消息队列 (Message) 是操作系统中进程间通信的一种方式。管道的本质是一个存放在内核中的长度不限的消息链表，一般遵循先进先出规则，也可以随机或按消息的类型查询，并且允许一个或多个进程向它写入或读取消息。 消息队列由消息队列标识符标识，提供有格式字节流并且具有类型。 信道 Channel 信道 (Channel) 是 Golang 中协程间通信的一种方式。信道的本质是一个线程安全的先进先出队列，可选择无缓冲或有缓冲，任意时刻同时只能有一个 goroutine 访问 channel。 信道可以指定类型。 Golang 并不支持无限容量的 channel，原因是如果生产速率远远大于消费速率，那么 channel 内的数据不断累积将会爆掉内存。 channel 使用make12345678// 双向channelch := make(chan T, cap)// 只读channel（但是没什么意义，双向channel可以赋值单向channel）ch_or := make(&lt;-chan T, cap)// 只写channel（但是没什么意义，双向channel可以赋值单向channel）ch_ow := make(chan&lt;- T, cap) 引用类型，使用 make 创建，零值为 nil 可选择数据类型 可选择缓冲容量 无缓冲：cap = 0，读写同步 有缓冲：cap &gt; 0，读写异步 可选择通信方向 只读：&lt;-chan 只写：chan&lt;- read-write1data := &lt;- ch 从 channel 中读取数据： 无缓冲：没有 goroutine 写入，channel 阻塞 有缓冲：channel 容量变空，channel 阻塞 1ch &lt;- data 向 channel 里写入数据： 无缓冲：没有 goroutine 读取，channel 阻塞 有缓冲：channel 容量变满，channel 阻塞 close123456789101112131415161718192021// 关闭 channel// close 手动关闭或等待自动 GCclose(ch)// 尝试写入已关闭的 channel// 导致 panic 异常ch &lt;- d// 返回数据或零值// 还有剩余数据则返回数据// 没有剩余数据则返回零值d := &lt;-ch// 返回数据和布尔值// true 表示成功从 channel 接收到值// false 表示 channel 已经被关闭并且里面没有值可接收d, ok := &lt;-ch// 尝试重复关闭 channel// 导致 panic 异常close(ch) 关闭 channel 可以通过显式的代码关闭或隐式的垃圾回收 对关闭后的 channel 进行写入操作： 导致 panic 异常 对关闭后的 channel 进行读取操作： 存在已经发送成功的数据：返回数据 不存在已经发送成功的数据：返回零值 对关闭后的 channel 进行重复关闭： 导致 panic 异常 close 常常与 select、range 和 defer 一起使用 range123456789101112131415ch := make(chan struct{})// for-range 写法for item := range ch { // ...}// for-break 写法for { item, ok := &lt;-ch // ... if !ok { break }} for...range 从信道中读出数据，会一直迭代到信道关闭，当 channel 中没有数据时会阻塞当前 goroutine。 select1234567891011121314151617181920212223// 处理一般逻辑，case 为一般表达式switch {case Case1: // ...case Case2: // ...case Case3: // ...default: // ...}// 处理通信逻辑，case 为通信表达式select {case item1, ok := &lt;-ch1: // ...case item2, ok := &lt;-ch2: // ...case item3, ok := &lt;-ch3: // ...default: // ...} 如果所有信道堵塞，有 default 语句：按照默认逻辑处理 如果所有信道堵塞，无 default 语句：等待至某一个信道可以处理 如果某个信道可以处理：直接处理该信道的逻辑 如果多个信道可以处理：随机处理某信道的逻辑 在 nil channel 上操作将会一直阻塞；使用 select{} 语句将会一直阻塞 应用实例单生产者-单消费者模型1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"fmt\" \"time\")const BUFLEN = 5// 生产者func producer(ch chan&lt;- int) { d := 1 for { ch &lt;- d fmt.Println(\"Produce:\", d) d++ time.Sleep(1 * time.Second) // 生产者速率不宜过快 }}// 消费者func consumer(ch &lt;-chan int) { for { d := &lt;-ch fmt.Println(\"Consume:\", d) time.Sleep(2 * time.Second) // 消费者速率不宜过快 }}func main() { // 生产消费的缓冲区 ch := make(chan int, BUFLEN) // 启动生产者协程 go producer(ch) // 启动消费者协程 go consumer(ch) // 防止主函数的退出 for { }} 多生产者-多消费者模型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package mainimport ( \"fmt\" \"math/rand\" \"sync\" \"time\")const BUFLEN = 5var cond *sync.Cond = sync.NewCond(&amp;sync.Mutex{})// 生产者func producer(ch chan&lt;- int) { for { cond.L.Lock() for len(ch) == BUFLEN { cond.Wait() } data := rand.Intn(1000) ch &lt;- data fmt.Println(\"Produce:\", data) cond.L.Unlock() cond.Signal() time.Sleep(2 * time.Second) // 生产者速率不宜过快 }}// 消费者func consumer(ch &lt;-chan int) { for { cond.L.Lock() for len(ch) == 0 { cond.Wait() } data := &lt;-ch fmt.Println(\"Consume:\", data) cond.L.Unlock() cond.Signal() time.Sleep(1 * time.Second) // 消费者速率不宜过快 }}func main() { rand.Seed(time.Now().UnixNano()) // 生产消费的缓冲区 ch := make(chan int, BUFLEN) // 启动 10 个生产者协程 for i := 0; i &lt; 10; i++ { go producer(ch) } // 启动 10 个消费者协程 for i := 0; i &lt; 10; i++ { go consumer(ch) } // 防止主函数的退出 for { }} 规律总结 参考链接 Go语言圣经 Go入门指南 channel的简介 channel的应用","link":"/2020/03/06/Golang与并发编程(4)/"},{"title":"#Golang# Golang与并发编程(6) 同步机制","text":"本文主要讨论同步机制的相关内容。 目录 Table of Contents 前情提要 尽管 Go 提倡“不要通过共享内存来通信，而应该通过通信来共享内存”，亦即使用 channel 而非使用 sync。然而支持同步机制仍然十分重要，无论是出于兼容或是方便的目的。 在《现代操作系统(第4版)》第2.3节-进程间通信中，提及了竞争条件 (race condition) 和临界区域 (critical region) 的概念，本节讨论重点落于通过互斥方案以解决经典 IPC 问题。其中包含了多种思路、工具和机制，如屏蔽中断、锁变量、严格轮换法、Peterson 解法、TSL 指令、睡眠与唤醒、互斥量、信号量、管程、消息传递、屏障、避免锁等。Go 的 channel 很明显借鉴了消息传递的解决方法，而 sync 包则对应了互斥量、信号量、睡眠与唤醒/管程、屏蔽中断的具体实现。 本文将讨论 Go 并发编程中的各式各样的同步机制，包括悲观并发控制和乐观并发控制，如有错漏，欢迎指出 ;P 互斥量 互斥量 (Mutex) 在 Golang 中对应了各种锁 (Lock)，包括互斥锁、读写锁、双重检查锁。互斥量主要用于通过锁机制实现悲观并发控制，锁住临界区 (critical section) 以保证同时刻只有一个 goroutine 可以访问共享资源 (shared resource) 。 互斥锁 sync.Mutex123456789101112131415161718192021222324252627// 数据加锁var mu sync.Mutexfunc DoSthToData() { mu.Lock() defer mu.Unlock() // do something to data in critical section}()// 对象加锁type SomeObj struct { mu *sync.Mutex}func NewSomeObj() *SomeObj { return &amp;SomeObj{ mu: &amp;sync.Mutex{} }}func (o *SomeObj) DoSthToObj() { o.mu.Lock() defer o.mu.Unlock() // do something to object in critical section} g1 已经加锁后，g2 再尝试加锁，g2 造成阻塞；g2 已经解锁后，g2 将加锁成功，g2 恢复运行。 无论是读还是写，均会互斥。 读写锁 sync.RWMutex1234567891011121314151617var mu sync.Mutex// 一路只写func WriteMutex() { mu.Lock() defer mu.Unlock() // write something to critical section}// 多路只读func ReadMutex() { mu.RLock() defer mu.RUnlock() // read something from critical section} 读写锁将数据或对象设定为写模式（只写）或者读模式（只读）。 写模式下，多个写操作之间是互斥的，即一路只写；读模式下，多个读操作之间不会互斥，即多路只读；写操作和读操作之间是互斥的。 所有被读锁定 (RLock) 的 goroutine 会在写解锁 (Unlock) 时唤醒；读解锁 (RUnlock) 只会在没有任何读锁定时唤醒一个要进行写锁定 (Lock) 而被阻塞的 goroutine。 双重检查锁 sync.Once1234567891011121314151617181920// 懒汉模式type Singleton struct{}var instance *Singletonvar mu sync.Mutexfunc GetSingleton() *Singleton { // 单例没被初始化才加锁 if instance == nil { mu.Lock() defer mu.Unlock() // 单例没被初始化才创建 if instance == nil { instance = &amp;Singleton{} } } return instance} 第一次检查：控制共享资源访问。 第二次检查：解决锁竞争带来的重复创建单例问题。 12345678910111213// 饿汉模式type Singleton struct{}var instance *Singleton// 初始化时仅创建一次func init() { instance = &amp;Singleton{}}func GetSingleton() *Singleton { return instance} 利用 init 函数只会被执行一次的特点，在程序运行前创建单例。 由于 init 函数没有参数值和返回值，有一定的局限性。 12345678910111213// sync.Oncetype Singleton struct{}var instance *Singletonvar once sync.Oncefunc GetSingleton() *Singleton { once.Do(func() { instance = &amp;Singleton{} }) return instance} 如果存在某个只执行一次的任务，不适合放在 init 函数，可考虑放在 sync.Once 类中。 sync.Once 内部使用了卫述语句、双重检查锁、原子操作等实现全局唯一操作。 信号量 信号量 (Semaphore) 在 Golang 中对应的是等待组 (sync.WaitGroup)。信号量主要用于通过计数来协调多个 goroutine 有序运行，等待批量并发任务运行结束。信道也可以实现类似功能，相比之下通过等待组的方式更为轻量。 1234567891011121314151617func main() { var wg sync.WaitGroup var mu sync.Mutex for i:=0; i++; i&lt;5 { wg.Add(1) go func() { defer wg.Done() mu.Lock() defer mu.Unlock() // do something }() } wg.Wait()} 等待组内部拥有计数器，通常而言：计数器增加 (Add) 、计数器减少 (Done) 和计数器等待 (Wait) 这三个方法应该整体出现。 等待组与同步锁配合使用，等待组解决批量任务的协调问题，同步锁解决单个任务的竞争问题。 条件变量 条件变量 (Condition Variables) 在 Golang 中对应的是条件变量 (sync.Cond)。条件变量主要用于通过条件来协调多个 goroutine 有序运行，唤醒单个或多个正在睡眠的协程。信道也可以实现类似功能，相比之下通过条件变量的方式更为轻量。 123456789101112131415161718192021222324252627282930313233func main() { cond := sync.Cond(&amp;sync.Mutex{}) condition := false go func() { cond.L.Lock() defer cond.L.Unlock() // do something in anonymous goroutine condition = true cond.Signal() // wake up one sleep goroutine on this condition }() go func() { cond.L.Lock() defer cond.L.Unlock() // do something in anonymous goroutine condition = true cond.Broadcast() // wake up all sleep goroutines on this goroutines }() cond.L.Lock() defer cond.L.Unlock() for !condition { cond.Wait() // do something in main goroutine }} 条件变量内部拥有同步锁，通常而言：等待 (Wait) 与单发 (Signal) 或广播 (Broadcast) 这两个方法应该配对出现。 条件变量与同步锁配合使用，条件变量解决协程处于睡眠或唤醒中的状态问题，同步锁解决单个任务的竞争问题。 原子操作 原子操作 (Atomic Operation) 在 Golang 中对应的是原子操作 (sync/atomic)。原子操作实现互斥的核心是：执行过程中 CPU 不能被中断，并基于这个基础上实现乐观并发控制。 增加与减少 Add12newi32 := atomic.AddInt32(&amp;i32, 1) // 原子操作：增加newi32 := atomic.AddInt32(&amp;i32, -1) // 原子操作：减少 有符号整数型：增加使用正数，减少使用负数。 无符号整数型：增加使用原码，减少使用补码。 指针类型：在 Golang 中不支持直接对指针进行运算。 比较与替换 CAS12isSwap := atomic.CompareAndSwapInt32(&amp;addr, oldVal, newVal) // 比较替换oldVal := atomic.SwapInt32(&amp;addr, newVal) // 直接替换 CAS 的优势：无锁机制，减少锁竞争的性能损耗。 CAS 的劣势：被操作值频繁变更，比较与替换则容易失败，需要引入循环进行多次尝试。 CAS 不会阻塞协程，但会暂时停滞。对于一些类型的值，乐观并发控制 (CAS) 优于悲观并发控制 (Lock)。 载入与存储 Load/Store12v := atomic.LoadInt32(&amp;value) // 原子操作：载入atomic.StoreInt32(&amp;value, v) // 原子操作：存储 Swap 比 CompareAndSwap 约束少（不做比较），比 Load 功能强（返回旧值）。 CompareAndSwap 可能会失败，Load 总是能成功。 参考链接 同步1-锁 同步2-等待组 同步3-条件变量 同步4-sync包的其他API 同步5-原子操作","link":"/2020/03/08/Golang与并发编程(6)/"},{"title":"#Golang# Golang与编程范式之面向对象编程","text":"介绍 Golang 中的面向对象思想实践，主要讨论以下四个部分： 类和对象 封装 继承 多态 目录 Table of Contents 简介 Golang 的起源受诸多早期编程语言的影响。类 C 让 Golang 本质上更倾向于是一门面向过程的语言，同时Golang 也借鉴了 Alef 来设计 Golang 的函数式编程特性，融合 CSP 中使用管道进行通信和控制同步的思想则很好地体现了如何面向消息编程。 虽然 Golang 不是一门传统的面向对象语言，但是 Golang 的设计却深受面向对象思想的影响。我们可以通过一种 Golang 的方式来实现面向对象的重要特性，这也是接下来将要讨论的重点。 PS：本文 just 一点自己的见解，学识有限难免有误，也希望可以抛砖引玉，欢迎大家的勘误和讨论╰(￣ω￣ｏ) 类和对象 众所周知🤫，类和对象是面向对象编程的灵魂（？类定义了一件事物的抽象特点，包含了数据的形式和对数据的操作；对象是类的实例，可以通过构造函数和析构函数来进行对生成和销毁的特殊处理。 C++ 的类和对象12345678910111213141516171819202122232425262728293031323334class Person {private: // 数据成员 string name; protected: // 数据方法 string getName() { return this-&gt;name; } void setName(string name) { this-&gt;name = name; } public: // 构造函数 Person(string name) { this-&gt;name = name; } // 析构函数 ~Person() { // ... }};int main() { Person* somebody = new Person(\"Bot\"); cout &lt;&lt; somebody-&gt;getName() &lt;&lt; endl; // Output: Bot somebody-&gt;setName(\"Exp\"); cout &lt;&lt; somebody-&gt;getName() &lt;&lt; endl; // Output: Exp return 0;} Golang的“类和对象”1234567891011121314151617181920212223242526272829type Person struct { // 数据成员 name string}// 数据方法func (this *Person) GetName() string { return p.name}func (this *Person) SetName(name string) { p.name = name}// 构造函数func NewPerson(string name) *Person { return &amp;Person{ name: name, }}// 析构函数// 由于 Golang 采用垃圾回收机制，一般不需要显式写析构函数func main() { somebody := NewPerson(\"Bot\") fmt.Println(somebody.getName()) // Output: Bot somebody.SetName(\"Exp\") fmt.Println(somebody.getName()) // Output: Exp} 区别联系耦合程度 C++ 的类是面向 class 而言的，数据成员和数据方法都必须在 class 内修改，可见耦合程度较高。 Golang 的“类”是面向 type 而言的，数据成员在 struct 内修改，数据方法则是可以在任意处增删 (recv *receiver_type) 对应的方法，可见耦合程度较低。 【PS：这里 type 的外延比 class 要广，type 除包括自定义类型外还支持内置类型的别名】 this 指针 C++ 对象的 this 指针常常是隐式的，每一个数据方法实际上都隐式传入了一个指向该对象的 this 指针： 123void setName([Person* this], string name) { this-&gt;name = name;} Golang “对象”的 this 指针必须是显式的，不难看出 this 指针是连接 Golang 中类型和方法的关键桥梁： 123func (this *Person) setName(string name) { this.name = name} 构造与析构 C++ 的构造函数和析构函数是比较容易理解的，构造函数在对象创建时被自动调用，析构函数在对象销毁时被自动调用。由于 C++ 无垃圾回收机制，对象的生命周期和作用域紧密相关。 Golang 严格上来说没有构造函数和析构函数的说法，可以通过用来专门做初始化的函数来模拟构造函数，而defer 和 finalizer 有类似析构的意味，但本质还是很不同的。由于 Golang 有垃圾回收机制，对象的生命周期取决于何时被 GC 进程回收，一般而言当变量不再被引用就会被垃圾回收掉。 封装 封装 aka 信息隐藏，其实包含了两层意思：一是调用方无须关心实现细节，二是调用方无法更改实现细节。封装在编程语言中一般体现在访问权限中。 Java 的封装 以经典的 OO 语言 Java 为例，由于 Java 同时存在类和包的概念，其访问权限需要考虑到两个维度，相对而言比较复杂。其中，Java 的访问权限通过关键字定义： public：公共可见，所有类可见 protected：继承可见，必须为继承关系，允许跨包 [default]：包内可见，不要求继承关系，仅限同包 private：私有可见，仅本类可见 Golang 的封装 而在 Golang 中没有所谓的类和对象概念（或者说可以用很 Golang 的方式类似实现），但引入了包管理机制，Golang 中只有简化的两层访问权限。其中，Golang 的访问权限通过标识符大小写定义： 标识符首字母大写：包外可见，所有的包均可见 标识符首字母小写：包内可见，本包文件均可见 一些说明 Golang 中的 标识符首字母大写 类似于 Java 中的 public Golang 中的 标识符首字母小写 类似于 Java 中的 [default] 继承 继承涉及三方面的内容：一是子类可以使用父类的属性和方法，避免重复编码；二是子类可以覆盖父类的属性和方法，是实现多态的必要条件之一；三是子类可以追加属于自己的属性和方法，完成子类的定制功能。 C++ 的继承123456789101112131415161718192021222324252627282930313233343536373839class Parent {public: // ... virtual void parentFunc() { // ... } virtual void parentFunc(params) { // ... } virtual void overrideFunc() { // Parent class content }}class Child: public Parent {public: // ... virtual void overrideFunc() { // Child class content } virtual void childFunc() { // ... }};int main() { Child* child = new Child(); child-&gt;parentFunc(); // 使用父类方法 child-&gt;overrideFunc(); // 使用已覆盖的子类方法 child-&gt;Parent::overrideFunc(); // 使用未覆盖的父类方法 child-&gt;childFunc(); // 使用子类方法 return 0;} Golang 的继承1234567891011121314151617181920212223242526272829303132type Parent struct { // ...}func (p *Parent) ParentFunc() { // ...}func (p *Parent) OverrideFunc() { // Parent class content}type Child struct { Parent // ...}func (c *Child) OverrideFunc() { // Child class content}func (c *Child) ChildFunc() { // ...}func main() { child := &amp;Child{} child.ParentFunc() // 使用父类方法 child.OverrideFunc() // 使用已覆盖的子类方法 child.Parent.OverrideFunc() // 使用未覆盖的父类方法 child.ChildFunc() // 使用子类方法} 一些说明 C++ 的继承更像是链式继承，从父类到子类进行构造，从子类到父类进行访问 Golang 的继承更像是组合继承，子类内嵌一个或多个父类 从 Golang 的继承机制容易看出它支持多继承，一些编程语言（如 Java）仅支持单继承 多态 多态指同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。当我们讨论多态时，我们常常会讨论重载以及重写和动态绑定。 语言基础接口 类型绑定方法集，接口定义方法集。如果类型绑定的方法集和接口定义的方法集重合，那么类型实现了接口。 类型内定义了有什么属性，接口内定义了有什么操作，两者产生关联的关键是方法是否都被实现。 接口是隐式实现的，不需要显式声明；接口是一种特殊的类型，它可以被赋值成实例的指针或引用。 基于以上事实，我们可以知道： 不同的接口可以完成不同的组合操作； 多个类型可以实现同个接口，一个类型可以实现多个接口； 不同的类型完成不同的组合操作，看起来却是同一个接口，这就是多态！ 断言 虽然我们提供对外提供了统一接口调用的方案，但是对内我们到底如何从接口出发辨别纷繁的类型呢？给定一个类型我们又该如何确定它是否实现了某个接口？ 类型断言和类型选择：给定接口确定类型 1234567891011121314// 类型断言if _, ok := varI.(T); ok {// ...}// 类型选择switch t := varI.(type) {case T:// ...case nil:// ...default:// ...} 接口断言：给定类型确定接口 1234// 接口断言if _, ok := varT.(I); ok {// ...} Golang 的多态重载 重载是指根据不同的方法签名调用不同的函数实现。 Golang 的设计思想中是不允许任何形式的重载的，这是为了强化显式化的风格。 【PS：不同类型的接收器绑定的同名方法，严格来说不算重载】 尽管 Golang 本身不提供重载的机制，我们还是可以借助接口来实现类似的功能。 12345678910111213141516171819202122func Speak(persons ...interface{}) { for _, person := range persons { switch t := person.(type) { case Chinese: // Speak Chinese case American: // Speak English case nil: // Error handler default: // Default handler } }}func main() { chinese := Chinese{} american := american{} Speak(chinese) // Speak Chinese Speak(american) // Speak English Speak(chinese, american) // chinese Speak Chinese, american Speak English} 重写和动态绑定 重写和动态绑定是为了允许将子类类型的指针赋值给父类类型的指针，在运行时可以通过指向父类的指针来调用实现子类中的方法。 既然Golang中不存在严格的类和对象，重写和动态绑定的理论其实并不太适合 Golang，我们只需要关心怎么将利用一个接口访问可以定位到具体的类型就可以了。 Golang 实现了编译时静态接口判断（类型是否实现接口），运行时动态类型选择（到底是哪种类型）。 1234567891011121314151617181920212223242526272829303132type Animal interface { move() // ...}type Bird struct { // ...}func (b *Bird) move() { // fly}type Pig struct { // ...}func (p *Pig) move() { // walk}func main() { var animal Animal bird := Bird{} pig := Pig{} animal = bird animal.move() // fly animal = pig animal.move() // walk} 参考链接 《Go语言圣经》 《Go入门指南》 致谢 感谢王同学坚持不懈的“八点钟检查”以及一点都不嫌弃的“康康博客”，让我得以在快要写不下去的时候还坚持着做一些有意义的复读，XOXO。","link":"/2020/03/01/Golang与编程范式(1)/"},{"title":"#Golang# Golang与编程范式之函数式编程","text":"介绍 Golang 中的函数式思想实践，主要讨论以下三个部分： 函数基础概念 闭包 装饰器模式 目录 Table of Contents 简介 Golang 的起源受诸多早期编程语言的影响。类 C 让 Golang 本质上更倾向于是一门面向过程的语言，同时Golang 也借鉴了 Alef 来设计 Golang 的函数式编程特性，融合 CSP 中使用管道进行通信和控制同步的思想则很好地体现了如何面向消息编程。 Golang 不是一门纯函数式的编程语言，但是函数在 Golang 中是“第一公民”，表现在于：函数支持参数值和返回值；函数作为一种类型，它的变量、常量和字面量既可以被存储也可以被调用；函数支持闭包功能。下面我们就来对这些话题作进一步的探讨吧~ PS：本文 just 一点自己的见解，学识有限难免有误，也希望可以抛砖引玉，欢迎大家的勘误和讨论╰(￣ω￣ｏ) 函数基础概念 函数定义一般包括关键字、函数名、参数值和返回值四个部分，注意区分函数类型和函数的区别。函数使用可以进行赋值变量和直接调用，注意区分函数变量、常量和字面量的区别。 函数定义123456789101112// 定义函数类型type FuncType func(params paramsType) returnType// 定义命名函数func Func(params paramsType) returnType { // ...}// 定义匿名函数func (params paramsType) returnType { // ...} 关键字：定义函数类型使用 type，定义命名函数或匿名函数使用 func 函数名：大写时包外可见，小写时包内可见 参数值：支持顺序参数，不支持关键字参数；支持不定参数，不支持默认值参数；有简化的写法 返回值：支持多值返回；支持有名返回；有简化的写法 PS：Golang 函数支持不同的接收器所绑定的函数同名，不支持传统的函数重载；支持嵌套匿名函数赋值，不支持嵌套命名函数定义。 函数使用12345678910111213141516171819202122232425262728293031// 函数变量定义var fn FuncType// 赋值命名函数fn = Func// 赋值匿名函数fn = func (params paramsType) returnType { // ...}// 函数变量作为参数值func paramsFunc(fn FuncType) { // ...}// 函数变量作为返回值func returnFunc() (fn FuncType) { // ...}// 函数变量调用res := fn(req)// 命名函数调用res := Func(req)// 匿名函数调用res := func (params paramsType) returnType { // ...}(req) 函数变量：属于引用类型 函数常量：命名函数的函数名 函数字面量：匿名函数的整体 PS：函数变量和函数常量都可以当作指针变量，该指针指向函数代码的开始位置。 闭包 闭包是由函数及其相关引用环境组合而成的实体，即闭包 = 函数 + 引用环境，一般通过在匿名函数中引用外部的局部变量或全局变量构成。 引用局部变量12345678910111213141516171819202122232425262728func genSumFunc() (func(int) int, func(int) int) { var sum int add := func(num int) int { sum = sum + num return sum } sub := func(num int) int { sum = sum - num return sum } return add, sub}func main() { f1, f2 := genSumFunc() g1, g2 := genSumFunc() var res int res = f1(1) // 1 res = f1(1) // 2 res = f2(1) // 1 res = g1(1) // 1 res = g1(1) // 2 res = g2(1) // 1} 引用外部 sum 局部变量，传入外部 num 局部变量，实现累加或累减。 多次调用普通函数 genSumFunc，引用外部 sum 局部变量创建副本。 多次调用不同的闭包函数 f1 和 f2 ，引用外部 sum 局部变量共享引用。 多次调用同一个闭包函数 f1 或 g1 ，引用外部 sum 局部变量共享引用。 引用全局变量123456789101112131415161718192021222324252627var sum intfunc genSumFunc() (func(int) int, func(int) int) { add := func(num int) int { sum = sum + num return sum } sub := func(num int) int { sum = sum - num return sum } return add, sub}func main() { f1, f2 := genSumFunc() g1, g2 := genSumFunc() var res int res = f1(1) // 1 res = f1(1) // 2 res = f2(1) // 1 res = g1(1) // 2 res = g1(1) // 3 res = g2(1) // 2} 引用外部 sum 全局变量，传入外部 num 局部变量，实现累加或累减。 多次调用普通函数 genSumFunc，引用外部 sum 全局变量共享引用。 多次调用不同的闭包函数 f1 和 f2 ，引用外部 sum 全局变量共享引用。 多次调用同一个闭包函数 f1 或 g1 ，引用外部 sum 全局变量共享引用。 一些说明 对象是附有行为的数据，类在定义时已经显式地定义了行为。 闭包是附有数据的行为，闭包中的数据没有显式地集中声明。 PS：闭包的目的是用共享局部变量来减少全局变量，代价是不够清晰和不够直接。 装饰器模式 类继承 (Class Inheritance) 在编译时增加行为，装饰器模式 (Decorator Pattern) 在运行时增加行为。装饰器的实现和闭包是分不开的。 Python 装饰器1234567891011121314151617181920212223242526def some_decorator_without_params(fn): @functools.wraps(fn) def wrapper(*args, **kwargs): # do something before function fn(*args, **kwargs) # do something after function return wrapperdef some_decorator_with_params(params): def decorator(fn): @functools.wraps(fn) def wrapper(*args, **kwargs): # do something before function using params fn(*args, **kwargs) # do something after function using params return wrapper return decorator@some_decorator_without_params@some_decorator_with_params(params)def HelloWorld(who, when=\"now\"): print(\"Hello World to %s at %s!\" % (who, when)) 闭包 (some_decorator) = 函数 (wrapper) + 引用环境 (fn) 装饰器 → 中间件 = @ 语法糖 + 洋葱顺序 Golang 装饰器12345678910111213141516171819202122232425262728type Decorator func(http.HandlerFunc) http.HandlerFuncfunc SomeDecorator(h http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { // do something before handler h(w,r) // do something after handler }}func Middlewares(h http.HandlerFunc, decos ...Decorator) http.HandlerFunc { for deco := range decos { d := decos[len(decos)-1-deco] h = d(h) } return h}func HelloWorldHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(\"Hello World!\") return}func main() { closure := SomeDecorator(HelloWorldHandler)} 闭包 (closure) = 函数 (anonymous func) + 引用环境 (h) 装饰器 → 中间件 = 闭包集合 + 洋葱顺序 参考链接 《Go语言核心编程》 《Go语言高级编程》 编程模式之Go如何实现装饰器 致谢 实际上再写这篇博客时，小王与我的关系已经发生微妙的变化。如你所知，世界是物质的，物质是运动的，人也难免发生变化，我们就是在这样那样的变化中忘掉自我而寻找无双的。有小王的一路陪伴，我当然要说我庆幸，并且希望可以一直幸运下去 :)","link":"/2020/03/02/Golang与编程范式(2)/"},{"title":"#Fiddler# HTTP的通信监控和回放：Fiddler抓包与Socket发包","text":"利用Fiddler抓包和Socket发包，并用Curl脚本统计响应时间，主要分为以下四个部分： 工具的配置及工具的使用 截获、修改、发送数据包 统计网页和元素的响应时间 需注意事项及待改进事项 任务 部署类似Microsoft PetshopWeb应用基本实例，开发性能测试小工具能截获基于IE浏览器与Web服务器的交互的数据包，修改数据包（比如简化起见，修改要搜索的关键字），再把修改后的内容使用多线程的方式发送到服务器。统计请求每个网页上主要元素（gif,css等）需要的时间，以及请求整个网页的时间。 提示： 在获取数据包的过程中要根据HTTP请求的特点，从原始的数据包中过滤出HTTP的数据包。找到提交的“搜索的关键字”，将其替换成其它字符。 发送数据包使用Socket，可以参考网络编程的资料。 方法 截获数据包 修改数据包 发送数据包 记响应时间 手段 用Fiddler截获 用Python修改 用Socket发送 用Fiddler查看 验证 可用性 易用性 并发性 工具的配置安装工具Fiddler下载地址 导入证书 勾选解码 过滤保存手动 脚本 1234567891011121314151617if (oSession.fullUrl.Contains(\"baidu.com\")) { // for(var key in oSession.oRequest.headers) { // if('Referer' === key) { if(oSession.oRequest.headers['Referer'].indexOf(\"&amp;wd=\") != -1) { var fso; var file; fso = new ActiveXObject(\"Scripting.FileSystemObject\"); file = fso.OpenTextFile(\"E:\\\\MyPrograms\\\\fiddler_sessions\\\\Session\" + new Date().getTime() + \".txt\", 8 ,true, true); // file.writeLine(\"Request url: \" + oSession.url); file.writeLine(\"Request header:\" + \"\\n\" + oSession.oRequest.headers); // file.writeLine(\"Request body: \" + oSession.GetRequestBodyAsString()); file.writeLine(\"\\n\"); file.close(); } // } // }} 设置断点手动 命令 在左下角黑框框中输入命令 停止断点：bpu 开始断点：bpu $host 工具的使用Statistics Filters Inspectors Composer AutoResponder 截获数据包图形界面 使用图形界面或编程脚本应用过滤 点击左下角 Capturing或空白处 停止或开始截获数据包 使用Statistics查看时间，使用Inspectors查看内容 使用图形界面或编程脚本保存会话 修改数据包程序脚本对于手动保存的会话 123456789101112131415161718192021222324252627282930# 替换请求中的搜索字段def get_ref(file, cont): with open(file, encoding='utf-8') as f: lines = f.readlines() for line in lines: if 'Referer' in line: start = line.find(\"&amp;wd=\") end = line.find(\"&amp;rsv_pq=\") old_str = line[start+4:end] new_str = parse.quote(cont) line = line.replace(old_str, new_str) return line# 重新拼装需发送的报文def get_req(file, cont): msg = '' with open(file, encoding='utf-8') as f: lines = f.readlines() for line in lines: if 'GET' in line: line = 'GET ' + get_ref(file, cont)[9:-1] + ' HTTP/1.1' if 'Referer' in line: line = get_ref(file, cont) if 'Accept-Encoding' in line: continue line = line.strip('\\n') + '\\r\\n' msg += line msg = bytes(msg, encoding=\"utf8\") return msg 对于自动保存的会话 1234567891011121314151617181920212223242526272829303132# 替换请求中的搜索字段def get_ref(file, cont): with open(file, encoding='utf-16') as f: lines = f.readlines() for line in lines: if 'Referer' in line: start = line.find(\"&amp;wd=\") end = line.find(\"&amp;rsv_pq=\") old_str = line[start+4:end] new_str = parse.quote(cont) line = line.replace(old_str, new_str) return line# 重新拼装需发送的报文def get_req(file, cont): msg = '' with open(file, encoding='utf-16') as f: lines = f.readlines() for line in lines: if 'Request header:' in line: continue if 'GET' in line: line = 'GET ' + get_ref(file, cont)[9:-1] + ' HTTP/1.1' if 'Referer' in line: line = get_ref(file, cont) if 'Accept-Encoding' in line: continue line = line.strip('\\n') + '\\r\\n' msg += line msg = bytes(msg[:-4], encoding=\"utf8\") return msg 发送数据包Fiddler使用WebForms 使用图形界面或编程脚本应用过滤 使用图形界面或运行命令设置断点 在 对应报文A 的 Request WebForms内修改“搜索关键字” 点击 Break on Response 将修改后的 对应报文A 发送到Fiddler 在 对应报文B 的 Request WebForms内查看“搜索关键字” 点击 Run to Completion 将修改后的 对应报文B 发送到Server 使用Composer 保存会话Request请求头部 在记事本内修改“搜索关键字” 在Composer内发送请求报文 Socket 123456789101112131415161718192021222324252627282930if __name__ == '__main__': # 读取信息 file = input(\"file:\") cont = input(\"cont:\") # 套接字连接服务端 s = ssl.wrap_socket(socket.socket()) s.connect(('www.baidu.com', 443)) # 发送修改后的请求 s.send(get_req(file, cont)) # 缓存服务端的响应 buffer = [] while True: d = s.recv(1024) if d: buffer.append(d) else: break res = b''.join(buffer) # 客户端关闭套接字 s.close() # 保存响应 header, html = res.split(b'\\r\\n\\r\\n', 1) print(header.decode('utf-8')) with open(cont + '.html', 'wb') as f: f.write(html) 记响应时间FiddlerPyCurlUrllibRequest实例的演示 [仅使用Fiddler抓包、修改、发包](录屏链接To be continue…) [Fiddler抓包+Python修改+Socket发包](录屏链接To be continue…) 需注意事项报文格式 无论使手动还是脚本保存会话的请求报文，都需要注意每个属性是否以 \\r\\n 结尾，最后属性是否以 \\r\\n\\r\\n 结尾 遇到 HTTP 400 Bad Request 响应仔细检查报文格式是否正确 编码问题 注意保存会话的编码格式，手动保存使用编码格式 utf-8 ，脚本保存使用编码格式 utf-16 Socket发送报文和接受报文都需要二进制数据 Fiddler默认使用GZip格式压缩，在发送请求报文时为确保响应主题非乱码，应该去除 Accept-Encoding: gzip, deflate 这行属性 端口问题 Socket通信需要知道主机地址及其端口号 Fiddler Sessions或Inpectors可知主机地址及其端口号 保存的TCP报文（使用Wireshark）可知主机地址及其端口号 保存的HTTP/HTTPS报文（使用Fiddler）仅知主机地址，已知常用端口：HTTP为80/HTTPS为443 请求变化 Break on Response 和 Run to Completion 对应会话并不相同 待改进事项 优化过滤会话和替换内容脚本（正则表达式） 发送响应回浏览器（Socket向其它进程发报文） 持续化、多线程抓包、修改、发包（多线程编程）","link":"/2019/10/11/HTTP的通信监控和回放：Fiddler抓包与Socket发包/"},{"title":"#Docker# LinuxOne上的Docker初体验","text":"在LinuxOne上利用Docker部署应用与服务，主要分为以下五个部分： 环境准备 Environment Docker原理 Theory Docker使用 Usage Docker实战 Practice 注意事项 Notices 目录 Table of Contents 环境准备 Environment申请Github账号并配置好本地Git 廖雪峰Git教程 申请IBM ID账号并开通开发者账号 该步骤主要提供接口权限 Register IBM ID （统一邮箱） Create an API Developer Portal account （统一邮箱） Apps Create new App Configure the App: Title: $TITLE Sumbit Client ID Client Secret API Products Use banking API Subscribe Default Plan Select Previous App Subscribe 申请IBM LinuxOne账号 该步骤主要提供部署环境 Virtual Machine Login Virtual Services Manage Instances Create Instances Configure the Instance Type: General purpose VM Instance Name: $INSTANCE_NAME Instance Description: $INSTANCE_DESCRITION Image: RHEL7.6 SSH Key Pairs: Create → Save → Select → Create Check the Instance Status: Active Linux User: linux1 IP Address: 148.100.xxx.xxx Private Cloud Login Catalog openmplbank Configure Input Release name Select Target Namespace Install View Helm Release Deployment AVAILABLE = 1 Launch 安装Node.js环境 安装Node.js: Download | Node.js 检查是否安装成功: 12$ node -v$ npm -v 安装SSH登录工具 Windows：可选PuTTY或Xshell或WSL Linux：ssh -i /path/to/key/keyname.pem linuxusername@serveripaddress Docker原理 Theory工作流程 名词辨析 概念 含义 Docker 镜像(Images) Docker镜像是用于创建Docker容器的模板。 Docker 容器(Container) Docker容器是独立运行的一个或一组应用。 Docker 客户端(Client) Docker客户端通过命令行或者其他工具使用Docker API，与Docker的守护进程通信。 Docker 主机(Host) Docker主机是一个物理或者虚拟的机器用于执行Docker守护进程和容器。 Docker使用 Usage安装 安装docker 123456789101112# 下载Docker归档包wget ftp://ftp.unicamp.br/pub/linuxpatch/s390x/redhat/rhel7.3/docker-17.05.0-ce-rhel7.3-20170523.tar.gz# 解压Docker归档包tar -xzvf docker-17.05.0-ce-rhel7.3-20170523.tar.gz# 迁移Docker归档包# !!! 这里直接cp到/usr/bin就好，因为/usr/local/bin不在PATH环境变量里 !!!cp docker-17.05.0-ce-rhel7.3-20170523/docker* /usr/bin/ 安装docker-compose 12345678910111213141516171819202122232425262728293031# 查看python-setuptoolsyum info python-setuptools# 安装python-setuptoolsyum install -y python-setuptools# 安装pipeasy_install pip# 网速过慢的话先禁用掉 IPv6echo 1 &gt; /proc/sys/net/ipv6/conf/all/disable_ipv6# 升级backports.ssl_match_hostnamepip install backports.ssl_match_hostname --upgrade --ignore-installed# 先安装依赖，不然会报错yum install python-devel libffi-devel# 安装docker-composepip install docker-compose==1.13.0# 查看docker-compose安装情况和版本信息docker-compose version 命令 后台启动daemon进程 1234# -g 设置Docker Daemon运行时的根目录# &amp; 放在命令后面表示设置此进程为后台进程docker daemon -g /local/docker/lib &amp; 命令查看docker信息 1234567# 查看当前机器docker版本老旧docker version# 检查后台有无docker进程运行ps aux | grep docker docker镜像处理 1234567891011# 查看所有镜像docker images# 拉取远程镜像docker image pull repository:tag# 构建本地镜像docker build -t \"repository:tag\" ./ docker容器处理 1234567891011# 查看所有容器docker ps# 创建运行容器docker run image# 停止运行容器docker stop container docker服务处理 1234567891011# 查看所有服务docker-compose ps# 创建运行服务docker-compose up# 停止运行服务docker-compose down docker build 123# -t 在新容器内指定一个伪终端或终端docker build -t \"repository:tag\" ./ docker run 12345# -d 开启daemon模式# -i 允许你对容器内的标准输入 (STDIN) 进行交互# -p 指定端口映射规则docker run -d -i -p ipadress1:port1/protocal:ipadress2:port2/protocal repository:tag docker-compose up 1234# -d 开启daemon模式# 端口映射和镜像来源都写在了.yml配置文件docker-compose up -d docker exec 1234# -i 允许你对容器内的标准输入 (STDIN) 进行交互# -t 在新容器内指定一个伪终端或终端docker exec –it container bash Docker实战 Practice切换权限和路径，配置用户习惯123456789101112131415# 切为根用户，否则没有权限sudo su# 切到家目录，否则难找文件cd ~# RHEL 7.6已经自带安装了VIM 7.4，启动命令是vi，习惯用vim命令的同学可以先设置一下别名[当前生效]alias vim='vi'# RHEL 7.6已经自带安装了VIM 7.4，启动命令是vi，习惯用vim命令的同学可以先设置一下别名[永久生效]# !!! 可以将alias vim='vi'加到~/.bashrc中 !!!source ~/.bashrc 安装并运行 WebSphere Liberty（练习使用docker run）123456789# 手动拉取websphere-liberty镜像到本地docker image pull s390x/websphere-liberty:webProfile7# 后台运行容器，并指定端口映射规则docker run -d -p 80:9080 -p 443:9443 s390x/websphere-liberty:webProfile7# 浏览器访问http://[LinuxOne Host IP]，即可看到WebSphere Liberty的界面 安装并运行 WordPress（练习使用docker-compose up）12345678910111213141516171819202122232425262728293031323334353637383940# 创建docker-compose.ymlvim docker-compose.yml# 编辑docker-compose.ymlversion: '2'services: wordpress: image: s390x/wordpress ports: - 8080:80 # 将本地 8080 端口映射到容器的 80 端口 environment: WORDPRESS_DB_PASSWORD: example mysql: image: brunswickheads/mariadb-5.5-s390x environment: MYSQL_ROOT_PASSWORD: example:wq# 查看docker-compose.ymlcat docker-compose.yml# 创建wordpress目录方便整理mkdir wordpressmv docker-compose.yml wordpress/cd wordpress/# 根据docker-compose.yml中定义的服务启动容器docker-compose up -d# 创建完成后，查看相关容器的状态docker-compose ps# 浏览器访问http://[Your LinuxONE IP Address]:8080，即可看到 WordPress 的页面 安装并运行 Todo App（熟悉MEAN Stack + Docker架构）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# 为方便管理文件，切换到家目录cd ~# 从Github拉取源码到本地使用git clone https://github.com/IBM/Cloud-Native-Workloads-on-LinuxONE# 迁移源码文件夹到家目录cp -r Cloud-Native-Workloads-on-LinuxONE/files/mean-docker ./# 安装显示目录树的插件包yum install -y tree# 显示mean-docker的目录树tree mean-dockermean-docker├── docker-compose.yml # docker-compose 配置文件├── express-server│ ├── app│ │ ├── models│ │ │ └── todo.js│ │ └── routes.js│ ├── config│ │ └── database.js│ ├── Dockerfile # docker image 生成文件│ ├── license│ ├── package.json│ ├── public│ │ ├── index.html # 前端文件│ │ └── js│ │ ├── controllers│ │ │ └── main.js # 后端文件│ │ ├── core.js│ │ └── services│ │ └── todos.js # 数据库文件│ ├── README.md│ └── server.js└── README.md # 说明文档8 directories, 14 files# 修改Angular.js成国内镜像源vim mean-docker/express-server/public/index.htmlsrc=\"//cdn.bootcss.com/angular.js/1.2.16/angular.min.js\"# 查看Dockerfile的内容cd express-server/lsvim Dockerfile# 编辑Dockerfile的内容# Expose the port the app runs inEXPOSE 8081......# Express listening portENV PORT 8081:wq# 重新构建镜像cd mean-dockerdocker-compose down # 停止正在运行的容器docker-compose build # 先重新构建镜像docker-compose up # 再基于新镜像重新启动容器# 查看docker-compose.yml的内容cd mean-docker/lsvim docker-compose.yml# 编辑docker-compose.yml的内容# 因为之前本地的8080端口被 WordPress 占用了，所以这里我们使用8081端口......ports:- \"8081:8081\" # 本地 8081 端口映射到 express 容器的 8081 端口......:wq# 启动指定服务docker-compose up -d# 使用docker-compose ps命令查看启动的容器docker-compose ps# 浏览器访问http://[ip of machine]:8081，即可看到你的 TODO-List App Todo App前端插入数据、后端处理数据、数据库查数据（熟悉MEAN Stack + Docker前后端数据库交互）1234567891011121314151617181920212223242526272829......# 在运行的容器中执行命令docker exec –it meandocker_database_1 bash# 进入MongoDB&gt; mongo# 查看数据库&gt; show dbs# 指定数据库&gt; use docker-mean# 枚举数据表&gt; show tables# 查看元祖集&gt; db.todos.find()# 指定元祖项&gt; db.todos.find({\"key\": \"value\"}) 本地部署金融微服务（熟悉Localhost → Micro-services模式）12345678910111213141516171819202122232425# Fork ICp-banking-microservices 到自己账号下，将你Fork的项目git clone至本地# Github配置过SSHgit clone git@github.com:LotteWong/ICp-banking-microservices.git# Github未配置SSHgit clone https://github.com/YOUR_USERNAME/ICp-banking-microservices# 在banking-application/public/js/bankingAPI.js中填入你的Client ID和Client Secret# 进入ICp-banking-microservices/banking-application目录，安装npm依赖npm install# 如果出现npm代理设置错误，重新设置代理即可npm config set registry \"http://registry.npmjs.org/\"# 进入ICp-banking-microservices/banking-application目录，启动应用node app.js# 浏览器访问http://localhost:3000，即可访问应用# 随便选择一个customer ID测试，若有JSON格式的数据返回，则说明API可用。如果出错可自排查，可能是ID和Secret不匹配（前往开发者页面的应用程序页面中验证ID和Secret）或者浏览器不支持网速较慢之类（更换浏览器更换网络源） 远程部署金融微服务（熟悉Docker → Micro-services模式）1234567891011121314151617181920212223242526272829303132333435363738# 在非 LinuxOne 的本机将项目推送至 Github 远程仓库# !!! 实际上不应该把Client ID和Client Secret这种密钥类型的数据推到 Github 上，这里为了方便实验暂时这么做，以后切勿模仿。 !!!git add public/js/bankingAPI.jsgit commit -m \"Update of bankingAPI.js\"git push origin master# 先登录你的 LinuxONE 主机实例，为方便管理文件，切换到家目录cd ~# 将你 Fork 后又更新的代码拉取到本地# Github配置过SSHgit clone git@github.com:LotteWong/ICp-banking-microservices.git# Github未配置SSHgit clone https://github.com/YOUR_USERNAME/ICp-banking-microservices# 构建 Docker 镜像docker build -t \"respository:tag\" ./# 查看 Docker 镜像docker images# 启动 Docker 容器docker run -p 3000:3000 respository:tag# 查看 Docker 容器docker ps# 浏览器访问http://[LinuxOne Host IP]:3000，即可访问应用# 随便选择一个customer ID测试，若有JSON格式的数据返回，则说明API可用。如果出错可自排查，可能是ID和Secret不匹配（前往开发者页面的应用程序页面中验证ID和Secret）或者浏览器不支持网速较慢之类（更换浏览器更换网络源） 云端部署金融微服务（熟悉Cloud → Micro-services模式）123# 到 ICP 中部署好的应用，点击启动，浏览器会自动跳转到分配的端口# 之后就和此前的实验一样了，只不过你的应用是部署在 ICP 上，由 Kubernetes 自动维护可用的 Pod 数量 注意事项 Notices 端口映射就是将主机的IP地址的一个端口映射到局域网中一台机器，当用户访问这个IP的这个端口时，服务器自动将请求映射到对应局域网分机。 .pem为通用证书格式，ppk为PuTTY下面的专有格式。两者都为SSH Key Pairs格式，内含公钥和密钥。 镜像是类，容器是对象，服务是对象集。Dockerfile用于构建镜像；docker-compose.yml用于组织镜像；docker run用于启动容器；docker-compose up用于启动服务。 使用Docker需要非常注意卷的管理，如果采用默认匿名的方式而不指定卷的位置，服务器的容量很快就会被每次重新生成的同一镜像给爆掉。 MEAN Stack包括MongoDB（数据库）、Express.js（路由）、AngularJS（前端）和Node.js（后端）。本次实验最终项目友链 👉 SCUT Online Bank Application。","link":"/2019/09/18/LinuxOne上的Docker实践/"},{"title":"#WSL# WSL从入门到...(2) Dive into WSL 1","text":"对 WSL 1 的一些实现细节进行补充说明，主要分为以下五个部分： 前情提要 背景 架构与功能 总结 参考链接 目录 Table of Contents 前情提要 前面已经简要介绍了 WSL 1 和 WSL 2 的区别，本节将聚焦于 WSL 1的实现细节。点开官方博客开始收获惊(da)喜(keng)，才疏学浅写错也不要打我 (预先感谢各位勘误 逃 【更多信息 👉 WSL从入门到…(1) WSL 1 vs WSL 2】 背景 Early subsystems were implemented as user mode modules that issued appropriate NT system calls based on the API they presented to applications for that subsystem. All applications were PE/COFF executables, a set of libraries and services to implement the subsystem API and NTDLL to perform the NT system call. When a user mode application got launched, the loader invoked the right subsystem to satisfy the application dependencies based on the executable header. 早期的子系统采用的方法是，将子系统视为上层的一系列进程组，通过 NTDLL 提供的 API 实现用户模式和内核模式通信，其中 loader 对 application 和 subsystem 进行管理。这里运行的仍然是 Win32 binaries，需要移植和维护。 Later versions of subsystems replaced the POSIX layer to provide the Subsystem for Unix-based Applications (SUA). The primary role of SUA was to encourage applications to get ported to Windows without significant rewrites. This was achieved by implementing the POSIX user mode APIs using NT constructs. 后来的子系统采用的方法是，在 POSIX 层做优化，移植而不是重写。这里运行的仍然是 Win32 binaries，需要移植和维护。 WSL is a collection of components that enables native Linux ELF64 binaries to run on Windows. It contains both user mode and kernel mode components. It is primarily comprised of: User mode session manager service that handles the Linux instance life cycle Pico provider drivers (lxss.sys, lxcore.sys) that emulate a Linux kernel by translating Linux syscalls Pico processes that host the unmodified user mode Linux (e.g. /bin/bash) WSL 采用的方法是，构造一整套包含用户模式和内核模式组件的系统，其主要由用户模式会话管理服务（User mode session manager service）、Pico 驱动（Pico provider drivers）和 Pico 进程 （Pico processes）三个部分组成。这里运行的仍然是 Linux binaries，无需移植和维护。 架构 工作流大概是：Windows 的 Bash 键入指令，交由 LXSS Manager Service 启动对应的 Linux 实例并进入对应的 Pico 进程，Linux 的 Bash 通过中间层的驱动器与 Windows Kernel 进行翻译交流（“The lxss.sys and lxcore.sys drivers translate the Linux system calls into NT APIs and emulate the Linux kernel.”）。 LXSS Manager Service LXSS Manager Service 负责 Windows 的 Bash（Win32 Process）和 Linux 的 Bash（Pico Process）之间的通信，主要在初始时工作。作用范围包括但不局限于：同步 Linux 实例的安装和卸载、每次只允许一个进程启动 Linux Binary 并在 pending 时阻塞后续启动进程等等。 Pico Drivers Pico Drivers 负责 Linux Instance（User Mode）和 Windows Kernel（Kernel Mode）之间的通信，主要在运行时工作。作用范围包括但不局限于：翻译 Linux system calls 为 Windows NT APIs 可以理解的形式，模拟 Linux 内核并对 Windows 内核进行操作等等。 Pico Processes 将可执行的 ELF binaries 加载进到 Pico Processes 的地址空间，并在 Linux 层上运行。其中 Linux 实例是一个特殊的为 Pico Processes 服务的数据结构，可以包含并追踪所有的 Linux 进程、线程和运行状态。它在 Win32 Process 首次启动 Linux Binary 时创建，在 Win32 Process 最后的客户端关闭连接时被销毁。从整体上看，整个 WSL 1 只有一个 Linux 实例，它隔离开了本机原有的 Windows 和所有新建的 Linux ；从内部来看，Linux 实例内的每个 Pico Process 都被单独隔离，这点和容器很类似。 功能 由于 Windows Kernel 和 Linux Kernel 基本上不兼容，需要额外处理很多中间转换，一般包括系统调用、文件系统、权限管理和网络配置等，下面介绍最基本和最重要的两个方面： System Calls syscall 是内核提供的一项服务，可以在用户模式下调用。Windows Kernel 和 Linux Kernel 都暴露了非常多的 syscall，但两者对此的设计模式并不同导致不兼容。 解决这种冲突的方法是引入 Pico Drivers（lxss.sys and lxcore.sys）。当一个 Linux Kernel syscall 被调用，该请求将被转发给 lxcore.sys，lxcore.sys 将 Linux Kernel syscall 翻译成等价的 Windows Kernel syscall，最后传到 Windows Kernel。特别地，如果在两种内核之间有某个 syscall 不存在映射关系（亦即不能互相翻译），lxss.sys 还被要求处理这种异常并提供相应的服务。 以 Linux 的 fork() 为例： As an example, the Linux fork() syscall has no direct equivalent call documented for Windows. When a fork system call is made to the Windows Subsystem for Linux, lxcore.sys does some of the initial work to prepare for copying the process. It then calls internal Windows NT kernel APIs to create the process with the correct semantics, and completes copying additional data for the new process. 以 Linux 的 chmod 为例： Linux Instance 产生附加 metadata，只由 Linux 文件系统能理解， Windows 文件系统并不能理解，但是 Windows Kernel 仍会接收该 metadata。但是 NTFS 对这个 metadata 无动于衷，而是 lxss.sys 处理该 metadata，最终反映到 ext4 中。由此可见，WSL 1 非常大的工作量都要花在应对不兼容的指令集。 PS: 尽管 Linux 的内核更新得非常快，用户模式的接口却是相对固定的，所以可以认为“WSL 1 abstracts the Linux kernel via their interface” File System 由于 Windows 和 Linux 的文件系统也不相同（Windows 的文件系统是 NTFS，Linux 的文件系统是 ext4），不能直接互相操作。WSL 的文件系统设计需要满足两点： 完整支持 Linux 文件系统 可访问和操作 Windows 中的磁盘和文件 为实现以上的目标 WSL 引入了两套文件系统（VolFs and DriveFs）。 VolFs 文件系统主要提供了 Linux 文件系统特性的支持，比如 Linux 文件目录（/etc, /bin, /usr, etc.）、权限管理和符号链接等等。DriveDs 文件系统主要用于与 Windows 做交互，比如 Windows 文件目录（/mnt/c, /mnt/d, etc.）、启动 Windows 的可执行文件等等。 PS: 需要注意的是，两套文件系统之间是如何进行交互的并未在原博客详细讨论，感兴趣的小伙伴可自行阅读续篇 WSL File System Support 总结 简单的理解：WSL 1 在 Windows Kernel 之上创建 Linux Instance，Win32 Process 通过 LXSS Manager Service 管理 Pico Process，用户模式的 Linux Instance 和内核模式的 Windows Kernel 之间通过 Pico Drivers 交流，依靠中间层驱动器翻译可以解决 System Calls 不兼容的问题，设计两套文件系统能够满足同时使用 Windows 和 Linux 的需要。 参考链接 Windows Subsystem for Linux Overview Project Drawbridge","link":"/2019/12/13/WSL从入门到...(2)/"},{"title":"#Blog# 从零到壹：GitHub Pages + Hexo = Blog","text":"利用GitHub Pages+Hexo打造一个个人博客，主要分为以下六个部分： 环境准备 Environment 文件配置 Configuration 个性化 Customization 博客写作 Writing 双备份 Backup 主机迁移 Migration 环境准备 Environment安装Git + Github 安装Git部署插件: 1$ npm install hexo-deployer-git --save 安装Node.js 安装Node.js: Download | Node.js 检查是否安装成功: 12$ node -v$ npm -v 安装Hexo 安装Hexo: 1$ npm install -g hexo-cli 检查是否安装成功: 1$ hexo -v 初始化: 1$ hexo init blog 文件配置 Configuration本地运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo s # 本地部署Hexo页面 远程运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo d # 远程部署Hexo页面 基本配置/_config.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: LotteWong # 个人博客显示名称subtitle: 在代码符号表象中避难。 # 个人博客副标题description: # 搜索引擎描述信息keywords: # 搜索引擎关键词author: LotteWong # 网站作者avatar: ./themes/icarus/source/images/favicon.ico # 网站头像language: en # 网站语言timezone: Asia/HongKong # 网站时区# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/plugins: # 设置个人博客插件theme: icarus # 设置个人博客主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git # 部署类型 repo: git@github.com:LotteWong/lottewong.github.io.git # 部署仓库 branch: master # 部署分支 个性化 Customization/themes/icarus/_config.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230# Version of the Icarus theme that is currently usedversion: 2.3.0# Path or URL to the website's iconfavicon: /images/favicon.ico# Path or URL to RSS atom.xmlrss: ./atom.xml# Path or URL to the website's logo to be shown on the left of the navigation bar or footerlogo: /images/logo.png# Open Graph metadata# https://hexo.io/docs/helpers.html#open-graphopen_graph: # Facebook App ID # fb_app_id: # Facebook Admin ID # fb_admins: # Twitter ID # twitter_id: # Twitter site # twitter_site: # Google+ profile link # google_plus: # Navigation bar link settings 顶部栏设置navbar: # Navigation bar menu links menu: Home: / Archives: /archives Categories: /categories Tags: /tags About: /about # Navigation bar links to be shown on the right links: Email: icon: far fa-envelope-open url: mailto:lottewong21@gmail.com# Footer section link settings 页尾栏设置footer: # Links to be shown on the right of the footer section links: GitHub: icon: fab fa-github url: 'https://github.com/LotteWong' RSS: icon: fas fa-rss url: /atom.xml# Sidebar settings. 侧边栏设置# Please be noted that a sidebar is only visible when it has at least one widgetsidebar: # left sidebar settings left: # Whether the left sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false # right sidebar settings right: # Whether the right sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false# Sidebar widget settings 侧边栏设置# https://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/widgets: - # Widget name type: profile # Where should the widget be placed, left or right position: left # Author name to be shown in the profile widget author: LotteWong # Title of the author to be shown in the profile widget author_title: SCUT, Undergraduate # Author's current location to be shown in the profile widget location: Guangzhou, China # Path or URL to the avatar to be shown in the profile widget avatar: # Email address for the Gravatar to be shown in the profile widget gravatar: # Whether to show avatar image rounded or square avatar_rounded: false # Path or URL for the follow button follow_link: 'https://github.com/LotteWong' # Links to be shown on the bottom of the profile widget social_links: Organization: icon: fas fa-sitemap url: 'https://github.com/SCUTMSC' Project: icon: fas fa-project-diagram url: 'https://github.com/scutse-man-month-myth/InkYear' - # Widget name type: toc # Where should the widget be placed, left or right position: left - # Widget name type: category # Where should the widget be placed, left or right position: left - # Widget name type: archive # Where should the widget be placed, left or right position: left - # Widget name type: recent_posts # Where should the widget be placed, left or right position: right - # Widget name type: tagcloud # Where should the widget be placed, left or right position: right - # Widget name type: tag # Where should the widget be placed, left or right position: right - # Widget name type: links # Where should the widget be placed, left or right position: right # Links to be shown in the links widget links: Bokjan: 'https://bokjan.com/' Kingsley: 'https://kingsleyxie.cn/' sticnarf: 'https://sticnarf.me/' xcw: 'https://yifanyu123.github.io/' Escape: 'https://www.cnblogs.com/escape-w/'# Article display settingsarticle: highlight: atom-one-light # Code highlight theme # https://github.com/highlightjs/highlight.js/tree/master/src/styles # theme: atom-one-light # Show code copying button # clipboard: true # Default folding status of the code blocks. Can be \"\", \"folded\", \"unfolded\" # fold: unfolded # Whether to show article thumbnail images thumbnail: true # Whether to show estimate article reading time readtime: true# Search plugin settings 搜索功能插件# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Searchsearch: # Name of the search plugin type: insight# Comment plugin settings 评论功能插件# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Commentcomment: # Name of the comment plugin type: gitalk owner: LotteWong repo: lottewong.github.io client_id: 31cfc7a3a72e1e062ccd client_secret: 2bbe6fbc0ec688642d56254b2b72a87b555ec76d admin: LotteWong# Donation entries 打赏功能插件# https://ppoffice.github.io/hexo-theme-icarus/categories/Donation/donate: # - # Donation entry name # type: alipay # Qrcode image URL # qrcode: '/images/alipay.png' # - # Donation entry name # type: wechat # Qrcode image URL # qrcode: '/images/wechat.png' # - # Donation entry name # type: paypal # Paypal business ID or email address # business: 'SuperGsama@outlook.com' # Currency code # currency_code: USD# Share plugin settings 分享功能插件# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Shareshare: # Share plugin name type: # Other plugin settingsplugins: # Enable page animations animejs: true # Enable the lightGallery and Justified Gallery plugins # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/gallery-plugin/ gallery: true # Enable the Outdated Browser plugin # http://outdatedbrowser.com/ outdated-browser: true # Enable the MathJax plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/mathjax-plugin/ mathjax: true # Show the back to top button on mobile devices back-to-top: true # Google Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Google-Analytics google-analytics: # Google Analytics tracking id tracking_id: # Baidu Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Baidu-Analytics baidu-analytics: # Baidu Analytics tracking id tracking_id: # Hotjar user feedback plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Hotjar hotjar: # Hotjar site id site_id: # Show a loading progress bar at top of the page progressbar: true # Show the copy button in the highlighted code area clipboard: true # BuSuanZi site/page view counter # https://busuanzi.ibruce.info busuanzi: true# CDN provider settings# https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/providers: # Name or URL of the JavaScript and/or stylesheet CDN provider cdn: jsdelivr # Name or URL of the webfont CDN provider fontcdn: google # Name or URL of the webfont Icon CDN provider iconcdn: fontawesome 博客写作 Writing 默认 1$ hexo new \"blog title\" 自定义 123456789101112title: {{ blog title }}categories: {{ blog category }}tags:- {{ blog tag }}toc: truethumbnail: {{ blog thumbnail }}{{ Abstract }}&lt;!-- more --&gt;{{ Content }} 双备份 Backup Hexo备份: 12# master branch$ hexo d Src备份: 12345# dev branch$ git checkout dev$ git add --all$ git commit -m \"new blog\"$ git push origin dev 主机迁移 Migration 已准备好环境： hexo-cli hexo-deployer-git 拷贝以下博客文件： _config.yml：配置文件 themes：主体文件 scaffolds：脚手架 source：博客文件 package.json：依赖文件 .gitignore：版本控制时忽略文件 执行以下相关命令： 12345$ npm install # 安装依赖$ hexo clean # 清理缓存$ hexo g # 重新生成$ hexo s # 本地预览$ hexo d # 远端部署 待办事项 Todos 对应图标 更多插件 绑定域名 更新外链 参考链接 References GitHub+Hexo 搭建个人网站详细教程 换电脑后如何迁移hexo博客 Hexo icarus","link":"/2019/06/02/从零到壹：GitHub Pages + Hexo = Blog/"},{"title":"#WSL# WSL从入门到...(4) Quick Start on WSL","text":"安装、配置并使用 WSL ，主要分为以下五个部分： 前情提要 安装发行版本 编写配置脚本 使用相关命令 参考链接 目录 Table of Contents 前情提要 终于结束漫长的听力翻译和阅读理解，开始真正搞机（期待地搓手手.gif。本文将解锁 WSL 1 初体验（发现 Windows build 版本好像快落后了一个世纪，WSL 2 装不了惹。 安装发行版本 配置相关： Windows 10 家庭中文版 1903 64 位操作系统，基于 x64 的处理器 WSL 1 Ubuntu 16.04 LTS Alpine WSL Step 1: 开启支持 WSL 选项 方法一：控制面板设置 “控制面板” -&gt; “程序” -&gt; “启用或关闭 Windows 功能” -&gt; “适用于 Linux 的 Windows 子系统” 重启电脑 方法二：输入命令设置 “Windows PowerShell（以管理员身份运行）” -&gt; Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 重启电脑 Step 2: 安装 Linux 发行版本 方法一：Microsoft Store 安装 打开应用商店 选择发行版本 Ubuntu 16.04 LTS Ubuntu 18.04 LTS OpenSUSE Leap 15 OpenSUSE Leap 42 SUSE Linux Enterprise Server 12 SUSE Linux Enterprise Server 15 Kali Linux Debian GNU/Linux Fedora Remix for WSL Pengwin Pengwin Enterprise Alpine WSL 安装发行版本 方法二：Command-Line/Script 安装 Manually download Windows Subsystem for Linux distro packages Step 3: 配置 Linux 发行版本 启动已安装好的 Linux 发行版本 点击启动： 菜单栏单击运行发行版本 磁贴板单击运行发行版本 命令启动： bash.exe ：默认目录为 Windows 用户目录 distro.exe：默认目录为 Linux 用户目录 wsl.exe：允许 Windows 和 Linux 的命令混用 等待 Linux 发行版本解压缩和初始化 创建 Linux 下的新用户及其密码 管理员用户之一 每次进入的默认用户 与 Windows 用户名无关 定期更新 Linux 下的 Package sudo apt update &amp;&amp; sudo apt upgrade PS: 常见报错解决页 👉 WSL troubleshooting page 编写配置脚本 WSL 支持使用 wsl.conf 来初始化自动挂载和网络配置两大功能。wsl.conf 位于 /etc目录，如果文件已存在，WSL 会自动读取适配；如果文件不存在，可以自行在目录内新建；如果文件出错了，WSL 会忽略配置文件。 自动挂载Section Label: [automount] key value default notes enabled boolean true true causes fixed drives (i.e C:/ or D:/) to be automatically mounted with DrvFs under /mnt. false means drives won’t be mounted automatically, but you could still mount them manually or via fstab. mountFsTab boolean true true sets /etc/fstab to be processed on WSL start. /etc/fstab is a file where you can declare other filesystems, like an SMB share. Thus, you can mount these filesystems automatically in WSL on start up. root String /mnt/ Sets the directory where fixed drives will be automatically mounted. For example, if you have a directory in WSL at /windir/and you specify that as the root, you would expect to see your fixed drives mounted at /windir/c options comma-separated list of values empty string This value is appended to the default DrvFs mount options string. Only DrvFs-specific options can be specified. Options that the mount binary would normally parse into a flag are not supported. If you want to explicitly specify those options, you must include every drive for which you want to do so in /etc/fstab. 网络配置Section label: [network] key value default notes generateHosts boolean true true sets WSL to generate /etc/hosts. The hosts file contains a static map of hostnames corresponding IP address. generateResolvConf boolean true true set WSL to generate /etc/resolv.conf. The resolv.conf contains a DNS list that are capable of resolving a given hostname to its IP address. 交互操作Section label: [interop] These options are available in Insider Build 17713 and later. key value default notes enabled boolean true Setting this key will determine whether WSL will support launching Windows processes. appendWindowsPath boolean true Setting this key will determine whether WSL will add Windows path elements to the $PATH environment variable. 具体示例1234567891011# Enable extra metadata options by default[automount]enabled = trueroot = /windir/options = \"metadata,umask=22,fmask=11\"mountFsTab = false# Enable DNS – even though these are turned on by default, we’ll specify here just to be explicit.[network]generateHosts = truegenerateResolvConf = true 使用相关命令查看版本列表 wsl -l, wsl --list：可用的 Linux 发行版 wsl --list --all： 未可用和已可用的 Linux 发行版 wsl --list --running：运行的 Linux 发行版 设置默认版本 wsl -s &lt;DistributionName&gt;, wsl --setdefault &lt;DistributionName&gt; 重新安装版本 wsl --unregister &lt;DistributionName&gt; 重复“安装发行版本”的“Step 3: 配置 Linux 发行版本” 指定参数登录 wsl -d, wsl --distribution：指定版本登录 wsl -u, wsl --user：指定用户登录 交互操作选择 $ echo 0 &gt; /proc/sys/fs/binfmt_misc/WSLInterop：停用交互操作 $ echo 1 &gt; /proc/sys/fs/binfmt_misc/WSLInterop：开启交互操作 Windows命令行运行Linux工具 wsl &lt;LinuxCommand&gt; 12345C:\\temp&gt; wsl ls -la | findstr \"foo\"-rwxrwxrwx 1 root root 14 Sep 27 14:26 foo.batC:\\temp&gt; dir | wsl grep foo09/27/2016 02:26 PM 14 foo.bat Linux命令行运行Windows工具 &lt;WindowsCommand&gt; 123456$ cmd.exe /C dir&lt;- contents of C:\\ -&gt;$ PING.EXE www.microsoft.comPinging e1863.dspb.akamaiedge.net [2600:1409:a:5a2::747] with 32 bytes of data:Reply from 2600:1409:a:5a2::747: time=2ms PS: 以上适用于 “Windows 10 Version 1903 and later“, “Versions Earlier than Windows 10 Version 1903 “的对应目录请查看文末的参考链接。Windows Insiders Builds 17063 起支持 Windows 和 Linux 共享环境变量；Fall Creators Update 起 Windows Path 将加入 Linux $PATH 。 参考链接 Windows Subsystem for Linux Documentation","link":"/2019/12/15/WSL从入门到...(4)/"},{"title":"#Unit Test# Unit Test Pre-study and Practice in Python","text":"If you write code, write tests. – The Way of Testivus 目录 Table of Contents 背景 近期由于工作需要，遂矛头瞄准了单元测试这片“无人之地”（bushi。单元测试的对比及意义将不会在本文赘述，一些概念的辨析也不会深究，但我个人认为最理想的观感至少应该满足两点：① 可以快速并重复地验证结果是否符合预期（毕竟不会有人写完代码不自测吧，汗.jpg）；② 将来某一天面临重构时不至于心慌慌。 提出的这两点要求看似简单明了实则十分模糊，所以单元测试是没有固定套路的，需要在方法论的指导下和团队的实践中不断完善。值得注意的是，在很多情况下我们都会”先上车后补票“（which 不是一种好习惯，因此我们也会面临额外的难题。 本文将以 Python 工程为例，预研单元测试的可行方案（仍有很大的进步空间，to be continued… 主要讨论以下内容： 测试流程：3A 原则；使用 Stub 和 Mock 测试用例：测试哪些内容；如何设计测试用例；如何管理测试数据；用例的规范性 技术选型：pytest、mock 及第三方的插件 工程实践：如何设计脚手架；脱敏案例实践与分析 常见问题：被测单元具有不可测性怎么办；单元测试如何保证质量 测试流程遵循 3A 原则编写单元测试用例，流程遵循 3A 原则： Arrange：准备测试数据 Action：调用被测单元 Assert：判断测试结果 Stub 和 Mock我们的工程很可能涉及到数据库的操作或外部服务调用等情况，如果我们认为单元测试应当是尽可能独立的（不同的声音见：Mock 七宗罪），那么我们就需要替换它们： Stub：一般指数据上的模拟 Mock：一般指数据上和行为上的模拟 测试用例测试粒度和优先级 优先测试业务层，而不是接口层，也不是持久层（牺牲了覆盖率，但最具性价比） 优先测试正在被频繁使用的函数 优先测试重要程度要更高的函数 优先测试代码逻辑更复杂的函数 优先测试经常会发生变更的函数 设计测试用例首先我们应该明确，单元测试本质上是一种白盒测试，所以代码分支的分析是必要的。 其次感谢来自测试同事的技术分享，帮助回顾了在软件测试课程中学习到的几种常见方法，还引入了正交试验的概念。下面主要关注其中三种： 等价类/边界值：适用于参数化 正交试验：多分支情况下，如何选出最优用例组合 流程分析：处理异常情况 管理测试数据需要管理的测试数据大致可以分为两类： 全局通用：作为全局常量写入统一的文件中 局部可用：在单元测试类中定义，可使用装饰器组织输入、输出和模拟的数据 用例的规范性存放位置 功能测试类代码：放在主要测试的代码目录的 /tests/functional 中 单元测试类代码：放在主要测试的代码目录的 /tests/unit 中 用例命名 测试文件命名：以 test_ 开头或以 _test 结尾（遵循下划线命名法） 测试类命名：以 Test 开头（遵循驼峰命名法） 测试方法命名：以 test_ 开头（遵循下划线命名法） 命名格式建议：为提高测试用例的可读性，测试方法可参考 test_[测试单元名称]_[测试场景]_[测试期望结果] 来命名，如 test_create_user_in_openstack_success create_user 为测试单元名称 in_openstack 为测试场景 success 为测试期望结果 技术选型单测框架通过以下对比，Python工程项目建议选用使用更简洁、功能更丰富且兼容性更好的 pytest 测试框架。 unittest Python语言的标准单元测试框架 提供了 test cases、test suites、test fixtures、test runner 等功能 nose 基于 unittest 扩展插件 兼容 unittest 的测试集 pytest 支持比 unittest 更简单的断言和众多的装饰器 支持测试用例分类标记和运行 支持测试数据输入的参数化 兼容 unittest 和 nose 的测试集 丰富的插件和活跃的社区 此处补充如何让 PyCharm 支持 pytest 的使用，至此 pytest 已经可以同时使用 IDE 或 CLI 来运行测试用例。 具体方法：修改 PyCharm 设置，file -&gt; Setting -&gt; Tools-&gt; Python Integrated Tools -&gt; ${ProjectName} -&gt; Default test runner -&gt; Choose pytest (unittest by default) 模拟框架在单元测试的过程中，需要对数据库访问和使用的外部服务进行 mock，我们希望可以实现： 模拟期望的返回数据 模拟期望的调用行为 模拟出错时抛出异常 由于 Python 作为一门动态语言，在运行时替换函数方法和成员变量是很容易实现的，即我们相对而言可以在不改动原有代码的情况下就实现单元测试的编写；为了更方便和更规范地使用mock功能，我们可以选用 Python 的 mock 库。 mock Python 最广泛被使用的 mock 第三方库，Python 3.3 后被列入标准库中 支持模拟返回值和副作用，以及进行调用的断言 其它工具控制台打印的测试日志既不直观也不能持久地保存，我们需要一个可以帮助输出测试报告的工具。由于测试框架已选用 pytest，测试报告工具可使用 pytest 的插件 pytest-html。 pytest-html 可输出多种文件格式的测试报告 可作为插件集成到 pytest 使用 统计代码覆盖率有助于反推被测代码和单元测试设计的合理性。代码覆盖率高不能说明代码质量高，但是代码覆盖率低那么代码质量一般都不高。由于测试框架已选用 pytest，覆盖统计工具可使用 pytest 的插件 pytest-cov。 pytest-cov 兼容 coverage 库 可作为插件集成到 pytest 使用 工程实践脚手架设计单元测试脚手架可以封装一些公共行为，提供以下功能： 管理公共和临时的测试数据 封装正常调用和异常调用的流程 完备的报错提醒和日志记录 … 某案例分析Step 1：源码分析阅读源码，整理出代码流程图 Step 2：用例设计根据前述的设计建议，分别采取等价类/边界值、正交试验和流程分析等方法合理设计测试用例。应当记录（必要时可以进行合并的操作）： 输入数据 输出期望 场景总数 异常分支 Step 3：运行用例PyCharm 内置支持运行测试或 Terminal 输入命令运行测试 pytest 常用命令：pytest [options] [file_or_dir] [file_or_dir] […] -s：控制台输出被测单元print的数据 -k：运行包含关键字的用例 -m：运行包含分类标记的用例 -v：打印用例执行的详细过程 -q：打印用例执行的简略过程 Step 4：分析结果获得测试结果报告（pytest-html） 安装 pytest-html 插件：pip install pytest-html 执行 pytest 命令：pytest [options] [test_file_or_dir] [test_file_or_dir] […] –html=[file]，如 pytest ./venus –html=./venus/tests/unit/htmlrept.html 测试结果以更美观和持久化的形式被保存下来 获取覆盖情况报告（pytest-cov） 安装 pytest-cov 插件：pip install pytest-cov 执行 pytest 命令：pytest [options] [test_file_or_dir] [test_file_or_dir] […] –cov=[src_dir_or_module] –cov-report=html，如 pytest ./venus –cov=venus.cloud.node_network –cov-report=html 白色为被单元测试覆盖到的代码，红色表示未被单元测试覆盖的代码 常见问题不可测性单元测试的工作量比开发程序的工作量要大几乎是肯定的，但是如果你发现在掌握了一定的科学方法之后仍觉得写的十分痛苦，那么你该思考是不是因为这个被测单元本身就不具备可测性。 对现有的项目进行单元测试补充，常常会遇到这样的问题：函数代码逻辑冗杂、架构层次设计不够合理导致无法注入替换等等。这时，我想我们不得不对其进行重构了（本文对此不展开讨论，感兴趣可以阅读宝典《重构：改善既有代码的设计》）。 单测质量只要是代码都将面临质量的考验，单元测试也不例外。 从程序本身而言，我们所能做的可以是遵循一些实用的原则： 单元测试不要掺杂逻辑 每个用例针对单一情景 使用经得起考验的脚手架和工具 … 对开发人员来说，一些必要的意识是应该培养的： 单元测试重视起来，条件允许的话考虑 TDD 开发 单元测试也应该和业务代码一样接受代码评审 循序渐进，先会写，再写好，最后优化 … 参考链接 以下文章对本文亦有贡献 :) 从头到脚说单测——谈有效的单元测试 测试扁平化之必备神器：好的单元测试 附录 使用文档和最佳实践 :) pytest 官方文档 mock 官方文档 pytest 插件列表 OpenStack Nova 单元测试源码","link":"/2020/11/19/Unit Test Pre-study and Practice in Python/"},{"title":"#Microservice# 微服务API网关的设计与实现(4) 数据库设计","text":"本文主要介绍微服务API网关的数据库设计，分为两个方面： MySQL 数据库表设计 - E-R图及关系模式 Redis 键值设计 目录 Table of Contents 数据库数据库三范式 1NF是对属性的原子性，要求属性不可再分解。 2NF是对记录的唯一性，要求记录有唯一标识，即不存在部分依赖。 3NF是对字段的冗余性，要求任何字段不能由其他字段中派生出来，即不存在传递依赖。 绘制E-R图例 确定所有的实体（矩形框） 确定实体的联系（连线） 确定实体和联系的属性（椭圆框） 确定实体的键（下划线） 转换关系模式 类型 映射方法 说明 一元联系 直接映射 实体的属性→关系模式的属性；实体的主键→关系模式的主键 二元联系 - 一对一 合并关系模式 合成一个关系模式 R；任一实体的全部主键→关系模式的主键 二元联系 - 一对多 引入外键 一方实体的主键→多方实体的外键；联系的属性→多方实体的属性 二元联系 - 多对多 增加关系模式 增加一个关系模式 R；两个实体的主键并集→关系模式的主键；联系的属性→关系模式的属性 超类子类 分化关系模式 分化两个关系模式 R1 和 R2；R1是父关系模式，包括R1主键和R1非主键；R2是子关系模式，包括R1主键和R2非主键；若概括是全部的，不用创建父关系模式，子关系模式包括所有 复合属性 由子属性代替 复合属性 A → 多个子属性代替 A1, A2, A3, … 多值属性 拆分关系模式 拆成两个关系模式 R1 和 R2；R1包括R的主键和M的本身；R2包括R的主键和除多值属性外的属性；注意设置级联操作 MySQL 数据库表设计用户的数据库表设计 实体 用户实体拥有用户ID、用户名称、加密密码和加密盐值四种属性，其中出于安全性的考虑，密码需要经过盐值加密后存储在数据库而非直接明文存储。 联系 没有联系可以分析。 转换 对用户的E-R图进行一元联系类型转换，得出关系模式：用户实体的属性为独立的一张表。 服务的数据库表设计 实体 服务实体拥有服务ID、服务名称、服务描述和协议类型四种属性，其中协议类型是多值属性，用于扩展和适配接入不同协议的服务，目前可支持 HTTP、HTTPS 和 WebSocket 协议。 协议接入与请求重写配置实体固定具有地址和重写规则属性，从协议接入与请求重写配置中可以泛化出各种类型的协议配置，不同协议的配置内容不尽相同。 权限认证配置实体包含ip黑白名单的属性，用于鉴别请求来源。 流量控制配置实体是相对服务而言的，具有限流间隔和限流次数属性，可以支持周期灵活的限流策略。 负载均衡配置实体有三大属性，分别为ip列表、weight列表和算法类型，其中算法类型是多值属性，标识了负载均衡使用的算法，目前支持随机负载均衡、轮询负载均衡、加权轮询负载均衡和一致性哈希负载均衡四种算法。 联系 服务实体与协议接入与请求重写配置实体、权限认证配置实体、流量控制配置实体、负载均衡配置实体和反向代理配置实体的关系都是一对一的拥有关系。特别地，协议接入配置实体存在泛化，可以衍生出不同类型的协议接入与请求重写配置。 转换 对服务的E-R图进行二元联系类型转换，得出关系模式：服务实体与权限认证配置实体、流量控制配置实体、负载均衡配置实体和反向代理配置实体合并为一张数据库表，为了考虑后续对其他协议进行扩展，故每种协议配置都建议新建一张数据库表。 应用的数据库表设计 实体 应用实体拥有应用ID、应用标识、应用名称和应用密钥四种属性，其中出于安全性的考虑密钥应该存储加密后的密文而非明文。 权限认证配置实体包含ip黑白名单的属性，用于鉴别请求来源。 流量控制配置实体是相对应用而言的，具有QPD（每日请求量）限制和QPS（每秒请求量）限制两种属性。 联系 应用实体与权限控制配置实体和流量控制配置实体的关系都是一对一的拥有关系。 转换 对应用的E-R图进行二元联系类型转换，得出关系模式：服务实体与权限认证配置实体和流量控制配置实体合并为一张数据库表。 Redis 键值设计会话的键值设计 键 值类型 值内容 session_{session_id} Binary 会话信息 配置的键值设计 键 值类型 值内容 app_{app_id} String app po as json service_{service_id} String service po as json lb_{lb_id} String load balance po as json ac_{ac_id} String access control po as json 计数器的键值设计 键 值类型 值内容 flow_day_count_{day_format}_flow_total_count String 总计每一天的流量统计数 flow_hour_count_{hour_format}_flow_total_count String 总计每小时的流量统计数 flow_day_count_{day_format}_flow_service_count_{service_name} String 单个服务每一天的流量统计数 flow_hour_count_{hour_format}_flow_service_count_{service_name} String 单个服务每小时的流量统计数 flow_day_count_{day_format}_flow_app_count_{app_id} String 单个应用每一天的流量统计数 flow_hour_count_{hour_format}_flow_app_count_{app_id} String 单个应用每小时的流量统计数 限流器的键值设计 键 值类型 值内容 rate_flow_service_count_{service_name} String 单个服务调用结束的时间点 rate_flow_app_count_{app_id} String 单个应用调用结束的时间点 Refs 数据库逻辑设计之三大范式通俗理解 数据库ER图基础概念整理 如何画好ER图 将E-R图转换成关系模式 数据库设计过程","link":"/2021/06/03/微服务API网关的设计与实现(4)/"},{"title":"#DevOps# 部署服务的N种姿势","text":"本文主要记录工作中服务常见的部署方式，旨在于 cover 日常的 CI/CD 场景： 进程+单机：systemctl + rpm 容器+单机：docker-compose + image 容器+集群：k8s + image systemctl + rpm systemctl：自行注册/启动/更新/停止 rpm：流水线生成 rpm，自行安装/更新 注册服务12345678910111213141516171819vim /usr/lib/systemd/system/wework-service.service[Unit]Description=wework-serviceAfter=network.target[Service]User=rootGroup=rootPermissionsStartOnly=trueExecStart=/usr/bin/wework-service --config=/etc/wework-service/config.yamlRestart=alwaysLimitNOFILE=65535WorkingDirectory=/usr/share/wework-service[Install]WantedBy=multi-user.target:wq 保证 WorkingDirectory 必须存在，否则抛出错误，解决方法如下： 12# Failed at step CHDIR spawning /xxx: No such file or directorymkdir -p /usr/share/wework-service 保证 ExecStart 可以执行，交叉编译二进制可执行文件，设置权限为可执行，具体命令： 12345678# 交叉编译set CGO_ENBALED=0set GOOS=linuxset GOARCH=amd64go build -o cmd/server/wework-service cmd/server/main.go# 设置权限chmod 755 /usr/bin/wework-service 启动服务12345678910# Step 1: 初次交叉编译# Step 2: 上传二进制可执行文件（若配置文件也更新，同步上传配置文件）# Step 3: 初次设置权限rpm -ivh wework-service-0.0.0-dev.1.xxxxxxx.rpm # 安装 rpm 包sudo systemctl daemon-reload # 重新加载配置文件sudo systemctl enable wework-service.service # 录入服务sudo systemctl start wework-service.service # 启动服务sudo systemctl status wework-service.service # 查看服务journalctl -u wework-service.service # 查看服务运行日志 更新服务12345678# Step 1: 重新交叉编译# Step 2: 上传二进制可执行文件（若配置文件也更新，同步上传配置文件）# Step 3: 重新设置权限rpm -Uvh wework-service-0.0.0-dev.1.xxxxxxx.rpm # 更新 rpm 包sudo systemctl restart wework-service.service # 重启服务sudo systemctl status wework-service.service # 查看服务journalctl -u wework-service.service # 查看服务运行日志 停止服务123sudo systemctl stop wework-service.service # 停止服务sudo systemctl status wework-service.service # 查看服务journalctl -u wework-service.service # 查看服务运行日志 docker-compose + image docker-compose：提供编排配置文件 image：流水线生成 image，直接从公司仓库拉或者下载上传镜像 docker-compose yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# /data/wework-service/base.yamlversion: \"2.1\"services: # 中间件 mongo-standalone: image: ${mongo-standalone-image} privileged: true healthcheck: test: [] interval: 10s start_period: 15s environment: MONGO_INITDB_ROOT_USERNAME: username MONGO_INITDB_ROOT_PASSWORD: password MONGO_INITDB_DATABASE: database volumes: # 挂载 volume - /etc/localtime:/etc/localtime:ro - /data/xxx/install/init_script/mongo:/docker-entrypoint-initdb.d - /data/xxx/mount_points/mongodb:/data/db ports: # 映射 port - 27017:27017 restart: always command: --replSet rs0 # 微服务 wework-service: image: ${wework-service-image} privileged: true volumes: # 挂载 volume - /etc/localtime:/etc/localtime:ro - /data/xxx/conf/wework-service/config.yaml:/etc/wework-service/config.yaml - /data/xxx/logs/wework-service:/var/log/wework-service ports: # 映射 port - xxxx:xxxx restart: always # 启动顺序 step-0: image: ${wait-for-dependencies-image} environment: TIMEOUT_LENGTH: 60 depends_on: - mongo-standalone command: mongo-standalone:27017 step-1: image: ${wait-for-dependencies-image} environment: TIMEOUT_LENGTH: 30 depends_on: - wework-service command: wework-service:xxxxnetworks: default: driver: bridge ipam: config: - subnet: ${subnet_segment} 访问服务1http://{node_ip}:{port} 或 http://{domain}:{port} 更新服务更新配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 修改配置文件（修改挂载路径的不是容器内部的）vim /data/xxx/conf/wework-service/config.yaml:wq# -------------------------------------------------------------------# 执行更新脚本#!/bin/bash# 读取参数if [ \"$1\" ]then container_name=$1else echo -e \"usage: ./restart.sh container-name\\n e.g. ./restart.sh wework-service\" exit 1fi# 重启容器container_id=$(docker ps -a | grep \"${container_name}\" | awk '{print $1}')if [ \"$container_id\" == \"\" ]then echo \"container not found!\" exit 1fiecho -n \"restarting ${container_name}... \"docker restart \"${container_id}\" &gt; restart.log &amp;# 健康检查PID=$!marks=( '/' '-' '\\' '|' )while s=$(ps -p $PID -o s=) &amp;&amp; [[ \"$s\" &amp;&amp; \"$s\" != 'Z' ]]; do echo -ne \"\\b${marks[i++ % ${#marks[@]}]}\"; sleep 0.5doneoutput=$(cat restart.log)if [ \"$output\" == \"$container_id\" ]then echo -e \"\\b\\e[32mDone.\\033[0m\"else echo -e \"\\b\\e[31mFailed!\\033[0m\" echo \"$output\"fi 更新镜像12345678910111213141516171819202122232425262728# 镜像获取# 1. 先从本地仓库查找（如果不能ping通公司的仓库，需要下载→保存→上传→加载流程）# 2. 再从远程仓库下载（如果可以ping通公司的仓库，可以直接让脚本跑）# -------------------------------------------------------------------# 执行更新脚本#! /bin/bash# 读取参数docker_service_name=$1service_tag=$2if [[ $# -lt 2 ]];then echo \"please input two param for docker_service_name and service_tag. eg: wework-service 0.0.0-dev.1.xxxxxxx\" exit 1fiIFS=\" \" read -r -a values &lt;&lt;&lt; \"${docker_service_name//\\// }\"# 停止服务service_name=${values[$[${#values[@]}-1]]}workspace=\"/data/wework-service\"cd \"${workspace}\"docker-compose -f base.yml stop \"${service_name}\"echo y | docker-compose -f base.yml rm \"${service_name}\"# 启动服务sed -i \"s/image: ${docker_service_name//\\//\\\\/}.*$/image: ${docker_service_name//\\//\\\\/}:${service_tag}/\" base.ymldocker-compose -f base.yml up -d \"${service_name}\" k8s + image k8s：提供编排配置文件 image：流水线生成 image，直接从公司仓库拉或者下载上传镜像 Kubernetes Deployment1234567891011121314151617181920212223242526Pod Template: Labels: app=wework-service Containers: wework-service: Image: ${wework-service-image} Port: xxxx/TCP Host Port: 0/TCP Limits: cpu: 600m memory: 1Gi Requests: cpu: 64m memory: 64Mi Environment: &lt;none&gt; Mounts: /data/xxx/conf/wework-service from app-config (rw) /etc/localtime from host-time (rw) Volumes: host-time: Type: HostPath (bare host directory volume) Path: /etc/localtime HostPathType: app-config: Type: ConfigMap (a volume populated by a ConfigMap) Name: wework-service-config Optional: false Kubernetes Service1234567891011Name: wework-serviceNamespace: defaultLabels: app=wework-serviceSelector: app=wework-serviceType: ClusterIPIP: x.x.x.x # Cluster IpPort: http xxxx/TCPTargetPort: xxxx/TCPEndpoints: x.x.x.x:xxxx # Pod IpSession Affinity: NoneEvents: &lt;none&gt; 访问服务1http://{ingress_ip}:{port} 或 http://{domain}:{port} 更新服务更新配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 修改配置文件（修改挂载路径的不是容器内部的）kubectl edit configmap wework-service:wq# -------------------------------------------------------------------# 执行更新脚本#!/bin/bash# 读取参数if [ \"$1\" ]then pod_name=$1else echo -e \"usage: ./restart.sh pod-name\\n e.g. ./restart.sh wework-service\" exit 1fi# 重启容器pod_id=$(kubectl get pods | grep \"${pod_name}\" | awk '{print $1}')if [ \"$pod_id\" == \"\" ]then echo \"pod not found!\" exit 1fiecho -n \"restarting ${pod_name}... \"kubectl delete pod \"${pod_id}\" &gt; restart.log &amp;# 健康检查PID=$!marks=( '/' '-' '\\' '|' )while s=$(ps -p $PID -o s=) &amp;&amp; [[ \"$s\" &amp;&amp; \"$s\" != 'Z' ]]; do echo -ne \"\\b${marks[i++ % ${#marks[@]}]}\"; sleep 0.5doneoutput=$(cat restart.log)if [ \"$output\" == \"$pod_id\" ]then echo -e \"\\b\\e[32mDone.\\033[0m\"else echo -e \"\\b\\e[31mFailed!\\033[0m\" echo \"$output\"fi 更新镜像12345678910111213# 镜像获取# 1. 先从本地仓库查找（如果不能ping通公司的仓库，需要下载→保存→上传→加载流程）# 2. 再从远程仓库下载（如果可以ping通公司的仓库，可以直接让脚本跑）# -------------------------------------------------------------------# 登录中转机器docker pull pub/wework-service:0.0.0-dev.1.xxxxxxxdocker tag pub/wework-service:0.0.0-dev.1.xxxxxxx pri/wework-service:0.0.0-dev.1.xxxxxxxdocker push pri/wework-service:0.0.0-dev.1.xxxxxxx# 登录联调机器kubectl set image deploy/wework-service wework-service=pri/wework-service:0.0.0-dev.1.xxxxxxx 堡垒机和隧道机访问服务 所谓隧道代理，就是一个能够自动更换代理地址的代理服务（local → remote）。该隧道机对 local 和 remote 均网络互通，但是 local 和 remote 之间网络不通。 登录隧道机 配置转发规则 选不分配终端 配置 hosts 文件：127.0.0.1 web.test.wework.com 打开隧道机 访问 web 服务：http://web.test.wework.com 更新服务 跳板机属于内控堡垒机范畴，是一种用于单点登陆的主机应用系统。开发机直连公司的内网，跳板机直连实验室内网。 登录开发机 下载镜像并保存镜像 123456789101112#! /bin/bashdocker_service_name=$1service_tag=$2if [[ $# -lt 2 ]];then echo \"please input two param for docker_service_name and service_tag. eg: wework-service 0.0.0-dev.1.xxxxxxx\" exit 1fidocker pull $1:$2IFS=\" \" read -r -a values &lt;&lt;&lt; \"${docker_service_name//\\// }\"service_name=${values[$[${#values[@]}-1]]}docker save -o ${service_name}_${service_tag//./-}.tar $1:$2 sz ${wework-service-image}.tar 到本地 登录跳板机 从本地 rz 上传镜像并加载镜像 1docker load -i ${wework-service-image}.tar 执行更新服务脚本","link":"/2021/10/22/部署服务的N种姿势/"}],"tags":[{"name":"Mock","slug":"Mock","link":"/tags/Mock/"},{"name":"Swagger","slug":"Swagger","link":"/tags/Swagger/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Gin","slug":"Gin","link":"/tags/Gin/"},{"name":"Gorm","slug":"Gorm","link":"/tags/Gorm/"},{"name":"Microservice","slug":"Microservice","link":"/tags/Microservice/"},{"name":"Concurrency","slug":"Concurrency","link":"/tags/Concurrency/"},{"name":"Postman","slug":"Postman","link":"/tags/Postman/"},{"name":"Newman","slug":"Newman","link":"/tags/Newman/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"WSL","slug":"WSL","link":"/tags/WSL/"},{"name":"GoConvey","slug":"GoConvey","link":"/tags/GoConvey/"},{"name":"GoMonkey","slug":"GoMonkey","link":"/tags/GoMonkey/"},{"name":"GoMock","slug":"GoMock","link":"/tags/GoMock/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Go-Micro","slug":"Go-Micro","link":"/tags/Go-Micro/"},{"name":"Grpc","slug":"Grpc","link":"/tags/Grpc/"},{"name":"Vim","slug":"Vim","link":"/tags/Vim/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"Programming Paradigm","slug":"Programming-Paradigm","link":"/tags/Programming-Paradigm/"},{"name":"Fiddler","slug":"Fiddler","link":"/tags/Fiddler/"},{"name":"GitHub Pages","slug":"GitHub-Pages","link":"/tags/GitHub-Pages/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Pytest","slug":"Pytest","link":"/tags/Pytest/"}],"categories":[{"name":"QA","slug":"QA","link":"/categories/QA/"},{"name":"Others","slug":"Others","link":"/categories/Others/"},{"name":"Microservice","slug":"Microservice","link":"/categories/Microservice/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"DevOps","slug":"DevOps","link":"/categories/DevOps/"},{"name":"Sucks","slug":"Sucks","link":"/categories/Sucks/"},{"name":"Arch","slug":"Arch","link":"/categories/Arch/"},{"name":"Mind Map","slug":"Mind-Map","link":"/categories/Mind-Map/"},{"name":"Cheat Sheet","slug":"Cheat-Sheet","link":"/categories/Cheat-Sheet/"}]}